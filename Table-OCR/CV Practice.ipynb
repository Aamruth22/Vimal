{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f26b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/vimalkumar/Documents/Back up/cv/cells/000-000.png',\n",
       " '/home/vimalkumar/Documents/Back up/cv/cells/000-001.png',\n",
       " '/home/vimalkumar/Documents/Back up/cv/cells/000-002.png',\n",
       " '/home/vimalkumar/Documents/Back up/cv/cells/000-003.png',\n",
       " '/home/vimalkumar/Documents/Back up/cv/cells/000-004.png',\n",
       " '/home/vimalkumar/Documents/Back up/cv/cells/000-005.png',\n",
       " '/home/vimalkumar/Documents/Back up/cv/cells/001-000.png',\n",
       " '/home/vimalkumar/Documents/Back up/cv/cells/001-001.png',\n",
       " '/home/vimalkumar/Documents/Back up/cv/cells/001-002.png',\n",
       " '/home/vimalkumar/Documents/Back up/cv/cells/001-003.png',\n",
       " '/home/vimalkumar/Documents/Back up/cv/cells/001-004.png',\n",
       " '/home/vimalkumar/Documents/Back up/cv/cells/001-005.png',\n",
       " '/home/vimalkumar/Documents/Back up/cv/cells/002-000.png',\n",
       " '/home/vimalkumar/Documents/Back up/cv/cells/002-001.png']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_cell_images_from_table(image):\n",
    "    BLUR_KERNEL_SIZE = (17, 17)\n",
    "    STD_DEV_X_DIRECTION = 0\n",
    "    STD_DEV_Y_DIRECTION = 0\n",
    "    blurred = cv2.GaussianBlur(image, BLUR_KERNEL_SIZE, STD_DEV_X_DIRECTION, STD_DEV_Y_DIRECTION)\n",
    "    MAX_COLOR_VAL = 255\n",
    "    BLOCK_SIZE = 15\n",
    "    SUBTRACT_FROM_MEAN = -2\n",
    "    \n",
    "    img_bin = cv2.adaptiveThreshold(\n",
    "        ~blurred,\n",
    "        MAX_COLOR_VAL,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        BLOCK_SIZE,\n",
    "        SUBTRACT_FROM_MEAN,\n",
    "    )\n",
    "    vertical = horizontal = img_bin.copy()\n",
    "    SCALE = 5\n",
    "    image_width, image_height = horizontal.shape\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(image_width / SCALE), 1))\n",
    "    horizontally_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(image_height / SCALE)))\n",
    "    vertically_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "    \n",
    "    horizontally_dilated = cv2.dilate(horizontally_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1)))\n",
    "    vertically_dilated = cv2.dilate(vertically_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (1, 60)))\n",
    "    \n",
    "    mask = horizontally_dilated + vertically_dilated\n",
    "    contours, heirarchy = cv2.findContours(\n",
    "        mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE,\n",
    "    )\n",
    "    \n",
    "    perimeter_lengths = [cv2.arcLength(c, True) for c in contours]\n",
    "    epsilons = [0.05 * p for p in perimeter_lengths]\n",
    "    approx_polys = [cv2.approxPolyDP(c, e, True) for c, e in zip(contours, epsilons)]\n",
    "    \n",
    "    # Filter out contours that aren't rectangular. Those that aren't rectangular\n",
    "    # are probably noise.\n",
    "    approx_rects = [p for p in approx_polys if len(p) == 4]\n",
    "    bounding_rects = [cv2.boundingRect(a) for a in approx_polys]\n",
    "    \n",
    "    # Filter out rectangles that are too narrow or too short.\n",
    "    MIN_RECT_WIDTH = 40\n",
    "    MIN_RECT_HEIGHT = 10\n",
    "    bounding_rects = [\n",
    "        r for r in bounding_rects if MIN_RECT_WIDTH < r[2] and MIN_RECT_HEIGHT < r[3]\n",
    "    ]\n",
    "    \n",
    "    # The largest bounding rectangle is assumed to be the entire table.\n",
    "    # Remove it from the list. We don't want to accidentally try to OCR\n",
    "    # the entire table.\n",
    "    largest_rect = max(bounding_rects, key=lambda r: r[2] * r[3])\n",
    "    bounding_rects = [b for b in bounding_rects if b is not largest_rect]\n",
    "    \n",
    "    cells = [c for c in bounding_rects]\n",
    "    def cell_in_same_row(c1, c2):\n",
    "        c1_center = c1[1] + c1[3] - c1[3] / 2\n",
    "        c2_bottom = c2[1] + c2[3]\n",
    "        c2_top = c2[1]\n",
    "        return c2_top < c1_center < c2_bottom\n",
    "    \n",
    "    orig_cells = [c for c in cells]\n",
    "    rows = []\n",
    "    while cells:\n",
    "        first = cells[0]\n",
    "        rest = cells[1:]\n",
    "        cells_in_same_row = sorted(\n",
    "            [\n",
    "                c for c in rest\n",
    "                if cell_in_same_row(c, first)\n",
    "            ],\n",
    "            key=lambda c: c[0]\n",
    "        )\n",
    "    \n",
    "        row_cells = sorted([first] + cells_in_same_row, key=lambda c: c[0])\n",
    "        rows.append(row_cells)\n",
    "        cells = [\n",
    "            c for c in rest\n",
    "            if not cell_in_same_row(c, first)\n",
    "        ]\n",
    "    \n",
    "    # Sort rows by average height of their center.\n",
    "    def avg_height_of_center(row):\n",
    "        centers = [y + h - h / 2 for x, y, w, h in row]\n",
    "        return sum(centers) / len(centers)\n",
    "    \n",
    "    rows.sort(key=avg_height_of_center)\n",
    "    cell_images_rows = []\n",
    "    for row in rows:\n",
    "        cell_images_row = []\n",
    "        for x, y, w, h in row:\n",
    "            cell_images_row.append(image[y:y+h, x:x+w])\n",
    "        cell_images_rows.append(cell_images_row)\n",
    "    return cell_images_rows\n",
    "\n",
    "def main(f):\n",
    "    results = []\n",
    "    directory, filename = os.path.split(f)\n",
    "    table = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "    rows = extract_cell_images_from_table(table)\n",
    "    cell_img_dir = os.path.join(directory, \"cells\")\n",
    "    os.makedirs(cell_img_dir, exist_ok=True)\n",
    "    out_path = '/home/vimalkumar/Documents/Back up/cv/cells'\n",
    "    paths = []\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, cell in enumerate(row):\n",
    "            cell_filename = \"{:03d}-{:03d}.png\".format(i, j)\n",
    "            path = os.path.join(out_path, cell_filename)\n",
    "            cv2.imwrite(path, cell)\n",
    "            paths.append(path)\n",
    "    return paths\n",
    "\n",
    "f = '/home/vimalkumar/Downloads/final_tables_2.png'\n",
    "\n",
    "main(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b83e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "\n",
    "def main(image_file, tess_args):\n",
    "    \"\"\"\n",
    "    OCR the image and output the text to a file with an extension that is ready\n",
    "    to be used in Tesseract training (.gt.txt).\n",
    "    Tries to crop the image so that only the relevant text gets passed to Tesseract.\n",
    "    Returns the name of the text file that contains the text.\n",
    "    \"\"\"\n",
    "    #file_path = '/home/vimal/Documents/table_detect_samples/structured images/input/011364700/cells'\n",
    "    #image_file = os.listdir(file_path)\n",
    "    \n",
    "    for f in image_file:\n",
    "        #print(f)\n",
    "        directory, filename = os.path.split(f)\n",
    "        filename_sans_ext, ext = os.path.splitext(filename)\n",
    "        image = cv2.imread(os.path.join(file_path,f), cv2.IMREAD_GRAYSCALE)\n",
    "        cropped = crop_to_text(image)\n",
    "        #ocr_data_dir = os.path.join(directory, \"ocr_data\")\n",
    "        #os.makedirs(ocr_data_dir, exist_ok=True)\n",
    "        #out_imagepath = os.path.join(ocr_data_dir, filename)\n",
    "        out_path = '/home/vimalkumar/Documents/Back up/cv/text'\n",
    "        out_txtpath = os.path.join(out_path, \"{}.gt.txt\".format(filename_sans_ext))\n",
    "        #cv2.imwrite(out_imagepath, cropped)\n",
    "        if not tess_args:\n",
    "            d = os.path.dirname(sys.modules[\"table_ocr\"].__file__)\n",
    "            tessdata_dir = os.path.join(d, \"tessdata\")\n",
    "            tess_args = [\"--psm\", \"7\", \"-l\", \"table-ocr\", \"--tessdata-dir\", tessdata_dir]\n",
    "        txt = ocr_image(cropped, \" \".join(tess_args))\n",
    "        with open(out_txtpath, \"w\") as txt_file:\n",
    "            txt_file.write(txt)\n",
    "        #return out_txtpath\n",
    "def crop_to_text(image):\n",
    "    MAX_COLOR_VAL = 255\n",
    "    BLOCK_SIZE = 15\n",
    "    SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "    img_bin = cv2.adaptiveThreshold(\n",
    "        ~image,\n",
    "        MAX_COLOR_VAL,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        BLOCK_SIZE,\n",
    "        SUBTRACT_FROM_MEAN,\n",
    "    )\n",
    "\n",
    "    img_h, img_w = image.shape\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(img_w * 0.5), 1))\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(img_h * 0.7)))\n",
    "    horizontal_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "    vertical_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "    both = horizontal_lines + vertical_lines\n",
    "    cleaned = img_bin - both\n",
    "\n",
    "    # Get rid of little noise.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    opened = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)\n",
    "    opened = cv2.dilate(opened, kernel)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(opened, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_rects = [cv2.boundingRect(c) for c in contours]\n",
    "    NUM_PX_COMMA = 6\n",
    "    MIN_CHAR_AREA = 5 * 9\n",
    "    char_sized_bounding_rects = [(x, y, w, h) for x, y, w, h in bounding_rects if w * h > MIN_CHAR_AREA]\n",
    "    if char_sized_bounding_rects:\n",
    "        minx, miny, maxx, maxy = math.inf, math.inf, 0, 0\n",
    "        for x, y, w, h in char_sized_bounding_rects:\n",
    "            minx = min(minx, x)\n",
    "            miny = min(miny, y)\n",
    "            maxx = max(maxx, x + w)\n",
    "            maxy = max(maxy, y + h)\n",
    "        x, y, w, h = minx, miny, maxx - minx, maxy - miny\n",
    "        cropped = image[y:min(img_h, y+h+NUM_PX_COMMA), x:min(img_w, x+w)]\n",
    "    else:\n",
    "        # If we morphed out all of the text, assume an empty image.\n",
    "        cropped = MAX_COLOR_VAL * np.ones(shape=(20, 100), dtype=np.uint8)\n",
    "    bordered = cv2.copyMakeBorder(cropped, 5, 5, 5, 5, cv2.BORDER_CONSTANT, None, 255)\n",
    "    return bordered\n",
    "def ocr_image(image, config):\n",
    "    return pytesseract.image_to_string(\n",
    "            image,\n",
    "            config='--psm 6'\n",
    "        )\n",
    "\n",
    "file_path = '/home/vimalkumar/Documents/Back up/cv/cells'\n",
    "image_file = os.listdir(file_path)\n",
    "tess_args = os.listdir(file_path)\n",
    "\n",
    "main(image_file, tess_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3e0b3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kind of Tax\\n(a)</td>\n",
       "      <td>Tax Period\\nEnding\\n(b}</td>\n",
       "      <td>Identifying Number\\nfe</td>\n",
       "      <td>Date of\\nAssessment\\n(dj</td>\n",
       "      <td>Last Day for\\nRefiling\\nfe)</td>\n",
       "      <td>Unpaid Balance\\nof Assessment\\n(f}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CIVP\\nCIVP\\nCIVP\\nCIVP\\nCIVP\\nCIVP\\nCIVP\\nCIVP...</td>\n",
       "      <td>06/30/2011\\n06/30/2012\\n09/30/2012\\n12/31/2012...</td>\n",
       "      <td>XXX-XX-0496\\nXXX-XX-0496\\nXXX-XX-0496\\nXXX-XX-...</td>\n",
       "      <td>11/02/2015\\n11/02/2015\\n11/02/2015\\n11/02/2015...</td>\n",
       "      <td>12/02/2025\\n12/02/2025\\n12/02/2025\\n12/02/2025...</td>\n",
       "      <td>1934.88\\n3098.94\\n2166.40\\n2047.09\\n2740.05\\n3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0   \\\n",
       "0                                   Kind of Tax\\n(a)   \n",
       "1  CIVP\\nCIVP\\nCIVP\\nCIVP\\nCIVP\\nCIVP\\nCIVP\\nCIVP...   \n",
       "\n",
       "                                                  1   \\\n",
       "0                            Tax Period\\nEnding\\n(b}   \n",
       "1  06/30/2011\\n06/30/2012\\n09/30/2012\\n12/31/2012...   \n",
       "\n",
       "                                                  2   \\\n",
       "0                             Identifying Number\\nfe   \n",
       "1  XXX-XX-0496\\nXXX-XX-0496\\nXXX-XX-0496\\nXXX-XX-...   \n",
       "\n",
       "                                                  3   \\\n",
       "0                           Date of\\nAssessment\\n(dj   \n",
       "1  11/02/2015\\n11/02/2015\\n11/02/2015\\n11/02/2015...   \n",
       "\n",
       "                                                  4   \\\n",
       "0                        Last Day for\\nRefiling\\nfe)   \n",
       "1  12/02/2025\\n12/02/2025\\n12/02/2025\\n12/02/2025...   \n",
       "\n",
       "                                                  5   6   7   8   9   10  \n",
       "0                 Unpaid Balance\\nof Assessment\\n(f} NaN NaN NaN NaN NaN  \n",
       "1  1934.88\\n3098.94\\n2166.40\\n2047.09\\n2740.05\\n3... NaN NaN NaN NaN NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io \n",
    "import csv\n",
    "\n",
    "def text_files_to_csv(files):\n",
    "    \"\"\"Files must be sorted lexicographically\n",
    "    Filenames must be <row>-<colum>.txt.\n",
    "    000-000.txt\n",
    "    000-001.txt\n",
    "    001-000.txt\n",
    "    etc...\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for f in files:\n",
    "        directory, filename = os.path.split(f)\n",
    "        with open(os.path.join(file_path,f)) as of:\n",
    "            txt = of.read().strip()\n",
    "        row, column = map(int, filename.split(\".\")[0].split(\"-\"))\n",
    "        if row == len(rows):\n",
    "            rows.append([])\n",
    "        rows[row].append(txt)\n",
    "\n",
    "    csv_file = io.StringIO()\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerows(rows)\n",
    "    return csv_file.getvalue()\n",
    "\n",
    "def main(files):\n",
    "    return text_files_to_csv(files)\n",
    "\n",
    "\n",
    "file_path = '/home/vimalkumar/Documents/Back up/cv/text'\n",
    "file = file = os.listdir(file_path)\n",
    "files = sorted(file)\n",
    "\n",
    "\n",
    "a = main(files)\n",
    "#print(a)\n",
    "\n",
    "\n",
    "text_file = open(\"/home/vimalkumar/Documents/Back up/cv/txt/HL_txt.txt\", \"wt\")\n",
    "n = text_file.write(a)\n",
    "text_file.close()\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/vimalkumar/Documents/Back up/cv/txt/HL_txt.txt',header=None,delimiter=',', \n",
    "                     names=list(range(11)))\n",
    "    #df = df.dropna(how='all', axis=1)\n",
    "    #df.columns = df.iloc[0]\n",
    "    #df = df[1:]\n",
    "df = df.dropna(thresh = 3)\n",
    "\n",
    "df.to_csv('/home/vimalkumar/Documents/Back up/cv/txt/HL_csv.csv')\n",
    "#df = df.dropna(thresh = 3)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02737883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edf52e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       Kind of Tax\\n(a)\n",
       "1                Tax Period\\nEnding\\n(b}\n",
       "2                 Identifying Number\\nfe\n",
       "3               Date of\\nAssessment\\n(dj\n",
       "4            Last Day for\\nRefiling\\nfe)\n",
       "5     Unpaid Balance\\nof Assessment\\n(f}\n",
       "6                                    NaN\n",
       "7                                    NaN\n",
       "8                                    NaN\n",
       "9                                    NaN\n",
       "10                                   NaN\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece96c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
