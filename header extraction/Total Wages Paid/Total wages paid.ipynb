{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b62886a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input/0105256000.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-041425e243fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n\u001b[1;32m     21\u001b[0m                              os.path.splitext(file_name)[0]))\n\u001b[0;32m---> 22\u001b[0;31m img = mpimg.imread(os.path.join\n\u001b[0m\u001b[1;32m     23\u001b[0m                    ('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input',\n\u001b[1;32m     24\u001b[0m                     file_name))\n",
      "\u001b[0;32m~/Documents/python_new/cde_venv/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mimg_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         return (_pil_png_to_float_array(image)\n\u001b[1;32m   1503\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImagePlugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPngImageFile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_new/cde_venv/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input/0105256000.jpeg'"
     ]
    }
   ],
   "source": [
    "file_name = '0111295000.jpeg'\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import io \n",
    "import csv\n",
    "import pandas as pd\n",
    "import shutil, os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "shutil.copytree('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/sample', \n",
    "    os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                             os.path.splitext(file_name)[0]))\n",
    "img = mpimg.imread(os.path.join\n",
    "                   ('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input',\n",
    "                    file_name))\n",
    "width = img.shape[1]\n",
    "height = img.shape[0]\n",
    "wi = width * 0.95\n",
    "he = height * 0.1\n",
    "w = int(wi)\n",
    "h = int(he)\n",
    "y = 350\n",
    "x1 = w * 0.45\n",
    "x = int(x1)\n",
    "crop = img[y:y+h, x:x+w]\n",
    "im = Image.fromarray(crop)\n",
    "b = os.path.splitext(file_name)[0]+'_crop.jpeg'\n",
    "im.save(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                       os.path.splitext(file_name)[0],'crop',b))\n",
    "\n",
    "def extract_cell_images_from_table(image):\n",
    "    BLUR_KERNEL_SIZE = (17, 17)\n",
    "    STD_DEV_X_DIRECTION = 0\n",
    "    STD_DEV_Y_DIRECTION = 0\n",
    "    blurred = cv2.GaussianBlur(image, BLUR_KERNEL_SIZE, STD_DEV_X_DIRECTION, STD_DEV_Y_DIRECTION)\n",
    "    MAX_COLOR_VAL = 255\n",
    "    BLOCK_SIZE = 15\n",
    "    SUBTRACT_FROM_MEAN = -2\n",
    "    \n",
    "    img_bin = cv2.adaptiveThreshold(\n",
    "        ~blurred,\n",
    "        MAX_COLOR_VAL,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        BLOCK_SIZE,\n",
    "        SUBTRACT_FROM_MEAN,\n",
    "    )\n",
    "    vertical = horizontal = img_bin.copy()\n",
    "    SCALE = 5\n",
    "    image_width, image_height = horizontal.shape\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(image_width / SCALE), 1))\n",
    "    horizontally_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(image_height / SCALE)))\n",
    "    vertically_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "    \n",
    "    horizontally_dilated = cv2.dilate(horizontally_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1)))\n",
    "    vertically_dilated = cv2.dilate(vertically_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (1, 60)))\n",
    "    \n",
    "    mask = horizontally_dilated + vertically_dilated\n",
    "    contours, heirarchy = cv2.findContours(\n",
    "        mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE,\n",
    "    )\n",
    "    \n",
    "    perimeter_lengths = [cv2.arcLength(c, True) for c in contours]\n",
    "    epsilons = [0.05 * p for p in perimeter_lengths]\n",
    "    approx_polys = [cv2.approxPolyDP(c, e, True) for c, e in zip(contours, epsilons)]\n",
    "    \n",
    "    # Filter out contours that aren't rectangular. Those that aren't rectangular\n",
    "    # are probably noise.\n",
    "    approx_rects = [p for p in approx_polys if len(p) == 4]\n",
    "    bounding_rects = [cv2.boundingRect(a) for a in approx_polys]\n",
    "    \n",
    "    # Filter out rectangles that are too narrow or too short.\n",
    "    MIN_RECT_WIDTH = 40\n",
    "    MIN_RECT_HEIGHT = 10\n",
    "    bounding_rects = [\n",
    "        r for r in bounding_rects if MIN_RECT_WIDTH < r[2] and MIN_RECT_HEIGHT < r[3]\n",
    "    ]\n",
    "    \n",
    "    # The largest bounding rectangle is assumed to be the entire table.\n",
    "    # Remove it from the list. We don't want to accidentally try to OCR\n",
    "    # the entire table.\n",
    "    largest_rect = max(bounding_rects, key=lambda r: r[2] * r[3])\n",
    "    bounding_rects = [b for b in bounding_rects if b is not largest_rect]\n",
    "    \n",
    "    cells = [c for c in bounding_rects]\n",
    "    def cell_in_same_row(c1, c2):\n",
    "        c1_center = c1[1] + c1[3] - c1[3] / 2\n",
    "        c2_bottom = c2[1] + c2[3]\n",
    "        c2_top = c2[1]\n",
    "        return c2_top < c1_center < c2_bottom\n",
    "    \n",
    "    orig_cells = [c for c in cells]\n",
    "    rows = []\n",
    "    while cells:\n",
    "        first = cells[0]\n",
    "        rest = cells[1:]\n",
    "        cells_in_same_row = sorted(\n",
    "            [\n",
    "                c for c in rest\n",
    "                if cell_in_same_row(c, first)\n",
    "            ],\n",
    "            key=lambda c: c[0]\n",
    "        )\n",
    "    \n",
    "        row_cells = sorted([first] + cells_in_same_row, key=lambda c: c[0])\n",
    "        rows.append(row_cells)\n",
    "        cells = [\n",
    "            c for c in rest\n",
    "            if not cell_in_same_row(c, first)\n",
    "        ]\n",
    "    \n",
    "    # Sort rows by average height of their center.\n",
    "    def avg_height_of_center(row):\n",
    "        centers = [y + h - h / 2 for x, y, w, h in row]\n",
    "        return sum(centers) / len(centers)\n",
    "    \n",
    "    rows.sort(key=avg_height_of_center)\n",
    "    cell_images_rows = []\n",
    "    for row in rows:\n",
    "        cell_images_row = []\n",
    "        for x, y, w, h in row:\n",
    "            cell_images_row.append(image[y:y+h, x:x+w])\n",
    "        cell_images_rows.append(cell_images_row)\n",
    "    return cell_images_rows\n",
    "\n",
    "def main(f):\n",
    "    results = []\n",
    "    directory, filename = os.path.split(f)\n",
    "    table = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "    rows = extract_cell_images_from_table(table)\n",
    "    #cell_img_dir = os.path.join(directory, \"cells\")\n",
    "    #os.makedirs(cell_img_dir, exist_ok=True)\n",
    "    out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                            os.path.splitext(file_name)[0],'cells')\n",
    "    paths = []\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, cell in enumerate(row):\n",
    "            cell_filename = \"{:03d}-{:03d}.png\".format(i, j)\n",
    "            path = os.path.join(out_path, cell_filename)\n",
    "            cv2.imwrite(path, cell)\n",
    "            paths.append(path)\n",
    "    return paths\n",
    "\n",
    "f = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                       os.path.splitext(file_name)[0],'crop',b)\n",
    "main(f)\n",
    "\n",
    "def main(image_file, tess_args):\n",
    "    \"\"\"\n",
    "    OCR the image and output the text to a file with an extension that is ready\n",
    "    to be used in Tesseract training (.gt.txt).\n",
    "    Tries to crop the image so that only the relevant text gets passed to Tesseract.\n",
    "    Returns the name of the text file that contains the text.\n",
    "    \"\"\"\n",
    "    #file_path = '/home/vimal/Documents/table_detect_samples/structured images/input/011364700/cells'\n",
    "    #image_file = os.listdir(file_path)\n",
    "    \n",
    "    for f in image_file:\n",
    "        #print(f)\n",
    "        directory, filename = os.path.split(f)\n",
    "        filename_sans_ext, ext = os.path.splitext(filename)\n",
    "        image = cv2.imread(os.path.join(file_path,f), cv2.IMREAD_GRAYSCALE)\n",
    "        cropped = crop_to_text(image)\n",
    "        #ocr_data_dir = os.path.join(directory, \"ocr_data\")\n",
    "        #os.makedirs(ocr_data_dir, exist_ok=True)\n",
    "        #out_imagepath = os.path.join(ocr_data_dir, filename)\n",
    "        out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                            os.path.splitext(file_name)[0],'text')\n",
    "        out_txtpath = os.path.join(out_path, \"{}.txt\".format(filename_sans_ext))\n",
    "        #cv2.imwrite(out_imagepath, cropped)\n",
    "        if not tess_args:\n",
    "            d = os.path.dirname(sys.modules[\"table_ocr\"].__file__)\n",
    "            tessdata_dir = os.path.join(d, \"tessdata\")\n",
    "            tess_args = [\"--psm\", \"7\", \"-l\", \"table-ocr\", \"--tessdata-dir\", tessdata_dir]\n",
    "        txt = ocr_image(cropped, \" \".join(tess_args))\n",
    "        with open(out_txtpath, \"w\") as txt_file:\n",
    "            txt_file.write(txt)\n",
    "        #return out_txtpath\n",
    "def crop_to_text(image):\n",
    "    MAX_COLOR_VAL = 255\n",
    "    BLOCK_SIZE = 15\n",
    "    SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "    img_bin = cv2.adaptiveThreshold(\n",
    "        ~image,\n",
    "        MAX_COLOR_VAL,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY,\n",
    "        BLOCK_SIZE,\n",
    "        SUBTRACT_FROM_MEAN,\n",
    "    )\n",
    "\n",
    "    img_h, img_w = image.shape\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(img_w * 0.5), 1))\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(img_h * 0.7)))\n",
    "    horizontal_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "    vertical_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "    both = horizontal_lines + vertical_lines\n",
    "    cleaned = img_bin - both\n",
    "\n",
    "    # Get rid of little noise.\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    opened = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)\n",
    "    opened = cv2.dilate(opened, kernel)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(opened, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bounding_rects = [cv2.boundingRect(c) for c in contours]\n",
    "    NUM_PX_COMMA = 6\n",
    "    MIN_CHAR_AREA = 5 * 9\n",
    "    char_sized_bounding_rects = [(x, y, w, h) for x, y, w, h in bounding_rects if w * h > MIN_CHAR_AREA]\n",
    "    if char_sized_bounding_rects:\n",
    "        minx, miny, maxx, maxy = math.inf, math.inf, 0, 0\n",
    "        for x, y, w, h in char_sized_bounding_rects:\n",
    "            minx = min(minx, x)\n",
    "            miny = min(miny, y)\n",
    "            maxx = max(maxx, x + w)\n",
    "            maxy = max(maxy, y + h)\n",
    "        x, y, w, h = minx, miny, maxx - minx, maxy - miny\n",
    "        cropped = image[y:min(img_h, y+h+NUM_PX_COMMA), x:min(img_w, x+w)]\n",
    "    else:\n",
    "        # If we morphed out all of the text, assume an empty image.\n",
    "        cropped = MAX_COLOR_VAL * np.ones(shape=(20, 100), dtype=np.uint8)\n",
    "    bordered = cv2.copyMakeBorder(cropped, 5, 5, 5, 5, cv2.BORDER_CONSTANT, None, 255)\n",
    "    return bordered\n",
    "def ocr_image(image, config):\n",
    "    return pytesseract.image_to_string(\n",
    "        image,\n",
    "        lang='eng', config='--psm 6'\n",
    "    )\n",
    "\n",
    "file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                            os.path.splitext(file_name)[0],'cells')\n",
    "image_file = os.listdir(file_path)\n",
    "tess_args = os.listdir(file_path)\n",
    "\n",
    "main(image_file, tess_args)\n",
    "\n",
    "def text_files_to_csv(files):\n",
    "    \"\"\"Files must be sorted lexicographically\n",
    "    Filenames must be <row>-<colum>.txt.\n",
    "    000-000.txt\n",
    "    000-001.txt\n",
    "    001-000.txt\n",
    "    etc...\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for f in files:\n",
    "        directory, filename = os.path.split(f)\n",
    "        with open(os.path.join(file_path,f)) as of:\n",
    "            txt = of.read().strip()\n",
    "        row, column = map(int, filename.split(\".\")[0].split(\"-\"))\n",
    "        if row == len(rows):\n",
    "            rows.append([])\n",
    "        rows[row].append(txt)\n",
    "\n",
    "    csv_file = io.StringIO()\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerows(rows)\n",
    "    return csv_file.getvalue()\n",
    "\n",
    "def main(files):\n",
    "    return text_files_to_csv(files)\n",
    "\n",
    "\n",
    "file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                            os.path.splitext(file_name)[0],'text')\n",
    "file = os.listdir(file_path)\n",
    "files = sorted(file)\n",
    "\n",
    "a = main(files)\n",
    "#print(a)\n",
    "\n",
    "c = os.path.splitext(file_name)[0]+'_text.txt'\n",
    "#cs = os.path.splitext(file_name)[0]+'_xl.csv'\n",
    "\n",
    "text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                            os.path.splitext(file_name)[0],'txt',c), \"wt\")\n",
    "n = text_file.write(a)\n",
    "text_file.close()\n",
    "\n",
    "df = pd.read_csv(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                            os.path.splitext(file_name)[0],'txt',c),\n",
    "    header=None,delimiter=',',names=list(range(10)))\n",
    "df1 = df[df[0].str.contains('TOTAL WAGES PAID') | df[0].str.contains('total wages paid')\n",
    "                             | df[0].str.contains('Total wages paid')]\n",
    "df1.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "367817a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def total_wages_paid(file_name):\n",
    "    import matplotlib.image as mpimg\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    import cv2\n",
    "    import os\n",
    "    import math\n",
    "    import sys\n",
    "    import numpy as np\n",
    "    import pytesseract\n",
    "    import io \n",
    "    import csv\n",
    "    import pandas as pd\n",
    "    import shutil, os\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    shutil.copytree('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/sample', \n",
    "        os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                 os.path.splitext(file_name)[0]))\n",
    "    img = mpimg.imread(os.path.join\n",
    "                       ('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input',\n",
    "                        file_name))\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    wi = width * 0.95\n",
    "    he = height * 0.1\n",
    "    w = int(wi)\n",
    "    h = int(he)\n",
    "    y = 350\n",
    "    x1 = w * 0.45\n",
    "    x = int(x1)\n",
    "    crop = img[y:y+h, x:x+w]\n",
    "    im = Image.fromarray(crop)\n",
    "    b = os.path.splitext(file_name)[0]+'_crop.jpeg'\n",
    "    im.save(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                           os.path.splitext(file_name)[0],'crop',b))\n",
    "\n",
    "    def extract_cell_images_from_table(image):\n",
    "        BLUR_KERNEL_SIZE = (17, 17)\n",
    "        STD_DEV_X_DIRECTION = 0\n",
    "        STD_DEV_Y_DIRECTION = 0\n",
    "        blurred = cv2.GaussianBlur(image, BLUR_KERNEL_SIZE, STD_DEV_X_DIRECTION, STD_DEV_Y_DIRECTION)\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~blurred,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "        vertical = horizontal = img_bin.copy()\n",
    "        SCALE = 5\n",
    "        image_width, image_height = horizontal.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(image_width / SCALE), 1))\n",
    "        horizontally_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(image_height / SCALE)))\n",
    "        vertically_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "\n",
    "        horizontally_dilated = cv2.dilate(horizontally_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1)))\n",
    "        vertically_dilated = cv2.dilate(vertically_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (1, 60)))\n",
    "\n",
    "        mask = horizontally_dilated + vertically_dilated\n",
    "        contours, heirarchy = cv2.findContours(\n",
    "            mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE,\n",
    "        )\n",
    "\n",
    "        perimeter_lengths = [cv2.arcLength(c, True) for c in contours]\n",
    "        epsilons = [0.05 * p for p in perimeter_lengths]\n",
    "        approx_polys = [cv2.approxPolyDP(c, e, True) for c, e in zip(contours, epsilons)]\n",
    "\n",
    "        # Filter out contours that aren't rectangular. Those that aren't rectangular\n",
    "        # are probably noise.\n",
    "        approx_rects = [p for p in approx_polys if len(p) == 4]\n",
    "        bounding_rects = [cv2.boundingRect(a) for a in approx_polys]\n",
    "\n",
    "        # Filter out rectangles that are too narrow or too short.\n",
    "        MIN_RECT_WIDTH = 40\n",
    "        MIN_RECT_HEIGHT = 10\n",
    "        bounding_rects = [\n",
    "            r for r in bounding_rects if MIN_RECT_WIDTH < r[2] and MIN_RECT_HEIGHT < r[3]\n",
    "        ]\n",
    "\n",
    "        # The largest bounding rectangle is assumed to be the entire table.\n",
    "        # Remove it from the list. We don't want to accidentally try to OCR\n",
    "        # the entire table.\n",
    "        largest_rect = max(bounding_rects, key=lambda r: r[2] * r[3])\n",
    "        bounding_rects = [b for b in bounding_rects if b is not largest_rect]\n",
    "\n",
    "        cells = [c for c in bounding_rects]\n",
    "        def cell_in_same_row(c1, c2):\n",
    "            c1_center = c1[1] + c1[3] - c1[3] / 2\n",
    "            c2_bottom = c2[1] + c2[3]\n",
    "            c2_top = c2[1]\n",
    "            return c2_top < c1_center < c2_bottom\n",
    "\n",
    "        orig_cells = [c for c in cells]\n",
    "        rows = []\n",
    "        while cells:\n",
    "            first = cells[0]\n",
    "            rest = cells[1:]\n",
    "            cells_in_same_row = sorted(\n",
    "                [\n",
    "                    c for c in rest\n",
    "                    if cell_in_same_row(c, first)\n",
    "                ],\n",
    "                key=lambda c: c[0]\n",
    "            )\n",
    "\n",
    "            row_cells = sorted([first] + cells_in_same_row, key=lambda c: c[0])\n",
    "            rows.append(row_cells)\n",
    "            cells = [\n",
    "                c for c in rest\n",
    "                if not cell_in_same_row(c, first)\n",
    "            ]\n",
    "\n",
    "        # Sort rows by average height of their center.\n",
    "        def avg_height_of_center(row):\n",
    "            centers = [y + h - h / 2 for x, y, w, h in row]\n",
    "            return sum(centers) / len(centers)\n",
    "\n",
    "        rows.sort(key=avg_height_of_center)\n",
    "        cell_images_rows = []\n",
    "        for row in rows:\n",
    "            cell_images_row = []\n",
    "            for x, y, w, h in row:\n",
    "                cell_images_row.append(image[y:y+h, x:x+w])\n",
    "            cell_images_rows.append(cell_images_row)\n",
    "        return cell_images_rows\n",
    "\n",
    "    def main(f):\n",
    "        results = []\n",
    "        directory, filename = os.path.split(f)\n",
    "        table = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        rows = extract_cell_images_from_table(table)\n",
    "        #cell_img_dir = os.path.join(directory, \"cells\")\n",
    "        #os.makedirs(cell_img_dir, exist_ok=True)\n",
    "        out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'cells')\n",
    "        paths = []\n",
    "        for i, row in enumerate(rows):\n",
    "            for j, cell in enumerate(row):\n",
    "                cell_filename = \"{:03d}-{:03d}.png\".format(i, j)\n",
    "                path = os.path.join(out_path, cell_filename)\n",
    "                cv2.imwrite(path, cell)\n",
    "                paths.append(path)\n",
    "        return paths\n",
    "\n",
    "    f = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                           os.path.splitext(file_name)[0],'crop',b)\n",
    "    main(f)\n",
    "\n",
    "    def main(image_file, tess_args):\n",
    "        \"\"\"\n",
    "        OCR the image and output the text to a file with an extension that is ready\n",
    "        to be used in Tesseract training (.gt.txt).\n",
    "        Tries to crop the image so that only the relevant text gets passed to Tesseract.\n",
    "        Returns the name of the text file that contains the text.\n",
    "        \"\"\"\n",
    "        #file_path = '/home/vimal/Documents/table_detect_samples/structured images/input/011364700/cells'\n",
    "        #image_file = os.listdir(file_path)\n",
    "\n",
    "        for f in image_file:\n",
    "            #print(f)\n",
    "            directory, filename = os.path.split(f)\n",
    "            filename_sans_ext, ext = os.path.splitext(filename)\n",
    "            image = cv2.imread(os.path.join(file_path,f), cv2.IMREAD_GRAYSCALE)\n",
    "            cropped = crop_to_text(image)\n",
    "            #ocr_data_dir = os.path.join(directory, \"ocr_data\")\n",
    "            #os.makedirs(ocr_data_dir, exist_ok=True)\n",
    "            #out_imagepath = os.path.join(ocr_data_dir, filename)\n",
    "            out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'text')\n",
    "            out_txtpath = os.path.join(out_path, \"{}.txt\".format(filename_sans_ext))\n",
    "            #cv2.imwrite(out_imagepath, cropped)\n",
    "            if not tess_args:\n",
    "                d = os.path.dirname(sys.modules[\"table_ocr\"].__file__)\n",
    "                tessdata_dir = os.path.join(d, \"tessdata\")\n",
    "                tess_args = [\"--psm\", \"7\", \"-l\", \"table-ocr\", \"--tessdata-dir\", tessdata_dir]\n",
    "            txt = ocr_image(cropped, \" \".join(tess_args))\n",
    "            with open(out_txtpath, \"w\") as txt_file:\n",
    "                txt_file.write(txt)\n",
    "            #return out_txtpath\n",
    "    def crop_to_text(image):\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~image,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "\n",
    "        img_h, img_w = image.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(img_w * 0.5), 1))\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(img_h * 0.7)))\n",
    "        horizontal_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "        both = horizontal_lines + vertical_lines\n",
    "        cleaned = img_bin - both\n",
    "\n",
    "        # Get rid of little noise.\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        opened = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)\n",
    "        opened = cv2.dilate(opened, kernel)\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(opened, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        bounding_rects = [cv2.boundingRect(c) for c in contours]\n",
    "        NUM_PX_COMMA = 6\n",
    "        MIN_CHAR_AREA = 5 * 9\n",
    "        char_sized_bounding_rects = [(x, y, w, h) for x, y, w, h in bounding_rects if w * h > MIN_CHAR_AREA]\n",
    "        if char_sized_bounding_rects:\n",
    "            minx, miny, maxx, maxy = math.inf, math.inf, 0, 0\n",
    "            for x, y, w, h in char_sized_bounding_rects:\n",
    "                minx = min(minx, x)\n",
    "                miny = min(miny, y)\n",
    "                maxx = max(maxx, x + w)\n",
    "                maxy = max(maxy, y + h)\n",
    "            x, y, w, h = minx, miny, maxx - minx, maxy - miny\n",
    "            cropped = image[y:min(img_h, y+h+NUM_PX_COMMA), x:min(img_w, x+w)]\n",
    "        else:\n",
    "            # If we morphed out all of the text, assume an empty image.\n",
    "            cropped = MAX_COLOR_VAL * np.ones(shape=(20, 100), dtype=np.uint8)\n",
    "        bordered = cv2.copyMakeBorder(cropped, 5, 5, 5, 5, cv2.BORDER_CONSTANT, None, 255)\n",
    "        return bordered\n",
    "    def ocr_image(image, config):\n",
    "        return pytesseract.image_to_string(\n",
    "            image,\n",
    "            lang='eng', config='--psm 6'\n",
    "        )\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'cells')\n",
    "    image_file = os.listdir(file_path)\n",
    "    tess_args = os.listdir(file_path)\n",
    "\n",
    "    main(image_file, tess_args)\n",
    "\n",
    "    def text_files_to_csv(files):\n",
    "        \"\"\"Files must be sorted lexicographically\n",
    "        Filenames must be <row>-<colum>.txt.\n",
    "        000-000.txt\n",
    "        000-001.txt\n",
    "        001-000.txt\n",
    "        etc...\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        for f in files:\n",
    "            directory, filename = os.path.split(f)\n",
    "            with open(os.path.join(file_path,f)) as of:\n",
    "                txt = of.read().strip()\n",
    "            row, column = map(int, filename.split(\".\")[0].split(\"-\"))\n",
    "            if row == len(rows):\n",
    "                rows.append([])\n",
    "            rows[row].append(txt)\n",
    "\n",
    "        csv_file = io.StringIO()\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerows(rows)\n",
    "        return csv_file.getvalue()\n",
    "\n",
    "    def main(files):\n",
    "        return text_files_to_csv(files)\n",
    "\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'text')\n",
    "    file = os.listdir(file_path)\n",
    "    files = sorted(file)\n",
    "\n",
    "    a = main(files)\n",
    "    print(a)\n",
    "\n",
    "    c = os.path.splitext(file_name)[0]+'_text.txt'\n",
    "    t = os.path.splitext(file_name)[0]+'_f-text.txt'\n",
    "\n",
    "    #cs = os.path.splitext(file_name)[0]+'_xl.csv'\n",
    "\n",
    "    text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'txt',c), \"wt\")\n",
    "    n = text_file.write(a)\n",
    "    text_file.close()\n",
    "    #print(text_file)\n",
    "\n",
    "    df = pd.read_csv(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'txt',c),\n",
    "        header=None,delimiter=',',names=list(range(10)))\n",
    "    print(df)\n",
    "    df1 = df[df[0].str.contains('TOTAL WAGES PAID') | df[0].str.contains('total wages paid')\n",
    "                                 | df[0].str.contains('Total wages paid')]\n",
    "    final = df1.dropna(axis=1)\n",
    "    print(final)\n",
    "    final[0] = final[0].str.replace('\\d+','') \n",
    "    final[0] = final[0].str.replace(r'[^\\w\\s]+', '')\n",
    "    final[0] = final[0].str.replace('\\d+', '')\n",
    "    final[0] = final[0].str.strip()\n",
    "    final[1] = final[1].str.replace(r'[^\\w\\s]+', '')\n",
    "    print(final)\n",
    "    \n",
    "    with open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'final_text',t), 'a') as f:\n",
    "        f.write(final.to_string(header = False, index = False))\n",
    "    text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'final_text',t), 'r+')\n",
    "    print(text_file.read())\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a66cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"MUST HAVE AMOUNTS IN 4, 5, & 6, EVEN IF ZERO\",\r\n",
      "\"4 TOTAL WAGES PAID | 339,350 47\",\r\n",
      "\n",
      "                                              0   1   2   3   4   5   6   7  \\\n",
      "0  MUST HAVE AMOUNTS IN 4, 5, & 6, EVEN IF ZERO NaN NaN NaN NaN NaN NaN NaN   \n",
      "1               4 TOTAL WAGES PAID | 339,350 47 NaN NaN NaN NaN NaN NaN NaN   \n",
      "\n",
      "    8   9  \n",
      "0 NaN NaN  \n",
      "1 NaN NaN  \n",
      "                                 0\n",
      "1  4 TOTAL WAGES PAID | 339,350 47\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/python_new/cde_venv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-889838341174>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'0100477000.jpeg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtotal_wages_paid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-88a0c761e7ba>\u001b[0m in \u001b[0;36mtotal_wages_paid\u001b[0;34m(file_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\d+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m     \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[^\\w\\s]+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_new/cde_venv/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_new/cde_venv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "file_name = '0100477000.jpeg'\n",
    "total_wages_paid(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "eadcae41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"MUST HAVE AMOUNTS IN 4, 5, & 6, EVEN IF ZERO\",\r\n",
      "4 TOTAL WAGES PAID,glo ยง,\r\n",
      "\n",
      "                                              0      1   2   3   4   5   6  \\\n",
      "0  MUST HAVE AMOUNTS IN 4, 5, & 6, EVEN IF ZERO    NaN NaN NaN NaN NaN NaN   \n",
      "1                            4 TOTAL WAGES PAID  glo ยง NaN NaN NaN NaN NaN   \n",
      "\n",
      "    7   8   9  \n",
      "0 NaN NaN NaN  \n",
      "1 NaN NaN NaN  \n",
      "                    0      1\n",
      "1  4 TOTAL WAGES PAID  glo ยง\n",
      "                  0     1\n",
      "1  TOTAL WAGES PAID  glo \n",
      "TOTAL WAGES PAID glo \n"
     ]
    }
   ],
   "source": [
    "file_name = '0111295000.jpeg'\n",
    "total_wages_paid(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f8d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24908fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a4a9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3fec89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e787ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0648aca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57760b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04c3abd5",
   "metadata": {},
   "source": [
    "# GM total wages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c86ac3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Total_wages_paid(file_name):\n",
    "    import matplotlib.image as mpimg\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    import cv2\n",
    "    import os\n",
    "    import math\n",
    "    import sys\n",
    "    import numpy as np\n",
    "    import pytesseract\n",
    "    import io \n",
    "    import csv\n",
    "    import pandas as pd\n",
    "    import shutil, os\n",
    "\n",
    "    shutil.copytree('/home/vimalkumar.s/Documents/extraction/header/total wages paid/gm/sample', \n",
    "        os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/gm',\n",
    "                                 os.path.splitext(file_name)[0]))\n",
    "    img = mpimg.imread(os.path.join\n",
    "                       ('/home/vimalkumar.s/Documents/extraction/header/total wages paid/gm/input',\n",
    "                        file_name))\n",
    "    \n",
    "    def extract_cell_images_from_table(image):\n",
    "        BLUR_KERNEL_SIZE = (17, 17)\n",
    "        STD_DEV_X_DIRECTION = 0\n",
    "        STD_DEV_Y_DIRECTION = 0\n",
    "        blurred = cv2.GaussianBlur(image, BLUR_KERNEL_SIZE, STD_DEV_X_DIRECTION, STD_DEV_Y_DIRECTION)\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~blurred,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "        vertical = horizontal = img_bin.copy()\n",
    "        SCALE = 5\n",
    "        image_width, image_height = horizontal.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(image_width / SCALE), 1))\n",
    "        horizontally_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(image_height / SCALE)))\n",
    "        vertically_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "\n",
    "        horizontally_dilated = cv2.dilate(horizontally_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1)))\n",
    "        vertically_dilated = cv2.dilate(vertically_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (1, 60)))\n",
    "\n",
    "        mask = horizontally_dilated + vertically_dilated\n",
    "        contours, heirarchy = cv2.findContours(\n",
    "            mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE,\n",
    "        )\n",
    "\n",
    "        perimeter_lengths = [cv2.arcLength(c, True) for c in contours]\n",
    "        epsilons = [0.05 * p for p in perimeter_lengths]\n",
    "        approx_polys = [cv2.approxPolyDP(c, e, True) for c, e in zip(contours, epsilons)]\n",
    "\n",
    "        # Filter out contours that aren't rectangular. Those that aren't rectangular\n",
    "        # are probably noise.\n",
    "        approx_rects = [p for p in approx_polys if len(p) == 4]\n",
    "        bounding_rects = [cv2.boundingRect(a) for a in approx_polys]\n",
    "\n",
    "        # Filter out rectangles that are too narrow or too short.\n",
    "        MIN_RECT_WIDTH = 40\n",
    "        MIN_RECT_HEIGHT = 10\n",
    "        bounding_rects = [\n",
    "            r for r in bounding_rects if MIN_RECT_WIDTH < r[2] and MIN_RECT_HEIGHT < r[3]\n",
    "        ]\n",
    "\n",
    "        # The largest bounding rectangle is assumed to be the entire table.\n",
    "        # Remove it from the list. We don't want to accidentally try to OCR\n",
    "        # the entire table.\n",
    "        largest_rect = max(bounding_rects, key=lambda r: r[2] * r[3])\n",
    "        bounding_rects = [b for b in bounding_rects if b is not largest_rect]\n",
    "\n",
    "        cells = [c for c in bounding_rects]\n",
    "        def cell_in_same_row(c1, c2):\n",
    "            c1_center = c1[1] + c1[3] - c1[3] / 2\n",
    "            c2_bottom = c2[1] + c2[3]\n",
    "            c2_top = c2[1]\n",
    "            return c2_top < c1_center < c2_bottom\n",
    "\n",
    "        orig_cells = [c for c in cells]\n",
    "        rows = []\n",
    "        while cells:\n",
    "            first = cells[0]\n",
    "            rest = cells[1:]\n",
    "            cells_in_same_row = sorted(\n",
    "                [\n",
    "                    c for c in rest\n",
    "                    if cell_in_same_row(c, first)\n",
    "                ],\n",
    "                key=lambda c: c[0]\n",
    "            )\n",
    "\n",
    "            row_cells = sorted([first] + cells_in_same_row, key=lambda c: c[0])\n",
    "            rows.append(row_cells)\n",
    "            cells = [\n",
    "                c for c in rest\n",
    "                if not cell_in_same_row(c, first)\n",
    "            ]\n",
    "\n",
    "        # Sort rows by average height of their center.\n",
    "        def avg_height_of_center(row):\n",
    "            centers = [y + h - h / 2 for x, y, w, h in row]\n",
    "            return sum(centers) / len(centers)\n",
    "\n",
    "        rows.sort(key=avg_height_of_center)\n",
    "        cell_images_rows = []\n",
    "        for row in rows:\n",
    "            cell_images_row = []\n",
    "            for x, y, w, h in row:\n",
    "                cell_images_row.append(image[y:y+h, x:x+w])\n",
    "            cell_images_rows.append(cell_images_row)\n",
    "        return cell_images_rows\n",
    "\n",
    "    def main(f):\n",
    "        results = []\n",
    "        directory, filename = os.path.split(f)\n",
    "        table = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        rows = extract_cell_images_from_table(table)\n",
    "        #cell_img_dir = os.path.join(directory, \"cells\")\n",
    "        #os.makedirs(cell_img_dir, exist_ok=True)\n",
    "        out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/gm',\n",
    "                                os.path.splitext(file_name)[0],'cells')\n",
    "        paths = []\n",
    "        for i, row in enumerate(rows):\n",
    "            for j, cell in enumerate(row):\n",
    "                cell_filename = \"{:03d}-{:03d}.png\".format(i, j)\n",
    "                path = os.path.join(out_path, cell_filename)\n",
    "                cv2.imwrite(path, cell)\n",
    "                paths.append(path)\n",
    "        return paths\n",
    "\n",
    "    f = os.path.join(os.path.join\n",
    "                       ('/home/vimalkumar.s/Documents/extraction/header/total wages paid/gm/input',\n",
    "                        file_name))\n",
    "    main(f)\n",
    "\n",
    "    def main(image_file, tess_args):\n",
    "        \"\"\"\n",
    "        OCR the image and output the text to a file with an extension that is ready\n",
    "        to be used in Tesseract training (.gt.txt).\n",
    "        Tries to crop the image so that only the relevant text gets passed to Tesseract.\n",
    "        Returns the name of the text file that contains the text.\n",
    "        \"\"\"\n",
    "        #file_path = '/home/vimal/Documents/table_detect_samples/structured images/input/011364700/cells'\n",
    "        #image_file = os.listdir(file_path)\n",
    "\n",
    "        for f in image_file:\n",
    "            #print(f)\n",
    "            directory, filename = os.path.split(f)\n",
    "            filename_sans_ext, ext = os.path.splitext(filename)\n",
    "            image = cv2.imread(os.path.join(file_path,f), cv2.IMREAD_GRAYSCALE)\n",
    "            cropped = crop_to_text(image)\n",
    "            #ocr_data_dir = os.path.join(directory, \"ocr_data\")\n",
    "            #os.makedirs(ocr_data_dir, exist_ok=True)\n",
    "            #out_imagepath = os.path.join(ocr_data_dir, filename)\n",
    "            out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/gm',\n",
    "                                os.path.splitext(file_name)[0],'text')\n",
    "            out_txtpath = os.path.join(out_path, \"{}.txt\".format(filename_sans_ext))\n",
    "            #cv2.imwrite(out_imagepath, cropped)\n",
    "            if not tess_args:\n",
    "                d = os.path.dirname(sys.modules[\"table_ocr\"].__file__)\n",
    "                tessdata_dir = os.path.join(d, \"tessdata\")\n",
    "                tess_args = [\"--psm\", \"7\", \"-l\", \"table-ocr\", \"--tessdata-dir\", tessdata_dir]\n",
    "            txt = ocr_image(cropped, \" \".join(tess_args))\n",
    "            with open(out_txtpath, \"w\") as txt_file:\n",
    "                txt_file.write(txt)\n",
    "            #return out_txtpath\n",
    "    def crop_to_text(image):\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~image,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "\n",
    "        img_h, img_w = image.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(img_w * 0.5), 1))\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(img_h * 0.7)))\n",
    "        horizontal_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "        both = horizontal_lines + vertical_lines\n",
    "        cleaned = img_bin - both\n",
    "\n",
    "        # Get rid of little noise.\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        opened = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)\n",
    "        opened = cv2.dilate(opened, kernel)\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(opened, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        bounding_rects = [cv2.boundingRect(c) for c in contours]\n",
    "        NUM_PX_COMMA = 6\n",
    "        MIN_CHAR_AREA = 5 * 9\n",
    "        char_sized_bounding_rects = [(x, y, w, h) for x, y, w, h in bounding_rects if w * h > MIN_CHAR_AREA]\n",
    "        if char_sized_bounding_rects:\n",
    "            minx, miny, maxx, maxy = math.inf, math.inf, 0, 0\n",
    "            for x, y, w, h in char_sized_bounding_rects:\n",
    "                minx = min(minx, x)\n",
    "                miny = min(miny, y)\n",
    "                maxx = max(maxx, x + w)\n",
    "                maxy = max(maxy, y + h)\n",
    "            x, y, w, h = minx, miny, maxx - minx, maxy - miny\n",
    "            cropped = image[y:min(img_h, y+h+NUM_PX_COMMA), x:min(img_w, x+w)]\n",
    "        else:\n",
    "            # If we morphed out all of the text, assume an empty image.\n",
    "            cropped = MAX_COLOR_VAL * np.ones(shape=(20, 100), dtype=np.uint8)\n",
    "        bordered = cv2.copyMakeBorder(cropped, 5, 5, 5, 5, cv2.BORDER_CONSTANT, None, 255)\n",
    "        return bordered\n",
    "    def ocr_image(image, config):\n",
    "        return pytesseract.image_to_string(\n",
    "            image,\n",
    "            lang='eng', config='--psm 6'\n",
    "        )\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/gm',\n",
    "                                os.path.splitext(file_name)[0],'cells')\n",
    "    image_file = os.listdir(file_path)\n",
    "    tess_args = os.listdir(file_path)\n",
    "\n",
    "    main(image_file, tess_args)\n",
    "\n",
    "    def text_files_to_csv(files):\n",
    "        \"\"\"Files must be sorted lexicographically\n",
    "        Filenames must be <row>-<colum>.txt.\n",
    "        000-000.txt\n",
    "        000-001.txt\n",
    "        001-000.txt\n",
    "        etc...\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        for f in files:\n",
    "            directory, filename = os.path.split(f)\n",
    "            with open(os.path.join(file_path,f)) as of:\n",
    "                txt = of.read().strip()\n",
    "            row, column = map(int, filename.split(\".\")[0].split(\"-\"))\n",
    "            if row == len(rows):\n",
    "                rows.append([])\n",
    "            rows[row].append(txt)\n",
    "\n",
    "        csv_file = io.StringIO()\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerows(rows)\n",
    "        return csv_file.getvalue()\n",
    "\n",
    "    def main(files):\n",
    "        return text_files_to_csv(files)\n",
    "\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/gm',\n",
    "                                os.path.splitext(file_name)[0],'text')\n",
    "    file = os.listdir(file_path)\n",
    "    files = sorted(file)\n",
    "\n",
    "    a = main(files)\n",
    "    #print(a)\n",
    "\n",
    "    c = os.path.splitext(file_name)[0]+'_text.txt'\n",
    "    #cs = os.path.splitext(file_name)[0]+'_xl.csv'\n",
    "\n",
    "    text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/gm',\n",
    "                                os.path.splitext(file_name)[0],'txt',c), \"wt\")\n",
    "    n = text_file.write(a)\n",
    "    text_file.close()\n",
    "\n",
    "    df = pd.read_csv(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/gm',\n",
    "                                os.path.splitext(file_name)[0],'txt',c),\n",
    "        header=None,delimiter=',',names=list(range(10)))\n",
    "    df1 = df[df[0].str.contains('TOTAL WAGES PAID') | df[0].str.contains('total wages paid')\n",
    "                                 | df[0].str.contains('Total wages paid')]\n",
    "    final = df1.dropna(axis=1)\n",
    "    print(final[final.columns[0:2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a34b550a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0          1\n",
      "3  4 TOTAL WAGES PAID  64,571.94\n"
     ]
    }
   ],
   "source": [
    "file_name = '0534088000.jpeg'\n",
    "Total_wages_paid(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d4a62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cb1e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b12f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e8bdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec3585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9b0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e510f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5c12da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0109374000.tif TOTAL WAGES PAID 0\n",
      "0497990000.tif TOTAL WAGES PAID 249400\n",
      "0496106000.tif TOTAL WAGES PAID 19035118\n",
      "0103397000.tif TOTAL WAGES PAID 663517233\n",
      "0110228000.tif TOTAL WAGES PAID 8298131\n",
      "0500847001.tif TOTAL WAGES PAID 90754\n",
      "0107313000.tif TOTAL WAGES PAID 4079264\n",
      "0104702000.tif TOTAL WAGES PAID 0\n",
      "0102281000.tif TOTAL WAGES PAID 7786950\n",
      "0496813000.tif TOTAL WAGES PAID 3163933\n",
      "0108918000.tif TOTAL WAGES PAID 0\n",
      "0499639000.tif TOTAL WAGES PAID 12854493\n",
      "0496350000.tif TOTAL WAGES PAID 2190239\n",
      "0498112000.tif TOTAL WAGES PAID 5419282\n",
      "0110331000.tif TOTAL WAGES PAID 3777105407\n",
      "0504031000.tif TOTAL WAGES PAID 18805150\n",
      "0110040000.tif TOTAL WAGES PAID 747145\n",
      "0102880000.tif TOTAL WAGES PAID 114370139\n",
      "0503866000.tif TOTAL WAGES PAID 11421015\n",
      "0104921000.tif TOTAL WAGES PAID 25642596\n",
      "0109337000.tif TOTAL WAGES PAID 9758340\n",
      "0499335000.tif TOTAL WAGES PAID 0\n",
      "0102551000.tif TOTAL WAGES PAID 01553224\n",
      "0105311000.tif TOTAL WAGES PAID 11234600\n",
      "0504111000.tif TOTAL WAGES PAID 1715246\n",
      "0500221000.tif TOTAL WAGES PAID 278100\n",
      "0106842000.tif TOTAL WAGES PAID 25599630\n",
      "0110432000.tif TOTAL WAGES PAID 778800\n",
      "0498501000.tif TOTAL WAGES PAID 13611704\n",
      "0100617000.tif TOTAL WAGES PAID 492lA32\n",
      "0499925000.tif TOTAL WAGES PAID 1919870\n",
      "0108857000.tif TOTAL WAGES PAID 0887ZR00\n",
      "0110334000.tif TOTAL WAGES PAID 24453190\n",
      "0499741000.tif TOTAL WAGES PAID 450000\n",
      "0494629000.tif TOTAL WAGES PAID 3095\n",
      "0103841000.tif TOTAL WAGES PAID 15054298\n",
      "0108220000.tif TOTAL WAGES PAID 16964544\n",
      "0102292000.tif TOTAL WAGES PAID 28073731\n",
      "0498755000.tif TOTAL WAGES PAID 2868068\n",
      "0102108000.tif TOTAL WAGES PAID Alle5971dle\n",
      "0497319000.tif TOTAL WAGES PAID 1561996\n",
      "0500998000.tif TOTAL WAGES PAID 4183586\n",
      "0100477000.tif TOTAL WAGES PAID 33935047\n",
      "0109010000.tif TOTAL WAGES PAID 0\n",
      "0495860000.tif TOTAL WAGES PAID 1200000\n",
      "0495950000.tif TOTAL WAGES PAID 220899\n",
      "0498650000.tif TOTAL WAGES PAID 6019256\n",
      "0497212000.tif TOTAL WAGES PAID 3516429\n",
      "0497688000.tif TOTAL WAGES PAID 7930837\n",
      "0494564000.tif TOTAL WAGES PAID 9365312\n",
      "0495599000.tif TOTAL WAGES PAID 855675\n",
      "0111295000.tif TOTAL WAGES PAID ploS\n",
      "0102866000.tif TOTAL WAGES PAID 0\n",
      "0101439000.tif TOTAL WAGES PAID 17086993252\n",
      "0104079000.tif TOTAL WAGES PAID 1278550\n",
      "0496006000.tif TOTAL WAGES PAID 0\n",
      "0495469000.tif TOTAL WAGES PAID 2113550\n",
      "0501500000.tif TOTAL WAGES PAID 056000\n",
      "0497528000.tif TOTAL WAGES PAID 1200000\n",
      "0108704000.tif TOTAL WAGES PAID 77107638\n",
      "0106830000.tif TOTAL WAGES PAID 44355598\n",
      "0101231000.tif TOTAL WAGES PAID 0\n",
      "0105256000.tif TOTAL WAGES PAID 7237570\n",
      "0499887000.tif TOTAL WAGES PAID 2370975\n",
      "0110533000.tif TOTAL WAGES PAID 0\n",
      "0111158000.tif TOTAL WAGES PAID 4013896\n",
      "0495878000.tif TOTAL WAGES PAID 3610000\n",
      "0101426000.tif TOTAL WAGES PAID 12453094\n",
      "0495921000.tif TOTAL WAGES PAID 0\n",
      "0499771000.tif TOTAL WAGES PAID 6769873\n",
      "0498823000.tif TOTAL WAGES PAID 2250000\n",
      "0103998000.tif TOTAL WAGES PAID\n",
      "0502883000.tif TOTAL WAGES PAID 323990\n",
      "0101685000.tif TOTAL WAGES PAID 33048395\n",
      "0501239000.tif TOTAL WAGES PAID 42034488\n",
      "0109749000.tif TOTAL WAGES PAID 4316357\n",
      "0497277000.tif TOTAL WAGES PAID 801000\n",
      "0110182000.tif TOTAL WAGES PAID 0\n",
      "0495868000.tif TOTAL WAGES PAID 180000\n",
      "0495944000.tif TOTAL WAGES PAID 0\n",
      "0103379000.tif TOTAL WAGES PAID 0\n",
      "0110276000.tif TOTAL WAGES PAID 27526110\n",
      "0498322000.tif TOTAL WAGES PAID 837980\n",
      "0502465000.tif TOTAL WAGES PAID 13322100\n",
      "0500267000.tif TOTAL WAGES PAID 2900000\n",
      "0495949000.tif TOTAL WAGES PAID\n",
      "0495703000.tif TOTAL WAGES PAID 269834 Date Paid\n",
      "0110309000.tif TOTAL WAGES PAID 0\n",
      "0105862000.tif TOTAL WAGES PAID 3312100\n",
      "0101812000.tif TOTAL WAGES PAID 35095660\n",
      "0107523000.tif TOTAL WAGES PAID 39543721\n",
      "0501298000.tif TOTAL WAGES PAID\n",
      "0497041000.tif TOTAL WAGES PAID 0\n",
      "0101396000.tif TOTAL WAGES PAID 19502106\n",
      "0105901000.tif TOTAL WAGES PAID 2644981\n",
      "0102552000.tif TOTAL WAGES PAID 1000002\n",
      "0497812000.tif TOTAL WAGES PAID 3000000\n",
      "0499439000.tif TOTAL WAGES PAID 16943876\n",
      "0501668000.tif TOTAL WAGES PAID 49336484\n",
      "0109248000.tif TOTAL WAGES PAID 0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import sys\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import io \n",
    "import csv\n",
    "import pandas as pd\n",
    "import shutil, os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "    \n",
    "path = '/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input'\n",
    "for file_name in os.listdir(path):\n",
    "    #print(file_name)\n",
    "    shutil.copytree('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/sample', \n",
    "        os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                 os.path.splitext(file_name)[0]))\n",
    "     \n",
    "    img = mpimg.imread(os.path.join\n",
    "                       ('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input',\n",
    "                        file_name))\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    wi = width * 0.95\n",
    "    he = height * 0.3\n",
    "    w = int(wi)\n",
    "    h = int(he)\n",
    "    y = 0\n",
    "    x1 = w * 0.45\n",
    "    x = int(x1)\n",
    "    crop = img[y:y+h, x:x+w]\n",
    "    #plt.imshow(crop)\n",
    "    im = Image.fromarray(crop)\n",
    "    b = os.path.splitext(file_name)[0]+'_crop.jpeg'\n",
    "    im.save(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                           os.path.splitext(file_name)[0],'crop',b))\n",
    "    def extract_cell_images_from_table(image):\n",
    "        BLUR_KERNEL_SIZE = (17, 17)\n",
    "        STD_DEV_X_DIRECTION = 0\n",
    "        STD_DEV_Y_DIRECTION = 0\n",
    "        blurred = cv2.GaussianBlur(image, BLUR_KERNEL_SIZE, STD_DEV_X_DIRECTION, STD_DEV_Y_DIRECTION)\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~blurred,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "        vertical = horizontal = img_bin.copy()\n",
    "        SCALE = 5\n",
    "        image_width, image_height = horizontal.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(image_width / SCALE), 1))\n",
    "        horizontally_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(image_height / SCALE)))\n",
    "        vertically_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "\n",
    "        horizontally_dilated = cv2.dilate(horizontally_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1)))\n",
    "        vertically_dilated = cv2.dilate(vertically_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (1, 60)))\n",
    "\n",
    "        mask = horizontally_dilated + vertically_dilated\n",
    "        contours, heirarchy = cv2.findContours(\n",
    "            mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE,\n",
    "        )\n",
    "\n",
    "        perimeter_lengths = [cv2.arcLength(c, True) for c in contours]\n",
    "        epsilons = [0.05 * p for p in perimeter_lengths]\n",
    "        approx_polys = [cv2.approxPolyDP(c, e, True) for c, e in zip(contours, epsilons)]\n",
    "\n",
    "        # Filter out contours that aren't rectangular. Those that aren't rectangular\n",
    "        # are probably noise.\n",
    "        approx_rects = [p for p in approx_polys if len(p) == 4]\n",
    "        bounding_rects = [cv2.boundingRect(a) for a in approx_polys]\n",
    "\n",
    "        # Filter out rectangles that are too narrow or too short.\n",
    "        MIN_RECT_WIDTH = 40\n",
    "        MIN_RECT_HEIGHT = 10\n",
    "        bounding_rects = [\n",
    "            r for r in bounding_rects if MIN_RECT_WIDTH < r[2] and MIN_RECT_HEIGHT < r[3]\n",
    "        ]\n",
    "\n",
    "        # The largest bounding rectangle is assumed to be the entire table.\n",
    "        # Remove it from the list. We don't want to accidentally try to OCR\n",
    "        # the entire table.\n",
    "        largest_rect = max(bounding_rects, key=lambda r: r[2] * r[3])\n",
    "        bounding_rects = [b for b in bounding_rects if b is not largest_rect]\n",
    "\n",
    "        cells = [c for c in bounding_rects]\n",
    "        def cell_in_same_row(c1, c2):\n",
    "            c1_center = c1[1] + c1[3] - c1[3] / 2\n",
    "            c2_bottom = c2[1] + c2[3]\n",
    "            c2_top = c2[1]\n",
    "            return c2_top < c1_center < c2_bottom\n",
    "\n",
    "        orig_cells = [c for c in cells]\n",
    "        rows = []\n",
    "        while cells:\n",
    "            first = cells[0]\n",
    "            rest = cells[1:]\n",
    "            cells_in_same_row = sorted(\n",
    "                [\n",
    "                    c for c in rest\n",
    "                    if cell_in_same_row(c, first)\n",
    "                ],\n",
    "                key=lambda c: c[0]\n",
    "            )\n",
    "\n",
    "            row_cells = sorted([first] + cells_in_same_row, key=lambda c: c[0])\n",
    "            rows.append(row_cells)\n",
    "            cells = [\n",
    "                c for c in rest\n",
    "                if not cell_in_same_row(c, first)\n",
    "            ]\n",
    "\n",
    "        # Sort rows by average height of their center.\n",
    "        def avg_height_of_center(row):\n",
    "            centers = [y + h - h / 2 for x, y, w, h in row]\n",
    "            return sum(centers) / len(centers)\n",
    "\n",
    "        rows.sort(key=avg_height_of_center)\n",
    "        cell_images_rows = []\n",
    "        for row in rows:\n",
    "            cell_images_row = []\n",
    "            for x, y, w, h in row:\n",
    "                cell_images_row.append(image[y:y+h, x:x+w])\n",
    "            cell_images_rows.append(cell_images_row)\n",
    "        return cell_images_rows\n",
    "\n",
    "    def main(f):\n",
    "        results = []\n",
    "        directory, filename = os.path.split(f)\n",
    "        table = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        rows = extract_cell_images_from_table(table)\n",
    "        #cell_img_dir = os.path.join(directory, \"cells\")\n",
    "        #os.makedirs(cell_img_dir, exist_ok=True)\n",
    "        out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'cells')\n",
    "        paths = []\n",
    "        for i, row in enumerate(rows):\n",
    "            for j, cell in enumerate(row):\n",
    "                cell_filename = \"{:03d}-{:03d}.png\".format(i, j)\n",
    "                path = os.path.join(out_path, cell_filename)\n",
    "                cv2.imwrite(path, cell)\n",
    "                paths.append(path)\n",
    "        return paths\n",
    "\n",
    "    f = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                           os.path.splitext(file_name)[0],'crop',b)\n",
    "    main(f)\n",
    "    \n",
    "    def main(image_file, tess_args):\n",
    "        \"\"\"\n",
    "        OCR the image and output the text to a file with an extension that is ready\n",
    "        to be used in Tesseract training (.gt.txt).\n",
    "        Tries to crop the image so that only the relevant text gets passed to Tesseract.\n",
    "        Returns the name of the text file that contains the text.\n",
    "        \"\"\"\n",
    "        #file_path = '/home/vimal/Documents/table_detect_samples/structured images/input/011364700/cells'\n",
    "        #image_file = os.listdir(file_path)\n",
    "\n",
    "        for f in image_file:\n",
    "            #print(f)\n",
    "            directory, filename = os.path.split(f)\n",
    "            filename_sans_ext, ext = os.path.splitext(filename)\n",
    "            image = cv2.imread(os.path.join(file_path,f), cv2.IMREAD_GRAYSCALE)\n",
    "            cropped = crop_to_text(image)\n",
    "            #ocr_data_dir = os.path.join(directory, \"ocr_data\")\n",
    "            #os.makedirs(ocr_data_dir, exist_ok=True)\n",
    "            #out_imagepath = os.path.join(ocr_data_dir, filename)\n",
    "            out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'text')\n",
    "            out_txtpath = os.path.join(out_path, \"{}.txt\".format(filename_sans_ext))\n",
    "            #cv2.imwrite(out_imagepath, cropped)\n",
    "            if not tess_args:\n",
    "                d = os.path.dirname(sys.modules[\"table_ocr\"].__file__)\n",
    "                tessdata_dir = os.path.join(d, \"tessdata\")\n",
    "                tess_args = [\"--psm\", \"7\", \"-l\", \"table-ocr\", \"--tessdata-dir\", tessdata_dir]\n",
    "            txt = ocr_image(cropped, \" \".join(tess_args))\n",
    "            with open(out_txtpath, \"w\") as txt_file:\n",
    "                txt_file.write(txt)\n",
    "            #return out_txtpath\n",
    "    def crop_to_text(image):\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~image,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "\n",
    "        img_h, img_w = image.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(img_w * 0.5), 1))\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(img_h * 0.7)))\n",
    "        horizontal_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "        both = horizontal_lines + vertical_lines\n",
    "        cleaned = img_bin - both\n",
    "\n",
    "        # Get rid of little noise.\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        opened = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)\n",
    "        opened = cv2.dilate(opened, kernel)\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(opened, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        bounding_rects = [cv2.boundingRect(c) for c in contours]\n",
    "        NUM_PX_COMMA = 6\n",
    "        MIN_CHAR_AREA = 5 * 9\n",
    "        char_sized_bounding_rects = [(x, y, w, h) for x, y, w, h in bounding_rects if w * h > MIN_CHAR_AREA]\n",
    "        if char_sized_bounding_rects:\n",
    "            minx, miny, maxx, maxy = math.inf, math.inf, 0, 0\n",
    "            for x, y, w, h in char_sized_bounding_rects:\n",
    "                minx = min(minx, x)\n",
    "                miny = min(miny, y)\n",
    "                maxx = max(maxx, x + w)\n",
    "                maxy = max(maxy, y + h)\n",
    "            x, y, w, h = minx, miny, maxx - minx, maxy - miny\n",
    "            cropped = image[y:min(img_h, y+h+NUM_PX_COMMA), x:min(img_w, x+w)]\n",
    "        else:\n",
    "            # If we morphed out all of the text, assume an empty image.\n",
    "            cropped = MAX_COLOR_VAL * np.ones(shape=(20, 100), dtype=np.uint8)\n",
    "        bordered = cv2.copyMakeBorder(cropped, 5, 5, 5, 5, cv2.BORDER_CONSTANT, None, 255)\n",
    "        return bordered\n",
    "    def ocr_image(image, config):\n",
    "        return pytesseract.image_to_string(\n",
    "            image,\n",
    "            lang='eng', config='--psm 6'\n",
    "        )\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'cells')\n",
    "    image_file = os.listdir(file_path)\n",
    "    tess_args = os.listdir(file_path)\n",
    "\n",
    "    main(image_file, tess_args)\n",
    "    \n",
    "    def text_files_to_csv(files):\n",
    "        \"\"\"Files must be sorted lexicographically\n",
    "        Filenames must be <row>-<colum>.txt.\n",
    "        000-000.txt\n",
    "        000-001.txt\n",
    "        001-000.txt\n",
    "        etc...\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        for f in files:\n",
    "            directory, filename = os.path.split(f)\n",
    "            with open(os.path.join(file_path,f)) as of:\n",
    "                txt = of.read().strip()\n",
    "            row, column = map(int, filename.split(\".\")[0].split(\"-\"))\n",
    "            if row == len(rows):\n",
    "                rows.append([])\n",
    "            rows[row].append(txt)\n",
    "\n",
    "        csv_file = io.StringIO()\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerows(rows)\n",
    "        return csv_file.getvalue()\n",
    "\n",
    "    def main(files):\n",
    "        return text_files_to_csv(files)\n",
    "\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'text')\n",
    "    file = os.listdir(file_path)\n",
    "    files = sorted(file)\n",
    "\n",
    "    a = main(files)\n",
    "    #print(a)\n",
    "\n",
    "    c = os.path.splitext(file_name)[0]+'_text.txt'\n",
    "    t = os.path.splitext(file_name)[0]+'_f-text.txt'\n",
    "\n",
    "    #cs = os.path.splitext(file_name)[0]+'_xl.csv'\n",
    "\n",
    "    text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'txt',c), \"wt\")\n",
    "    n = text_file.write(a)\n",
    "    text_file.close()\n",
    "\n",
    "    df = pd.read_csv(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'txt',c),\n",
    "        header=None,delimiter=',',names=list(range(10)))\n",
    "    \n",
    "    if df[0].dtypes != 'object':\n",
    "        print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',0)\n",
    "    else:\n",
    "        df1 = df[df[0].str.contains('TOTAL WAGES PAID') | df[0].str.contains('total wages paid')\n",
    "                                 | df[0].str.contains('Total wages paid')]\n",
    "        final = df1.dropna(axis=1)\n",
    "        final = final.astype(str)\n",
    "        #print(final)\n",
    "        final[0] = final[0].str.replace('\\d+','') \n",
    "        final[0] = final[0].str.replace(r'[^\\w\\s]+', '')\n",
    "        final[0] = final[0].str.replace('\\d+', '')\n",
    "        final[0] = final[0].str.strip()\n",
    "        \n",
    "        if final.shape[1]>1:\n",
    "            final[1] = final[1].str.replace(r'[^\\w\\s]+', '')\n",
    "            final[1] = final[1].str.replace(\" \",\"\")\n",
    "\n",
    "        #print(final)\n",
    "        if len(final) == 0:\n",
    "            print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',0)\n",
    "        else:       \n",
    "            with open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'final_text',t), 'a') as f:\n",
    "                f.write(final.to_string(header = False, index = False))\n",
    "            text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'final_text',t), 'r+')\n",
    "            print(os.path.splitext(file_name)[0]+'.tif',text_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af66477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade9119c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e025d46f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd60c82b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b70203e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866b94cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308844b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeade57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f648a9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46973f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1b79a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66164aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad620d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe8b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5168c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f78ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7f849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621adaf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4776d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e8b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51861495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a63d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13866bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eaa840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe52c1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "b0dbe3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twp(file_name):\n",
    "    import matplotlib.image as mpimg\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    import cv2\n",
    "    import os\n",
    "    import math\n",
    "    import sys\n",
    "    import numpy as np\n",
    "    import pytesseract\n",
    "    import io \n",
    "    import csv\n",
    "    import pandas as pd\n",
    "    import shutil, os\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    #file_name = '0100477000.jpeg'\n",
    "\n",
    "    #path = '/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input'\n",
    "    #for file_name in os.listdir(path):\n",
    "        #print(file_name)\n",
    "    shutil.copytree('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/sample', \n",
    "        os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                 os.path.splitext(file_name)[0]))\n",
    "     \n",
    "    img = mpimg.imread(os.path.join\n",
    "                       ('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input',\n",
    "                        file_name))\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    wi = width * 0.95\n",
    "    he = height * 0.3\n",
    "    w = int(wi)\n",
    "    h = int(he)\n",
    "    y = 0\n",
    "    x1 = w * 0.45\n",
    "    x = int(x1)\n",
    "    crop = img[y:y+h, x:x+w]\n",
    "    #plt.imshow(crop)\n",
    "    im = Image.fromarray(crop)\n",
    "    b = os.path.splitext(file_name)[0]+'_crop.jpeg'\n",
    "    im.save(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                           os.path.splitext(file_name)[0],'crop',b))\n",
    "    def extract_cell_images_from_table(image):\n",
    "        BLUR_KERNEL_SIZE = (17, 17)\n",
    "        STD_DEV_X_DIRECTION = 0\n",
    "        STD_DEV_Y_DIRECTION = 0\n",
    "        blurred = cv2.GaussianBlur(image, BLUR_KERNEL_SIZE, STD_DEV_X_DIRECTION, STD_DEV_Y_DIRECTION)\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~blurred,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "        vertical = horizontal = img_bin.copy()\n",
    "        SCALE = 5\n",
    "        image_width, image_height = horizontal.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(image_width / SCALE), 1))\n",
    "        horizontally_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(image_height / SCALE)))\n",
    "        vertically_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "\n",
    "        horizontally_dilated = cv2.dilate(horizontally_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1)))\n",
    "        vertically_dilated = cv2.dilate(vertically_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (1, 60)))\n",
    "\n",
    "        mask = horizontally_dilated + vertically_dilated\n",
    "        contours, heirarchy = cv2.findContours(\n",
    "            mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE,\n",
    "        )\n",
    "\n",
    "        perimeter_lengths = [cv2.arcLength(c, True) for c in contours]\n",
    "        epsilons = [0.05 * p for p in perimeter_lengths]\n",
    "        approx_polys = [cv2.approxPolyDP(c, e, True) for c, e in zip(contours, epsilons)]\n",
    "\n",
    "        # Filter out contours that aren't rectangular. Those that aren't rectangular\n",
    "        # are probably noise.\n",
    "        approx_rects = [p for p in approx_polys if len(p) == 4]\n",
    "        bounding_rects = [cv2.boundingRect(a) for a in approx_polys]\n",
    "\n",
    "        # Filter out rectangles that are too narrow or too short.\n",
    "        MIN_RECT_WIDTH = 40\n",
    "        MIN_RECT_HEIGHT = 10\n",
    "        bounding_rects = [\n",
    "            r for r in bounding_rects if MIN_RECT_WIDTH < r[2] and MIN_RECT_HEIGHT < r[3]\n",
    "        ]\n",
    "\n",
    "        # The largest bounding rectangle is assumed to be the entire table.\n",
    "        # Remove it from the list. We don't want to accidentally try to OCR\n",
    "        # the entire table.\n",
    "        largest_rect = max(bounding_rects, key=lambda r: r[2] * r[3])\n",
    "        bounding_rects = [b for b in bounding_rects if b is not largest_rect]\n",
    "\n",
    "        cells = [c for c in bounding_rects]\n",
    "        def cell_in_same_row(c1, c2):\n",
    "            c1_center = c1[1] + c1[3] - c1[3] / 2\n",
    "            c2_bottom = c2[1] + c2[3]\n",
    "            c2_top = c2[1]\n",
    "            return c2_top < c1_center < c2_bottom\n",
    "\n",
    "        orig_cells = [c for c in cells]\n",
    "        rows = []\n",
    "        while cells:\n",
    "            first = cells[0]\n",
    "            rest = cells[1:]\n",
    "            cells_in_same_row = sorted(\n",
    "                [\n",
    "                    c for c in rest\n",
    "                    if cell_in_same_row(c, first)\n",
    "                ],\n",
    "                key=lambda c: c[0]\n",
    "            )\n",
    "\n",
    "            row_cells = sorted([first] + cells_in_same_row, key=lambda c: c[0])\n",
    "            rows.append(row_cells)\n",
    "            cells = [\n",
    "                c for c in rest\n",
    "                if not cell_in_same_row(c, first)\n",
    "            ]\n",
    "\n",
    "        # Sort rows by average height of their center.\n",
    "        def avg_height_of_center(row):\n",
    "            centers = [y + h - h / 2 for x, y, w, h in row]\n",
    "            return sum(centers) / len(centers)\n",
    "\n",
    "        rows.sort(key=avg_height_of_center)\n",
    "        cell_images_rows = []\n",
    "        for row in rows:\n",
    "            cell_images_row = []\n",
    "            for x, y, w, h in row:\n",
    "                cell_images_row.append(image[y:y+h, x:x+w])\n",
    "            cell_images_rows.append(cell_images_row)\n",
    "        return cell_images_rows\n",
    "\n",
    "    def main(f):\n",
    "        results = []\n",
    "        directory, filename = os.path.split(f)\n",
    "        table = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        rows = extract_cell_images_from_table(table)\n",
    "        #cell_img_dir = os.path.join(directory, \"cells\")\n",
    "        #os.makedirs(cell_img_dir, exist_ok=True)\n",
    "        out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'cells')\n",
    "        paths = []\n",
    "        for i, row in enumerate(rows):\n",
    "            for j, cell in enumerate(row):\n",
    "                cell_filename = \"{:03d}-{:03d}.png\".format(i, j)\n",
    "                path = os.path.join(out_path, cell_filename)\n",
    "                cv2.imwrite(path, cell)\n",
    "                paths.append(path)\n",
    "        return paths\n",
    "\n",
    "    f = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                           os.path.splitext(file_name)[0],'crop',b)\n",
    "    main(f)\n",
    "    \n",
    "    def main(image_file, tess_args):\n",
    "        \"\"\"\n",
    "        OCR the image and output the text to a file with an extension that is ready\n",
    "        to be used in Tesseract training (.gt.txt).\n",
    "        Tries to crop the image so that only the relevant text gets passed to Tesseract.\n",
    "        Returns the name of the text file that contains the text.\n",
    "        \"\"\"\n",
    "        #file_path = '/home/vimal/Documents/table_detect_samples/structured images/input/011364700/cells'\n",
    "        #image_file = os.listdir(file_path)\n",
    "\n",
    "        for f in image_file:\n",
    "            #print(f)\n",
    "            directory, filename = os.path.split(f)\n",
    "            filename_sans_ext, ext = os.path.splitext(filename)\n",
    "            image = cv2.imread(os.path.join(file_path,f), cv2.IMREAD_GRAYSCALE)\n",
    "            cropped = crop_to_text(image)\n",
    "            #ocr_data_dir = os.path.join(directory, \"ocr_data\")\n",
    "            #os.makedirs(ocr_data_dir, exist_ok=True)\n",
    "            #out_imagepath = os.path.join(ocr_data_dir, filename)\n",
    "            out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'text')\n",
    "            out_txtpath = os.path.join(out_path, \"{}.txt\".format(filename_sans_ext))\n",
    "            #cv2.imwrite(out_imagepath, cropped)\n",
    "            if not tess_args:\n",
    "                d = os.path.dirname(sys.modules[\"table_ocr\"].__file__)\n",
    "                tessdata_dir = os.path.join(d, \"tessdata\")\n",
    "                tess_args = [\"--psm\", \"7\", \"-l\", \"table-ocr\", \"--tessdata-dir\", tessdata_dir]\n",
    "            txt = ocr_image(cropped, \" \".join(tess_args))\n",
    "            with open(out_txtpath, \"w\") as txt_file:\n",
    "                txt_file.write(txt)\n",
    "            #return out_txtpath\n",
    "    def crop_to_text(image):\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~image,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "\n",
    "        img_h, img_w = image.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(img_w * 0.5), 1))\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(img_h * 0.7)))\n",
    "        horizontal_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "        both = horizontal_lines + vertical_lines\n",
    "        cleaned = img_bin - both\n",
    "\n",
    "        # Get rid of little noise.\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        opened = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)\n",
    "        opened = cv2.dilate(opened, kernel)\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(opened, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        bounding_rects = [cv2.boundingRect(c) for c in contours]\n",
    "        NUM_PX_COMMA = 6\n",
    "        MIN_CHAR_AREA = 5 * 9\n",
    "        char_sized_bounding_rects = [(x, y, w, h) for x, y, w, h in bounding_rects if w * h > MIN_CHAR_AREA]\n",
    "        if char_sized_bounding_rects:\n",
    "            minx, miny, maxx, maxy = math.inf, math.inf, 0, 0\n",
    "            for x, y, w, h in char_sized_bounding_rects:\n",
    "                minx = min(minx, x)\n",
    "                miny = min(miny, y)\n",
    "                maxx = max(maxx, x + w)\n",
    "                maxy = max(maxy, y + h)\n",
    "            x, y, w, h = minx, miny, maxx - minx, maxy - miny\n",
    "            cropped = image[y:min(img_h, y+h+NUM_PX_COMMA), x:min(img_w, x+w)]\n",
    "        else:\n",
    "            # If we morphed out all of the text, assume an empty image.\n",
    "            cropped = MAX_COLOR_VAL * np.ones(shape=(20, 100), dtype=np.uint8)\n",
    "        bordered = cv2.copyMakeBorder(cropped, 5, 5, 5, 5, cv2.BORDER_CONSTANT, None, 255)\n",
    "        return bordered\n",
    "    def ocr_image(image, config):\n",
    "        return pytesseract.image_to_string(\n",
    "            image,\n",
    "            lang='eng', config='--psm 6'\n",
    "        )\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'cells')\n",
    "    image_file = os.listdir(file_path)\n",
    "    tess_args = os.listdir(file_path)\n",
    "\n",
    "    main(image_file, tess_args)\n",
    "    \n",
    "    def text_files_to_csv(files):\n",
    "        \"\"\"Files must be sorted lexicographically\n",
    "        Filenames must be <row>-<colum>.txt.\n",
    "        000-000.txt\n",
    "        000-001.txt\n",
    "        001-000.txt\n",
    "        etc...\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        for f in files:\n",
    "            directory, filename = os.path.split(f)\n",
    "            with open(os.path.join(file_path,f)) as of:\n",
    "                txt = of.read().strip()\n",
    "            row, column = map(int, filename.split(\".\")[0].split(\"-\"))\n",
    "            if row == len(rows):\n",
    "                rows.append([])\n",
    "            rows[row].append(txt)\n",
    "\n",
    "        csv_file = io.StringIO()\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerows(rows)\n",
    "        return csv_file.getvalue()\n",
    "\n",
    "    def main(files):\n",
    "        return text_files_to_csv(files)\n",
    "\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'text')\n",
    "    file = os.listdir(file_path)\n",
    "    files = sorted(file)\n",
    "\n",
    "    a = main(files)\n",
    "    #print(a)\n",
    "\n",
    "    c = os.path.splitext(file_name)[0]+'_text.txt'\n",
    "    t = os.path.splitext(file_name)[0]+'_f-text.txt'\n",
    "\n",
    "    #cs = os.path.splitext(file_name)[0]+'_xl.csv'\n",
    "\n",
    "    text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'txt',c), \"wt\")\n",
    "    n = text_file.write(a)\n",
    "    text_file.close()\n",
    "\n",
    "    df = pd.read_csv(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'txt',c),\n",
    "        header=None,delimiter=',',names=list(range(10)))\n",
    "    #print(df)\n",
    "    \n",
    "    df1 = df.dropna(axis = 0,how = 'all')\n",
    "    #print(df1)\n",
    "    \n",
    "    word = 'TOTAL WAGES PAID'\n",
    "    \n",
    "        \n",
    "    \n",
    "    if df1[0].dtypes != 'object':\n",
    "        print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',0)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        for i in df1[0]:\n",
    "            if fuzz.ratio(word,i) > 80:\n",
    "                #print(i)\n",
    "                dff = df1[df1[0] == i]\n",
    "                dff = dff.dropna(axis = 1,how = 'all')\n",
    "                output = dff[1]\n",
    "                output = output.str.replace(r'[^\\w\\s]+', '')\n",
    "                output = output.str.replace(\" \",\"\")\n",
    "                #print(output)\n",
    "                if len(output) == 0:\n",
    "                    print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',0)\n",
    "                else:\n",
    "                    with open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                            os.path.splitext(file_name)[0],'final_text',t), 'a') as f:\n",
    "                        f.write(output.to_string(header = False, index = False))\n",
    "                    text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                            os.path.splitext(file_name)[0],'final_text',t), 'r+')\n",
    "                    print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',text_file.read())\n",
    "        \n",
    "                \n",
    "                \n",
    "    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "5aafc7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0497041000.tif TOTAL WAGES PAID 1150000\n"
     ]
    }
   ],
   "source": [
    "file_name = '0497041000.jpeg'\n",
    "twp(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "334c6e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    907.54\n",
      "Name: 1, dtype: object\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-4f069bf0560f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[ ,.#*!@$%^&()|\\''\"\u001b[0m\u001b[0;34m\":;]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m             \u001b[0;31m#print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "    import matplotlib.image as mpimg\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    import cv2\n",
    "    import os\n",
    "    import math\n",
    "    import sys\n",
    "    import numpy as np\n",
    "    import pytesseract\n",
    "    import io \n",
    "    import csv\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    import shutil, os\n",
    "    from fuzzywuzzy import fuzz\n",
    "    from fuzzywuzzy import process\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    file_name = '0500847001.jpeg'\n",
    "\n",
    "#path = '/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input'\n",
    "#for file_name in os.listdir(path):\n",
    "    #print(file_name)\n",
    "    shutil.copytree('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/sample', \n",
    "        os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                 os.path.splitext(file_name)[0]))\n",
    "     \n",
    "    img = mpimg.imread(os.path.join\n",
    "                       ('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input',\n",
    "                        file_name))\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    wi = width * 0.95\n",
    "    he = height * 0.3\n",
    "    w = int(wi)\n",
    "    h = int(he)\n",
    "    y = 0\n",
    "    x1 = w * 0.45\n",
    "    x = int(x1)\n",
    "    crop = img[y:y+h, x:x+w]\n",
    "    #plt.imshow(crop)\n",
    "    im = Image.fromarray(crop)\n",
    "    b = os.path.splitext(file_name)[0]+'_crop.jpeg'\n",
    "    im.save(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                           os.path.splitext(file_name)[0],'crop',b))\n",
    "    def extract_cell_images_from_table(image):\n",
    "        BLUR_KERNEL_SIZE = (17, 17)\n",
    "        STD_DEV_X_DIRECTION = 0\n",
    "        STD_DEV_Y_DIRECTION = 0\n",
    "        blurred = cv2.GaussianBlur(image, BLUR_KERNEL_SIZE, STD_DEV_X_DIRECTION, STD_DEV_Y_DIRECTION)\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~blurred,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "        vertical = horizontal = img_bin.copy()\n",
    "        SCALE = 5\n",
    "        image_width, image_height = horizontal.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(image_width / SCALE), 1))\n",
    "        horizontally_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(image_height / SCALE)))\n",
    "        vertically_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "\n",
    "        horizontally_dilated = cv2.dilate(horizontally_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1)))\n",
    "        vertically_dilated = cv2.dilate(vertically_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (1, 60)))\n",
    "\n",
    "        mask = horizontally_dilated + vertically_dilated\n",
    "        contours, heirarchy = cv2.findContours(\n",
    "            mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE,\n",
    "        )\n",
    "\n",
    "        perimeter_lengths = [cv2.arcLength(c, True) for c in contours]\n",
    "        epsilons = [0.05 * p for p in perimeter_lengths]\n",
    "        approx_polys = [cv2.approxPolyDP(c, e, True) for c, e in zip(contours, epsilons)]\n",
    "\n",
    "        # Filter out contours that aren't rectangular. Those that aren't rectangular\n",
    "        # are probably noise.\n",
    "        approx_rects = [p for p in approx_polys if len(p) == 4]\n",
    "        bounding_rects = [cv2.boundingRect(a) for a in approx_polys]\n",
    "\n",
    "        # Filter out rectangles that are too narrow or too short.\n",
    "        MIN_RECT_WIDTH = 40\n",
    "        MIN_RECT_HEIGHT = 10\n",
    "        bounding_rects = [\n",
    "            r for r in bounding_rects if MIN_RECT_WIDTH < r[2] and MIN_RECT_HEIGHT < r[3]\n",
    "        ]\n",
    "\n",
    "        # The largest bounding rectangle is assumed to be the entire table.\n",
    "        # Remove it from the list. We don't want to accidentally try to OCR\n",
    "        # the entire table.\n",
    "        largest_rect = max(bounding_rects, key=lambda r: r[2] * r[3])\n",
    "        bounding_rects = [b for b in bounding_rects if b is not largest_rect]\n",
    "\n",
    "        cells = [c for c in bounding_rects]\n",
    "        def cell_in_same_row(c1, c2):\n",
    "            c1_center = c1[1] + c1[3] - c1[3] / 2\n",
    "            c2_bottom = c2[1] + c2[3]\n",
    "            c2_top = c2[1]\n",
    "            return c2_top < c1_center < c2_bottom\n",
    "\n",
    "        orig_cells = [c for c in cells]\n",
    "        rows = []\n",
    "        while cells:\n",
    "            first = cells[0]\n",
    "            rest = cells[1:]\n",
    "            cells_in_same_row = sorted(\n",
    "                [\n",
    "                    c for c in rest\n",
    "                    if cell_in_same_row(c, first)\n",
    "                ],\n",
    "                key=lambda c: c[0]\n",
    "            )\n",
    "\n",
    "            row_cells = sorted([first] + cells_in_same_row, key=lambda c: c[0])\n",
    "            rows.append(row_cells)\n",
    "            cells = [\n",
    "                c for c in rest\n",
    "                if not cell_in_same_row(c, first)\n",
    "            ]\n",
    "\n",
    "        # Sort rows by average height of their center.\n",
    "        def avg_height_of_center(row):\n",
    "            centers = [y + h - h / 2 for x, y, w, h in row]\n",
    "            return sum(centers) / len(centers)\n",
    "\n",
    "        rows.sort(key=avg_height_of_center)\n",
    "        cell_images_rows = []\n",
    "        for row in rows:\n",
    "            cell_images_row = []\n",
    "            for x, y, w, h in row:\n",
    "                cell_images_row.append(image[y:y+h, x:x+w])\n",
    "            cell_images_rows.append(cell_images_row)\n",
    "        return cell_images_rows\n",
    "\n",
    "    def main(f):\n",
    "        results = []\n",
    "        directory, filename = os.path.split(f)\n",
    "        table = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        rows = extract_cell_images_from_table(table)\n",
    "        #cell_img_dir = os.path.join(directory, \"cells\")\n",
    "        #os.makedirs(cell_img_dir, exist_ok=True)\n",
    "        out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'cells')\n",
    "        paths = []\n",
    "        for i, row in enumerate(rows):\n",
    "            for j, cell in enumerate(row):\n",
    "                cell_filename = \"{:03d}-{:03d}.png\".format(i, j)\n",
    "                path = os.path.join(out_path, cell_filename)\n",
    "                cv2.imwrite(path, cell)\n",
    "                paths.append(path)\n",
    "        return paths\n",
    "\n",
    "    f = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                           os.path.splitext(file_name)[0],'crop',b)\n",
    "    main(f)\n",
    "    \n",
    "    def main(image_file, tess_args):\n",
    "        \"\"\"\n",
    "        OCR the image and output the text to a file with an extension that is ready\n",
    "        to be used in Tesseract training (.gt.txt).\n",
    "        Tries to crop the image so that only the relevant text gets passed to Tesseract.\n",
    "        Returns the name of the text file that contains the text.\n",
    "        \"\"\"\n",
    "        #file_path = '/home/vimal/Documents/table_detect_samples/structured images/input/011364700/cells'\n",
    "        #image_file = os.listdir(file_path)\n",
    "\n",
    "        for f in image_file:\n",
    "            #print(f)\n",
    "            directory, filename = os.path.split(f)\n",
    "            filename_sans_ext, ext = os.path.splitext(filename)\n",
    "            image = cv2.imread(os.path.join(file_path,f), cv2.IMREAD_GRAYSCALE)\n",
    "            cropped = crop_to_text(image)\n",
    "            #ocr_data_dir = os.path.join(directory, \"ocr_data\")\n",
    "            #os.makedirs(ocr_data_dir, exist_ok=True)\n",
    "            #out_imagepath = os.path.join(ocr_data_dir, filename)\n",
    "            out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'text')\n",
    "            out_txtpath = os.path.join(out_path, \"{}.txt\".format(filename_sans_ext))\n",
    "            #cv2.imwrite(out_imagepath, cropped)\n",
    "            if not tess_args:\n",
    "                d = os.path.dirname(sys.modules[\"table_ocr\"].__file__)\n",
    "                tessdata_dir = os.path.join(d, \"tessdata\")\n",
    "                tess_args = [\"--psm\", \"7\", \"-l\", \"table-ocr\", \"--tessdata-dir\", tessdata_dir]\n",
    "            txt = ocr_image(cropped, \" \".join(tess_args))\n",
    "            with open(out_txtpath, \"w\") as txt_file:\n",
    "                txt_file.write(txt)\n",
    "            #return out_txtpath\n",
    "    def crop_to_text(image):\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~image,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "\n",
    "        img_h, img_w = image.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(img_w * 0.5), 1))\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(img_h * 0.7)))\n",
    "        horizontal_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "        both = horizontal_lines + vertical_lines\n",
    "        cleaned = img_bin - both\n",
    "\n",
    "        # Get rid of little noise.\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        opened = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)\n",
    "        opened = cv2.dilate(opened, kernel)\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(opened, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        bounding_rects = [cv2.boundingRect(c) for c in contours]\n",
    "        NUM_PX_COMMA = 6\n",
    "        MIN_CHAR_AREA = 5 * 9\n",
    "        char_sized_bounding_rects = [(x, y, w, h) for x, y, w, h in bounding_rects if w * h > MIN_CHAR_AREA]\n",
    "        if char_sized_bounding_rects:\n",
    "            minx, miny, maxx, maxy = math.inf, math.inf, 0, 0\n",
    "            for x, y, w, h in char_sized_bounding_rects:\n",
    "                minx = min(minx, x)\n",
    "                miny = min(miny, y)\n",
    "                maxx = max(maxx, x + w)\n",
    "                maxy = max(maxy, y + h)\n",
    "            x, y, w, h = minx, miny, maxx - minx, maxy - miny\n",
    "            cropped = image[y:min(img_h, y+h+NUM_PX_COMMA), x:min(img_w, x+w)]\n",
    "        else:\n",
    "            # If we morphed out all of the text, assume an empty image.\n",
    "            cropped = MAX_COLOR_VAL * np.ones(shape=(20, 100), dtype=np.uint8)\n",
    "        bordered = cv2.copyMakeBorder(cropped, 5, 5, 5, 5, cv2.BORDER_CONSTANT, None, 255)\n",
    "        return bordered\n",
    "    def ocr_image(image, config):\n",
    "        return pytesseract.image_to_string(\n",
    "            image,\n",
    "            lang='eng', config='--psm 6'\n",
    "        )\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'cells')\n",
    "    image_file = os.listdir(file_path)\n",
    "    tess_args = os.listdir(file_path)\n",
    "\n",
    "    main(image_file, tess_args)\n",
    "    \n",
    "    def text_files_to_csv(files):\n",
    "        \"\"\"Files must be sorted lexicographically\n",
    "        Filenames must be <row>-<colum>.txt.\n",
    "        000-000.txt\n",
    "        000-001.txt\n",
    "        001-000.txt\n",
    "        etc...\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        for f in files:\n",
    "            directory, filename = os.path.split(f)\n",
    "            with open(os.path.join(file_path,f)) as of:\n",
    "                txt = of.read().strip()\n",
    "            row, column = map(int, filename.split(\".\")[0].split(\"-\"))\n",
    "            if row == len(rows):\n",
    "                rows.append([])\n",
    "            rows[row].append(txt)\n",
    "\n",
    "        csv_file = io.StringIO()\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerows(rows)\n",
    "        return csv_file.getvalue()\n",
    "\n",
    "    def main(files):\n",
    "        return text_files_to_csv(files)\n",
    "\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'text')\n",
    "    file = os.listdir(file_path)\n",
    "    files = sorted(file)\n",
    "\n",
    "    a = main(files)\n",
    "    #print(a)\n",
    "\n",
    "    c = os.path.splitext(file_name)[0]+'_text.txt'\n",
    "    t = os.path.splitext(file_name)[0]+'_f-text.txt'\n",
    "\n",
    "    #cs = os.path.splitext(file_name)[0]+'_xl.csv'\n",
    "\n",
    "    text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'txt',c), \"wt\")\n",
    "    n = text_file.write(a)\n",
    "    text_file.close()\n",
    "\n",
    "    df = pd.read_csv(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'txt',c),\n",
    "        header=None,delimiter=',',names=list(range(10)))\n",
    "    #print(df)\n",
    "    \n",
    "    df1 = df.dropna(axis = 0,how = 'all')\n",
    "    df1[1] = df1[1].astype(str)\n",
    "\n",
    "    #print(df1)\n",
    "    \n",
    "    word = 'TOTAL WAGES PAID'\n",
    "    \n",
    "        \n",
    "    \n",
    "    if df_drop[0].dtypes != 'object':\n",
    "        print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',0)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        for i in df1[0]:\n",
    "            if fuzz.ratio(word,i) > 80:\n",
    "                #print(i)\n",
    "                dff = df1[df1[0] == i]\n",
    "                dff = dff.dropna(axis = 1,how = 'all')\n",
    "                output = dff[1]\n",
    "                print(output)\n",
    "                output = re.sub(\"[ ,.#*!@$%^&()|\\''\"\":;]\", \"\", output)\n",
    "                #print(output)\n",
    "                if len(output) == 0:\n",
    "                    print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',0)\n",
    "                else:\n",
    "                    with open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                            os.path.splitext(file_name)[0],'final_text',t), 'a') as f:\n",
    "                        f.write(output.to_string(header = False, index = False))\n",
    "                    text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                            os.path.splitext(file_name)[0],'final_text',t), 'r+')\n",
    "                    print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',text_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e115c354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 MO EMPLOYER ACCOUNT NO YEAR\\n\\nae : 5 Ah 202...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUST HAVE AMOUNTS IN 4, 5, &amp; 6, EVEN IF ZERO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 TOTAL WAGES PAID</td>\n",
       "      <td>907.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 WAGES PAID IN EXCESS OF\\nPER WORKER\\nPER YEA...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0       1   2   3   4   5  \\\n",
       "0  2 MO EMPLOYER ACCOUNT NO YEAR\\n\\nae : 5 Ah 202...     NaN NaN NaN NaN NaN   \n",
       "1       MUST HAVE AMOUNTS IN 4, 5, & 6, EVEN IF ZERO     NaN NaN NaN NaN NaN   \n",
       "2                                 4 TOTAL WAGES PAID  907.54 NaN NaN NaN NaN   \n",
       "3  5 WAGES PAID IN EXCESS OF\\nPER WORKER\\nPER YEA...    0.00 NaN NaN NaN NaN   \n",
       "\n",
       "    6   7   8   9  \n",
       "0 NaN NaN NaN NaN  \n",
       "1 NaN NaN NaN NaN  \n",
       "2 NaN NaN NaN NaN  \n",
       "3 NaN NaN NaN NaN  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e53b2576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       4 non-null      object \n",
      " 1   1       2 non-null      float64\n",
      " 2   2       0 non-null      float64\n",
      " 3   3       0 non-null      float64\n",
      " 4   4       0 non-null      float64\n",
      " 5   5       0 non-null      float64\n",
      " 6   6       0 non-null      float64\n",
      " 7   7       0 non-null      float64\n",
      " 8   8       0 non-null      float64\n",
      " 9   9       0 non-null      float64\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 448.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ce3f455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 MO EMPLOYER ACCOUNT NO YEAR\\n\\nae : 5 Ah 202...</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUST HAVE AMOUNTS IN 4, 5, &amp; 6, EVEN IF ZERO</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 TOTAL WAGES PAID</td>\n",
       "      <td>907.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 WAGES PAID IN EXCESS OF\\nPER WORKER\\nPER YEA...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0       1   2   3   4   5  \\\n",
       "0  2 MO EMPLOYER ACCOUNT NO YEAR\\n\\nae : 5 Ah 202...     nan NaN NaN NaN NaN   \n",
       "1       MUST HAVE AMOUNTS IN 4, 5, & 6, EVEN IF ZERO     nan NaN NaN NaN NaN   \n",
       "2                                 4 TOTAL WAGES PAID  907.54 NaN NaN NaN NaN   \n",
       "3  5 WAGES PAID IN EXCESS OF\\nPER WORKER\\nPER YEA...     0.0 NaN NaN NaN NaN   \n",
       "\n",
       "    6   7   8   9  \n",
       "0 NaN NaN NaN NaN  \n",
       "1 NaN NaN NaN NaN  \n",
       "2 NaN NaN NaN NaN  \n",
       "3 NaN NaN NaN NaN  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2e4181b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4 entries, 0 to 3\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       4 non-null      object \n",
      " 1   1       4 non-null      object \n",
      " 2   2       0 non-null      float64\n",
      " 3   3       0 non-null      float64\n",
      " 4   4       0 non-null      float64\n",
      " 5   5       0 non-null      float64\n",
      " 6   6       0 non-null      float64\n",
      " 7   7       0 non-null      float64\n",
      " 8   8       0 non-null      float64\n",
      " 9   9       0 non-null      float64\n",
      "dtypes: float64(8), object(2)\n",
      "memory usage: 352.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd17b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1] = df[1].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8de0f84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 MO EMPLOYER ACCOUNT NO YEAR\\n\\nae : 5 Ah 202...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUST HAVE AMOUNTS IN 4, 5, &amp; 6, EVEN IF ZERO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 TOTAL WAGES PAID</td>\n",
       "      <td>907.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 WAGES PAID IN EXCESS OF\\nPER WORKER\\nPER YEA...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0       1   2   3   4   5  \\\n",
       "0  2 MO EMPLOYER ACCOUNT NO YEAR\\n\\nae : 5 Ah 202...     NaN NaN NaN NaN NaN   \n",
       "1       MUST HAVE AMOUNTS IN 4, 5, & 6, EVEN IF ZERO     NaN NaN NaN NaN NaN   \n",
       "2                                 4 TOTAL WAGES PAID  907.54 NaN NaN NaN NaN   \n",
       "3  5 WAGES PAID IN EXCESS OF\\nPER WORKER\\nPER YEA...    0.00 NaN NaN NaN NaN   \n",
       "\n",
       "    6   7   8   9  \n",
       "0 NaN NaN NaN NaN  \n",
       "1 NaN NaN NaN NaN  \n",
       "2 NaN NaN NaN NaN  \n",
       "3 NaN NaN NaN NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.dropna(axis = 0,how = 'all')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5990a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    907.54\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in df1[0]:\n",
    "            if fuzz.ratio(word,i) > 80:\n",
    "                #print(i)\n",
    "                dff = df1[df1[0] == i]\n",
    "                dff = dff.dropna(axis = 1,how = 'all')\n",
    "                output = (dff[1])\n",
    "                print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49ff8a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    907.54\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc40a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c78605eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = output.reset_index(drop=True, inplace=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22afeddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32ef06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79ffcac0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'style'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-721c3bbe0d76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhide_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/python_new/cde_venv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5463\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5465\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'style'"
     ]
    }
   ],
   "source": [
    "output = output.style.hide_index()\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c0f03cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'290754\\nName1dtypefloat64'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "num_1 = re.sub(\"[ ,.#*!@$%^&()|\\''\"\":;]\", \"\", output)\n",
    "num_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbf53d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 MO EMPLOYER ACCOUNT NO YEAR\\n\\nae : 5 Ah 202...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUST HAVE AMOUNTS IN 4, 5, &amp; 6, EVEN IF ZERO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 TOTAL WAGES PAID</td>\n",
       "      <td>907.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 WAGES PAID IN EXCESS OF\\nPER WORKER\\nPER YEA...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0       1   2   3   4   5  \\\n",
       "0  2 MO EMPLOYER ACCOUNT NO YEAR\\n\\nae : 5 Ah 202...     NaN NaN NaN NaN NaN   \n",
       "1       MUST HAVE AMOUNTS IN 4, 5, & 6, EVEN IF ZERO     NaN NaN NaN NaN NaN   \n",
       "2                                 4 TOTAL WAGES PAID  907.54 NaN NaN NaN NaN   \n",
       "3  5 WAGES PAID IN EXCESS OF\\nPER WORKER\\nPER YEA...    0.00 NaN NaN NaN NaN   \n",
       "\n",
       "    6   7   8   9  \n",
       "0 NaN NaN NaN NaN  \n",
       "1 NaN NaN NaN NaN  \n",
       "2 NaN NaN NaN NaN  \n",
       "3 NaN NaN NaN NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2cd82a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_e68dd_\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>        <th class=\"col_heading level0 col2\" >2</th>        <th class=\"col_heading level0 col3\" >3</th>        <th class=\"col_heading level0 col4\" >4</th>        <th class=\"col_heading level0 col5\" >5</th>        <th class=\"col_heading level0 col6\" >6</th>        <th class=\"col_heading level0 col7\" >7</th>        <th class=\"col_heading level0 col8\" >8</th>        <th class=\"col_heading level0 col9\" >9</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_e68dd_row0_col0\" class=\"data row0 col0\" >2 MO EMPLOYER ACCOUNT NO YEAR\n",
       "\n",
       "ae : 5 Ah 2020\n",
       "\n",
       "3 CALENDAR QUARTER\n",
       "\n",
       "it [x] 2 [} at FO] am (J</td>\n",
       "                        <td id=\"T_e68dd_row0_col1\" class=\"data row0 col1\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row0_col5\" class=\"data row0 col5\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row0_col6\" class=\"data row0 col6\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row0_col7\" class=\"data row0 col7\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row0_col8\" class=\"data row0 col8\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_e68dd_row1_col0\" class=\"data row1 col0\" >MUST HAVE AMOUNTS IN 4, 5, & 6, EVEN IF ZERO</td>\n",
       "                        <td id=\"T_e68dd_row1_col1\" class=\"data row1 col1\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row1_col5\" class=\"data row1 col5\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row1_col6\" class=\"data row1 col6\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row1_col7\" class=\"data row1 col7\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row1_col8\" class=\"data row1 col8\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row1_col9\" class=\"data row1 col9\" >nan</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_e68dd_row2_col0\" class=\"data row2 col0\" >4 TOTAL WAGES PAID</td>\n",
       "                        <td id=\"T_e68dd_row2_col1\" class=\"data row2 col1\" >907.540000</td>\n",
       "                        <td id=\"T_e68dd_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row2_col6\" class=\"data row2 col6\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row2_col7\" class=\"data row2 col7\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row2_col8\" class=\"data row2 col8\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row2_col9\" class=\"data row2 col9\" >nan</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_e68dd_row3_col0\" class=\"data row3 col0\" >5 WAGES PAID IN EXCESS OF\n",
       "PER WORKER\n",
       "PER YEAR (See Instruction Sheet)</td>\n",
       "                        <td id=\"T_e68dd_row3_col1\" class=\"data row3 col1\" >0.000000</td>\n",
       "                        <td id=\"T_e68dd_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row3_col3\" class=\"data row3 col3\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row3_col4\" class=\"data row3 col4\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row3_col5\" class=\"data row3 col5\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row3_col6\" class=\"data row3 col6\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row3_col7\" class=\"data row3 col7\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row3_col8\" class=\"data row3 col8\" >nan</td>\n",
       "                        <td id=\"T_e68dd_row3_col9\" class=\"data row3 col9\" >nan</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f53e602dfa0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df1.style.hide_index()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "74ed9194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0       1\n",
      "2  4 TOTAL WAGES PAID  907.54\n",
      "2    907.54\n",
      "Name: 1, dtype: float64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-076dd34128a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[ ,.#*!@$%^&()|\\''\"\u001b[0m\u001b[0;34m\":;]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "    import matplotlib.image as mpimg\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    import cv2\n",
    "    import os\n",
    "    import math\n",
    "    import sys\n",
    "    import numpy as np\n",
    "    import pytesseract\n",
    "    import io \n",
    "    import csv\n",
    "    import pandas as pd\n",
    "    import shutil, os\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    file_name = '0500847001.jpeg'\n",
    "\n",
    "    #path = '/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input'\n",
    "    #for file_name in os.listdir(path):\n",
    "        #print(file_name)\n",
    "    shutil.copytree('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/sample', \n",
    "        os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                 os.path.splitext(file_name)[0]))\n",
    "     \n",
    "    img = mpimg.imread(os.path.join\n",
    "                       ('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input',\n",
    "                        file_name))\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    wi = width * 0.95\n",
    "    he = height * 0.3\n",
    "    w = int(wi)\n",
    "    h = int(he)\n",
    "    y = 0\n",
    "    x1 = w * 0.45\n",
    "    x = int(x1)\n",
    "    crop = img[y:y+h, x:x+w]\n",
    "    #plt.imshow(crop)\n",
    "    im = Image.fromarray(crop)\n",
    "    b = os.path.splitext(file_name)[0]+'_crop.jpeg'\n",
    "    im.save(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                           os.path.splitext(file_name)[0],'crop',b))\n",
    "    def extract_cell_images_from_table(image):\n",
    "        BLUR_KERNEL_SIZE = (17, 17)\n",
    "        STD_DEV_X_DIRECTION = 0\n",
    "        STD_DEV_Y_DIRECTION = 0\n",
    "        blurred = cv2.GaussianBlur(image, BLUR_KERNEL_SIZE, STD_DEV_X_DIRECTION, STD_DEV_Y_DIRECTION)\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~blurred,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "        vertical = horizontal = img_bin.copy()\n",
    "        SCALE = 5\n",
    "        image_width, image_height = horizontal.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(image_width / SCALE), 1))\n",
    "        horizontally_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(image_height / SCALE)))\n",
    "        vertically_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "\n",
    "        horizontally_dilated = cv2.dilate(horizontally_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1)))\n",
    "        vertically_dilated = cv2.dilate(vertically_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (1, 60)))\n",
    "\n",
    "        mask = horizontally_dilated + vertically_dilated\n",
    "        contours, heirarchy = cv2.findContours(\n",
    "            mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE,\n",
    "        )\n",
    "\n",
    "        perimeter_lengths = [cv2.arcLength(c, True) for c in contours]\n",
    "        epsilons = [0.05 * p for p in perimeter_lengths]\n",
    "        approx_polys = [cv2.approxPolyDP(c, e, True) for c, e in zip(contours, epsilons)]\n",
    "\n",
    "        # Filter out contours that aren't rectangular. Those that aren't rectangular\n",
    "        # are probably noise.\n",
    "        approx_rects = [p for p in approx_polys if len(p) == 4]\n",
    "        bounding_rects = [cv2.boundingRect(a) for a in approx_polys]\n",
    "\n",
    "        # Filter out rectangles that are too narrow or too short.\n",
    "        MIN_RECT_WIDTH = 40\n",
    "        MIN_RECT_HEIGHT = 10\n",
    "        bounding_rects = [\n",
    "            r for r in bounding_rects if MIN_RECT_WIDTH < r[2] and MIN_RECT_HEIGHT < r[3]\n",
    "        ]\n",
    "\n",
    "        # The largest bounding rectangle is assumed to be the entire table.\n",
    "        # Remove it from the list. We don't want to accidentally try to OCR\n",
    "        # the entire table.\n",
    "        largest_rect = max(bounding_rects, key=lambda r: r[2] * r[3])\n",
    "        bounding_rects = [b for b in bounding_rects if b is not largest_rect]\n",
    "\n",
    "        cells = [c for c in bounding_rects]\n",
    "        def cell_in_same_row(c1, c2):\n",
    "            c1_center = c1[1] + c1[3] - c1[3] / 2\n",
    "            c2_bottom = c2[1] + c2[3]\n",
    "            c2_top = c2[1]\n",
    "            return c2_top < c1_center < c2_bottom\n",
    "\n",
    "        orig_cells = [c for c in cells]\n",
    "        rows = []\n",
    "        while cells:\n",
    "            first = cells[0]\n",
    "            rest = cells[1:]\n",
    "            cells_in_same_row = sorted(\n",
    "                [\n",
    "                    c for c in rest\n",
    "                    if cell_in_same_row(c, first)\n",
    "                ],\n",
    "                key=lambda c: c[0]\n",
    "            )\n",
    "\n",
    "            row_cells = sorted([first] + cells_in_same_row, key=lambda c: c[0])\n",
    "            rows.append(row_cells)\n",
    "            cells = [\n",
    "                c for c in rest\n",
    "                if not cell_in_same_row(c, first)\n",
    "            ]\n",
    "\n",
    "        # Sort rows by average height of their center.\n",
    "        def avg_height_of_center(row):\n",
    "            centers = [y + h - h / 2 for x, y, w, h in row]\n",
    "            return sum(centers) / len(centers)\n",
    "\n",
    "        rows.sort(key=avg_height_of_center)\n",
    "        cell_images_rows = []\n",
    "        for row in rows:\n",
    "            cell_images_row = []\n",
    "            for x, y, w, h in row:\n",
    "                cell_images_row.append(image[y:y+h, x:x+w])\n",
    "            cell_images_rows.append(cell_images_row)\n",
    "        return cell_images_rows\n",
    "\n",
    "    def main(f):\n",
    "        results = []\n",
    "        directory, filename = os.path.split(f)\n",
    "        table = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        rows = extract_cell_images_from_table(table)\n",
    "        #cell_img_dir = os.path.join(directory, \"cells\")\n",
    "        #os.makedirs(cell_img_dir, exist_ok=True)\n",
    "        out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'cells')\n",
    "        paths = []\n",
    "        for i, row in enumerate(rows):\n",
    "            for j, cell in enumerate(row):\n",
    "                cell_filename = \"{:03d}-{:03d}.png\".format(i, j)\n",
    "                path = os.path.join(out_path, cell_filename)\n",
    "                cv2.imwrite(path, cell)\n",
    "                paths.append(path)\n",
    "        return paths\n",
    "\n",
    "    f = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                           os.path.splitext(file_name)[0],'crop',b)\n",
    "    main(f)\n",
    "    \n",
    "    def main(image_file, tess_args):\n",
    "        \"\"\"\n",
    "        OCR the image and output the text to a file with an extension that is ready\n",
    "        to be used in Tesseract training (.gt.txt).\n",
    "        Tries to crop the image so that only the relevant text gets passed to Tesseract.\n",
    "        Returns the name of the text file that contains the text.\n",
    "        \"\"\"\n",
    "        #file_path = '/home/vimal/Documents/table_detect_samples/structured images/input/011364700/cells'\n",
    "        #image_file = os.listdir(file_path)\n",
    "\n",
    "        for f in image_file:\n",
    "            #print(f)\n",
    "            directory, filename = os.path.split(f)\n",
    "            filename_sans_ext, ext = os.path.splitext(filename)\n",
    "            image = cv2.imread(os.path.join(file_path,f), cv2.IMREAD_GRAYSCALE)\n",
    "            cropped = crop_to_text(image)\n",
    "            #ocr_data_dir = os.path.join(directory, \"ocr_data\")\n",
    "            #os.makedirs(ocr_data_dir, exist_ok=True)\n",
    "            #out_imagepath = os.path.join(ocr_data_dir, filename)\n",
    "            out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'text')\n",
    "            out_txtpath = os.path.join(out_path, \"{}.txt\".format(filename_sans_ext))\n",
    "            #cv2.imwrite(out_imagepath, cropped)\n",
    "            if not tess_args:\n",
    "                d = os.path.dirname(sys.modules[\"table_ocr\"].__file__)\n",
    "                tessdata_dir = os.path.join(d, \"tessdata\")\n",
    "                tess_args = [\"--psm\", \"7\", \"-l\", \"table-ocr\", \"--tessdata-dir\", tessdata_dir]\n",
    "            txt = ocr_image(cropped, \" \".join(tess_args))\n",
    "            with open(out_txtpath, \"w\") as txt_file:\n",
    "                txt_file.write(txt)\n",
    "            #return out_txtpath\n",
    "    def crop_to_text(image):\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~image,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "\n",
    "        img_h, img_w = image.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(img_w * 0.5), 1))\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(img_h * 0.7)))\n",
    "        horizontal_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "        both = horizontal_lines + vertical_lines\n",
    "        cleaned = img_bin - both\n",
    "\n",
    "        # Get rid of little noise.\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        opened = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)\n",
    "        opened = cv2.dilate(opened, kernel)\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(opened, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        bounding_rects = [cv2.boundingRect(c) for c in contours]\n",
    "        NUM_PX_COMMA = 6\n",
    "        MIN_CHAR_AREA = 5 * 9\n",
    "        char_sized_bounding_rects = [(x, y, w, h) for x, y, w, h in bounding_rects if w * h > MIN_CHAR_AREA]\n",
    "        if char_sized_bounding_rects:\n",
    "            minx, miny, maxx, maxy = math.inf, math.inf, 0, 0\n",
    "            for x, y, w, h in char_sized_bounding_rects:\n",
    "                minx = min(minx, x)\n",
    "                miny = min(miny, y)\n",
    "                maxx = max(maxx, x + w)\n",
    "                maxy = max(maxy, y + h)\n",
    "            x, y, w, h = minx, miny, maxx - minx, maxy - miny\n",
    "            cropped = image[y:min(img_h, y+h+NUM_PX_COMMA), x:min(img_w, x+w)]\n",
    "        else:\n",
    "            # If we morphed out all of the text, assume an empty image.\n",
    "            cropped = MAX_COLOR_VAL * np.ones(shape=(20, 100), dtype=np.uint8)\n",
    "        bordered = cv2.copyMakeBorder(cropped, 5, 5, 5, 5, cv2.BORDER_CONSTANT, None, 255)\n",
    "        return bordered\n",
    "    def ocr_image(image, config):\n",
    "        return pytesseract.image_to_string(\n",
    "            image,\n",
    "            lang='eng', config='--psm 6'\n",
    "        )\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'cells')\n",
    "    image_file = os.listdir(file_path)\n",
    "    tess_args = os.listdir(file_path)\n",
    "\n",
    "    main(image_file, tess_args)\n",
    "    \n",
    "    def text_files_to_csv(files):\n",
    "        \"\"\"Files must be sorted lexicographically\n",
    "        Filenames must be <row>-<colum>.txt.\n",
    "        000-000.txt\n",
    "        000-001.txt\n",
    "        001-000.txt\n",
    "        etc...\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        for f in files:\n",
    "            directory, filename = os.path.split(f)\n",
    "            with open(os.path.join(file_path,f)) as of:\n",
    "                txt = of.read().strip()\n",
    "            row, column = map(int, filename.split(\".\")[0].split(\"-\"))\n",
    "            if row == len(rows):\n",
    "                rows.append([])\n",
    "            rows[row].append(txt)\n",
    "\n",
    "        csv_file = io.StringIO()\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerows(rows)\n",
    "        return csv_file.getvalue()\n",
    "\n",
    "    def main(files):\n",
    "        return text_files_to_csv(files)\n",
    "\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'text')\n",
    "    file = os.listdir(file_path)\n",
    "    files = sorted(file)\n",
    "\n",
    "    a = main(files)\n",
    "    #print(a)\n",
    "\n",
    "    c = os.path.splitext(file_name)[0]+'_text.txt'\n",
    "    t = os.path.splitext(file_name)[0]+'_f-text.txt'\n",
    "\n",
    "    #cs = os.path.splitext(file_name)[0]+'_xl.csv'\n",
    "\n",
    "    text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'txt',c), \"wt\")\n",
    "    n = text_file.write(a)\n",
    "    text_file.close()\n",
    "\n",
    "    df = pd.read_csv(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'txt',c),\n",
    "        header=None,delimiter=',',names=list(range(10)))\n",
    "    #print(df)\n",
    "    \n",
    "    df1 = df.dropna(axis = 0,how = 'all')\n",
    "    #print(df1)\n",
    "    \n",
    "    word = 'TOTAL WAGES PAID'\n",
    "    \n",
    "        \n",
    "    \n",
    "    if df1[0].dtypes != 'object':\n",
    "        print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',0)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        for i in df1[0]:\n",
    "            if fuzz.ratio(word,i) > 80:\n",
    "                #print(i)\n",
    "                dff = df1[df1[0] == i]\n",
    "                dff = dff.dropna(axis = 1,how = 'all')\n",
    "                print(dff)\n",
    "                output = dff[1]\n",
    "                print(output)\n",
    "                out = re.sub(\"[ ,.#*!@$%^&()|\\''\"\":;]\", \"\", output)\n",
    "                print(out)\n",
    "                \n",
    "                if len(output) == 0:\n",
    "                    print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',0)\n",
    "                else:\n",
    "                    with open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                            os.path.splitext(file_name)[0],'final_text',t), 'a') as f:\n",
    "                        f.write(output.to_string(header = False, index = False))\n",
    "                        \n",
    "                    text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                            os.path.splitext(file_name)[0],'final_text',t), 'r+')\n",
    "                    \n",
    "                    print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',text_file.read())\n",
    "        \n",
    "                \n",
    "                \n",
    "    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3164f2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 MO EMPLOYER ACCOUNT NO YEAR\\n\\nae : 5 Ah 202...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUST HAVE AMOUNTS IN 4, 5, &amp; 6, EVEN IF ZERO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 TOTAL WAGES PAID</td>\n",
       "      <td>907.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 WAGES PAID IN EXCESS OF\\nPER WORKER\\nPER YEA...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0       1   2   3   4   5  \\\n",
       "0  2 MO EMPLOYER ACCOUNT NO YEAR\\n\\nae : 5 Ah 202...     NaN NaN NaN NaN NaN   \n",
       "1       MUST HAVE AMOUNTS IN 4, 5, & 6, EVEN IF ZERO     NaN NaN NaN NaN NaN   \n",
       "2                                 4 TOTAL WAGES PAID  907.54 NaN NaN NaN NaN   \n",
       "3  5 WAGES PAID IN EXCESS OF\\nPER WORKER\\nPER YEA...    0.00 NaN NaN NaN NaN   \n",
       "\n",
       "    6   7   8   9  \n",
       "0 NaN NaN NaN NaN  \n",
       "1 NaN NaN NaN NaN  \n",
       "2 NaN NaN NaN NaN  \n",
       "3 NaN NaN NaN NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "86f2f0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       4 non-null      object \n",
      " 1   1       2 non-null      float64\n",
      " 2   2       0 non-null      float64\n",
      " 3   3       0 non-null      float64\n",
      " 4   4       0 non-null      float64\n",
      " 5   5       0 non-null      float64\n",
      " 6   6       0 non-null      float64\n",
      " 7   7       0 non-null      float64\n",
      " 8   8       0 non-null      float64\n",
      " 9   9       0 non-null      float64\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 448.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9af93720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 MO EMPLOYER ACCOUNT NO YEAR\\n\\nae : 5 Ah 202...</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUST HAVE AMOUNTS IN 4, 5, &amp; 6, EVEN IF ZERO</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 TOTAL WAGES PAID</td>\n",
       "      <td>907.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 WAGES PAID IN EXCESS OF\\nPER WORKER\\nPER YEA...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0       1   2   3   4   5  \\\n",
       "0  2 MO EMPLOYER ACCOUNT NO YEAR\\n\\nae : 5 Ah 202...     nan NaN NaN NaN NaN   \n",
       "1       MUST HAVE AMOUNTS IN 4, 5, & 6, EVEN IF ZERO     nan NaN NaN NaN NaN   \n",
       "2                                 4 TOTAL WAGES PAID  907.54 NaN NaN NaN NaN   \n",
       "3  5 WAGES PAID IN EXCESS OF\\nPER WORKER\\nPER YEA...     0.0 NaN NaN NaN NaN   \n",
       "\n",
       "    6   7   8   9  \n",
       "0 NaN NaN NaN NaN  \n",
       "1 NaN NaN NaN NaN  \n",
       "2 NaN NaN NaN NaN  \n",
       "3 NaN NaN NaN NaN  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0dae204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twp(file_name):\n",
    "    import matplotlib.image as mpimg\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    from fuzzywuzzy import fuzz\n",
    "    from fuzzywuzzy import process\n",
    "    import cv2\n",
    "    import os\n",
    "    import math\n",
    "    import sys\n",
    "    import numpy as np\n",
    "    import pytesseract\n",
    "    import io \n",
    "    import csv\n",
    "    import pandas as pd\n",
    "    import shutil, os\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    #file_name = '0100477000.jpeg'\n",
    "\n",
    "    #path = '/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input'\n",
    "    #for file_name in os.listdir(path):\n",
    "        #print(file_name)\n",
    "    shutil.copytree('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/sample', \n",
    "        os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                 os.path.splitext(file_name)[0]))\n",
    "     \n",
    "    img = mpimg.imread(os.path.join\n",
    "                       ('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input',\n",
    "                        file_name))\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    wi = width * 0.95\n",
    "    he = height * 0.3\n",
    "    w = int(wi)\n",
    "    h = int(he)\n",
    "    y = 0\n",
    "    x1 = w * 0.45\n",
    "    x = int(x1)\n",
    "    crop = img[y:y+h, x:x+w]\n",
    "    #plt.imshow(crop)\n",
    "    im = Image.fromarray(crop)\n",
    "    b = os.path.splitext(file_name)[0]+'_crop.jpeg'\n",
    "    im.save(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                           os.path.splitext(file_name)[0],'crop',b))\n",
    "    def extract_cell_images_from_table(image):\n",
    "        BLUR_KERNEL_SIZE = (17, 17)\n",
    "        STD_DEV_X_DIRECTION = 0\n",
    "        STD_DEV_Y_DIRECTION = 0\n",
    "        blurred = cv2.GaussianBlur(image, BLUR_KERNEL_SIZE, STD_DEV_X_DIRECTION, STD_DEV_Y_DIRECTION)\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~blurred,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "        vertical = horizontal = img_bin.copy()\n",
    "        SCALE = 5\n",
    "        image_width, image_height = horizontal.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(image_width / SCALE), 1))\n",
    "        horizontally_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(image_height / SCALE)))\n",
    "        vertically_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "\n",
    "        horizontally_dilated = cv2.dilate(horizontally_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1)))\n",
    "        vertically_dilated = cv2.dilate(vertically_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (1, 60)))\n",
    "\n",
    "        mask = horizontally_dilated + vertically_dilated\n",
    "        contours, heirarchy = cv2.findContours(\n",
    "            mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE,\n",
    "        )\n",
    "\n",
    "        perimeter_lengths = [cv2.arcLength(c, True) for c in contours]\n",
    "        epsilons = [0.05 * p for p in perimeter_lengths]\n",
    "        approx_polys = [cv2.approxPolyDP(c, e, True) for c, e in zip(contours, epsilons)]\n",
    "\n",
    "        # Filter out contours that aren't rectangular. Those that aren't rectangular\n",
    "        # are probably noise.\n",
    "        approx_rects = [p for p in approx_polys if len(p) == 4]\n",
    "        bounding_rects = [cv2.boundingRect(a) for a in approx_polys]\n",
    "\n",
    "        # Filter out rectangles that are too narrow or too short.\n",
    "        MIN_RECT_WIDTH = 40\n",
    "        MIN_RECT_HEIGHT = 10\n",
    "        bounding_rects = [\n",
    "            r for r in bounding_rects if MIN_RECT_WIDTH < r[2] and MIN_RECT_HEIGHT < r[3]\n",
    "        ]\n",
    "\n",
    "        # The largest bounding rectangle is assumed to be the entire table.\n",
    "        # Remove it from the list. We don't want to accidentally try to OCR\n",
    "        # the entire table.\n",
    "        largest_rect = max(bounding_rects, key=lambda r: r[2] * r[3])\n",
    "        bounding_rects = [b for b in bounding_rects if b is not largest_rect]\n",
    "\n",
    "        cells = [c for c in bounding_rects]\n",
    "        def cell_in_same_row(c1, c2):\n",
    "            c1_center = c1[1] + c1[3] - c1[3] / 2\n",
    "            c2_bottom = c2[1] + c2[3]\n",
    "            c2_top = c2[1]\n",
    "            return c2_top < c1_center < c2_bottom\n",
    "\n",
    "        orig_cells = [c for c in cells]\n",
    "        rows = []\n",
    "        while cells:\n",
    "            first = cells[0]\n",
    "            rest = cells[1:]\n",
    "            cells_in_same_row = sorted(\n",
    "                [\n",
    "                    c for c in rest\n",
    "                    if cell_in_same_row(c, first)\n",
    "                ],\n",
    "                key=lambda c: c[0]\n",
    "            )\n",
    "\n",
    "            row_cells = sorted([first] + cells_in_same_row, key=lambda c: c[0])\n",
    "            rows.append(row_cells)\n",
    "            cells = [\n",
    "                c for c in rest\n",
    "                if not cell_in_same_row(c, first)\n",
    "            ]\n",
    "\n",
    "        # Sort rows by average height of their center.\n",
    "        def avg_height_of_center(row):\n",
    "            centers = [y + h - h / 2 for x, y, w, h in row]\n",
    "            return sum(centers) / len(centers)\n",
    "\n",
    "        rows.sort(key=avg_height_of_center)\n",
    "        cell_images_rows = []\n",
    "        for row in rows:\n",
    "            cell_images_row = []\n",
    "            for x, y, w, h in row:\n",
    "                cell_images_row.append(image[y:y+h, x:x+w])\n",
    "            cell_images_rows.append(cell_images_row)\n",
    "        return cell_images_rows\n",
    "\n",
    "    def main(f):\n",
    "        results = []\n",
    "        directory, filename = os.path.split(f)\n",
    "        table = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        rows = extract_cell_images_from_table(table)\n",
    "        #cell_img_dir = os.path.join(directory, \"cells\")\n",
    "        #os.makedirs(cell_img_dir, exist_ok=True)\n",
    "        out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'cells')\n",
    "        paths = []\n",
    "        for i, row in enumerate(rows):\n",
    "            for j, cell in enumerate(row):\n",
    "                cell_filename = \"{:03d}-{:03d}.png\".format(i, j)\n",
    "                path = os.path.join(out_path, cell_filename)\n",
    "                cv2.imwrite(path, cell)\n",
    "                paths.append(path)\n",
    "        return paths\n",
    "\n",
    "    f = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                           os.path.splitext(file_name)[0],'crop',b)\n",
    "    main(f)\n",
    "    \n",
    "    def main(image_file, tess_args):\n",
    "        \"\"\"\n",
    "        OCR the image and output the text to a file with an extension that is ready\n",
    "        to be used in Tesseract training (.gt.txt).\n",
    "        Tries to crop the image so that only the relevant text gets passed to Tesseract.\n",
    "        Returns the name of the text file that contains the text.\n",
    "        \"\"\"\n",
    "        #file_path = '/home/vimal/Documents/table_detect_samples/structured images/input/011364700/cells'\n",
    "        #image_file = os.listdir(file_path)\n",
    "\n",
    "        for f in image_file:\n",
    "            #print(f)\n",
    "            directory, filename = os.path.split(f)\n",
    "            filename_sans_ext, ext = os.path.splitext(filename)\n",
    "            image = cv2.imread(os.path.join(file_path,f), cv2.IMREAD_GRAYSCALE)\n",
    "            cropped = crop_to_text(image)\n",
    "            #ocr_data_dir = os.path.join(directory, \"ocr_data\")\n",
    "            #os.makedirs(ocr_data_dir, exist_ok=True)\n",
    "            #out_imagepath = os.path.join(ocr_data_dir, filename)\n",
    "            out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'text')\n",
    "            out_txtpath = os.path.join(out_path, \"{}.txt\".format(filename_sans_ext))\n",
    "            #cv2.imwrite(out_imagepath, cropped)\n",
    "            if not tess_args:\n",
    "                d = os.path.dirname(sys.modules[\"table_ocr\"].__file__)\n",
    "                tessdata_dir = os.path.join(d, \"tessdata\")\n",
    "                tess_args = [\"--psm\", \"7\", \"-l\", \"table-ocr\", \"--tessdata-dir\", tessdata_dir]\n",
    "            txt = ocr_image(cropped, \" \".join(tess_args))\n",
    "            with open(out_txtpath, \"w\") as txt_file:\n",
    "                txt_file.write(txt)\n",
    "            #return out_txtpath\n",
    "    def crop_to_text(image):\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~image,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "\n",
    "        img_h, img_w = image.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(img_w * 0.5), 1))\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(img_h * 0.7)))\n",
    "        horizontal_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "        both = horizontal_lines + vertical_lines\n",
    "        cleaned = img_bin - both\n",
    "\n",
    "        # Get rid of little noise.\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        opened = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)\n",
    "        opened = cv2.dilate(opened, kernel)\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(opened, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        bounding_rects = [cv2.boundingRect(c) for c in contours]\n",
    "        NUM_PX_COMMA = 6\n",
    "        MIN_CHAR_AREA = 5 * 9\n",
    "        char_sized_bounding_rects = [(x, y, w, h) for x, y, w, h in bounding_rects if w * h > MIN_CHAR_AREA]\n",
    "        if char_sized_bounding_rects:\n",
    "            minx, miny, maxx, maxy = math.inf, math.inf, 0, 0\n",
    "            for x, y, w, h in char_sized_bounding_rects:\n",
    "                minx = min(minx, x)\n",
    "                miny = min(miny, y)\n",
    "                maxx = max(maxx, x + w)\n",
    "                maxy = max(maxy, y + h)\n",
    "            x, y, w, h = minx, miny, maxx - minx, maxy - miny\n",
    "            cropped = image[y:min(img_h, y+h+NUM_PX_COMMA), x:min(img_w, x+w)]\n",
    "        else:\n",
    "            # If we morphed out all of the text, assume an empty image.\n",
    "            cropped = MAX_COLOR_VAL * np.ones(shape=(20, 100), dtype=np.uint8)\n",
    "        bordered = cv2.copyMakeBorder(cropped, 5, 5, 5, 5, cv2.BORDER_CONSTANT, None, 255)\n",
    "        return bordered\n",
    "    def ocr_image(image, config):\n",
    "        return pytesseract.image_to_string(\n",
    "            image,\n",
    "            lang='eng', config='--psm 6'\n",
    "        )\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'cells')\n",
    "    image_file = os.listdir(file_path)\n",
    "    tess_args = os.listdir(file_path)\n",
    "\n",
    "    main(image_file, tess_args)\n",
    "    \n",
    "    def text_files_to_csv(files):\n",
    "        \"\"\"Files must be sorted lexicographically\n",
    "        Filenames must be <row>-<colum>.txt.\n",
    "        000-000.txt\n",
    "        000-001.txt\n",
    "        001-000.txt\n",
    "        etc...\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        for f in files:\n",
    "            directory, filename = os.path.split(f)\n",
    "            with open(os.path.join(file_path,f)) as of:\n",
    "                txt = of.read().strip()\n",
    "            row, column = map(int, filename.split(\".\")[0].split(\"-\"))\n",
    "            if row == len(rows):\n",
    "                rows.append([])\n",
    "            rows[row].append(txt)\n",
    "\n",
    "        csv_file = io.StringIO()\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerows(rows)\n",
    "        return csv_file.getvalue()\n",
    "\n",
    "    def main(files):\n",
    "        return text_files_to_csv(files)\n",
    "\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'text')\n",
    "    file = os.listdir(file_path)\n",
    "    files = sorted(file)\n",
    "\n",
    "    a = main(files)\n",
    "    #print(a)\n",
    "\n",
    "    c = os.path.splitext(file_name)[0]+'_text.txt'\n",
    "    t = os.path.splitext(file_name)[0]+'_f-text.txt'\n",
    "\n",
    "    #cs = os.path.splitext(file_name)[0]+'_xl.csv'\n",
    "\n",
    "    text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'txt',c), \"wt\")\n",
    "    n = text_file.write(a)\n",
    "    text_file.close()\n",
    "\n",
    "    df = pd.read_csv(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                os.path.splitext(file_name)[0],'txt',c),\n",
    "        header=None,delimiter=',',names=list(range(10)))\n",
    "    #print(df)\n",
    "    \n",
    "    df1 = df.dropna(axis = 0,how = 'all')\n",
    "    #print(df1)\n",
    "    \n",
    "    word = 'TOTAL WAGES PAID'\n",
    "    \n",
    "        \n",
    "    \n",
    "    if df1[0].dtypes != 'object':\n",
    "        print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',0)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        for i in df1[0]:\n",
    "            if fuzz.ratio(word,i) > 80:\n",
    "                #print(i)\n",
    "                dff = df1[df1[0] == i]\n",
    "                dff = dff.dropna(axis = 1,how = 'all')\n",
    "                output = dff[1]\n",
    "                output = output.str.replace(r'[^\\w\\s]+', '')\n",
    "                output = output.str.replace(\" \",\"\")\n",
    "                #print(output)\n",
    "                \n",
    "                if len(output) == 0:\n",
    "                    print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',0)\n",
    "                else:\n",
    "                    with open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                            os.path.splitext(file_name)[0],'final_text',t), 'a') as f:\n",
    "                        f.write(output.to_string(header = False, index = False))\n",
    "                        \n",
    "                    text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                            os.path.splitext(file_name)[0],'final_text',t), 'r+')\n",
    "                    \n",
    "                    print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',text_file.read())\n",
    "        \n",
    "                \n",
    "                \n",
    "    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f95f95f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0101231000.tif TOTAL WAGES PAID 99454\n"
     ]
    }
   ],
   "source": [
    "file_name = '0101231000.jpeg'\n",
    "twp(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb21351d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vimalkumar.s/Documents/python_new/cde_venv/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0414782000.tif TOTAL WAGES PAID 10215000\n",
      "0388041000.tif TOTAL WAGES PAID 1855002\n",
      "0965510000.tif TOTAL WAGES PAID 39043\n",
      "0964684000.tif TOTAL WAGES PAID 775000\n",
      "0943362000.tif TOTAL WAGES PAID 4078454\n",
      "0925469000.tif TOTAL WAGES PAID OLS4\n",
      "0949784000.tif TOTAL WAGES PAID 325050\n",
      "0774334000.tif TOTAL WAGES PAID 1823726\n",
      "0843659000.tif TOTAL WAGES PAID 3103750\n",
      "0689178000.tif TOTAL WAGES PAID 3922854\n",
      "0216226000.tif TOTAL WAGES PAID 5650845\n",
      "0648125000.tif TOTAL WAGES PAID 2090175\n",
      "0822217000.tif TOTAL WAGES PAID 1013900\n",
      "0343681000.tif TOTAL WAGES PAID 4026350\n",
      "0876479000.tif TOTAL WAGES PAID nan\n",
      "0415680002.tif TOTAL WAGES PAID 3475\n",
      "0644730000.tif TOTAL WAGES PAID 2281796\n",
      "0939535000.tif TOTAL WAGES PAID 34100C\n",
      "0784699000.tif TOTAL WAGES PAID 285626\n",
      "0796110000.tif TOTAL WAGES PAID 5\n",
      "0469665000.tif TOTAL WAGES PAID 6688888\n",
      "0539605000.tif TOTAL WAGES PAID 570000\n",
      "0105253000.tif TOTAL WAGES PAID 1730296\n",
      "0848314000.tif TOTAL WAGES PAID 364383\n",
      "0507327000.tif TOTAL WAGES PAID 3175149\n",
      "0906601000.tif TOTAL WAGES PAID 354500\n",
      "0755634000.tif TOTAL WAGES PAID 1808470\n",
      "0124025000.tif TOTAL WAGES PAID nan\n",
      "0933538000.tif TOTAL WAGES PAID 943920\n",
      "0885707000.tif TOTAL WAGES PAID 377796\n",
      "0885696000.tif TOTAL WAGES PAID 974016\n",
      "0504959000.tif TOTAL WAGES PAID 427873\n",
      "0656910000.tif TOTAL WAGES PAID 9065485\n",
      "0872623000.tif TOTAL WAGES PAID 337985\n",
      "0619505000.tif TOTAL WAGES PAID 6256448\n",
      "0850365000.tif TOTAL WAGES PAID S46F00\n",
      "0352450000.tif TOTAL WAGES PAID nan\n",
      "0928519001.tif TOTAL WAGES PAID 3600\n",
      "0739401000.tif TOTAL WAGES PAID 4287300\n",
      "0358273000.tif TOTAL WAGES PAID 1800000\n",
      "0954699000.tif TOTAL WAGES PAID 174250\n",
      "0652322000.tif TOTAL WAGES PAID 1016274\n",
      "0964710000.tif TOTAL WAGES PAID 2327696\n",
      "0758728000.tif TOTAL WAGES PAID 600000\n",
      "0906467000.tif TOTAL WAGES PAID 1651772\n",
      "0593002000.tif TOTAL WAGES PAID 705210\n",
      "0908445000.tif TOTAL WAGES PAID 736250\n",
      "0834514000.tif TOTAL WAGES PAID 1150000\n",
      "0440048000.tif TOTAL WAGES PAID 365528\n",
      "0327815000.tif TOTAL WAGES PAID 1658800\n",
      "0380460000.tif TOTAL WAGES PAID 8176785\n",
      "0964707000.tif TOTAL WAGES PAID 480000\n",
      "0311597000.tif TOTAL WAGES PAID 2795000\n",
      "0954573000.tif TOTAL WAGES PAID 3743279\n",
      "0673373000.tif TOTAL WAGES PAID 6637358\n",
      "0295519000.tif TOTAL WAGES PAID 1201848\n",
      "0798747000.tif TOTAL WAGES PAID 794584\n",
      "0599295000.tif TOTAL WAGES PAID 8092429\n",
      "0438022000.tif TOTAL WAGES PAID 2073992\n",
      "0853323000.tif TOTAL WAGES PAID Gfod\n",
      "0208577000.tif TOTAL WAGES PAID 25915696\n",
      "0400462000.tif TOTAL WAGES PAID 1139586\n",
      "0904042000.tif TOTAL WAGES PAID 109447\n",
      "0596676000.tif TOTAL WAGES PAID 5784OC\n",
      "0915050000.tif TOTAL WAGES PAID 1100000\n",
      "0308511000.tif TOTAL WAGES PAID 1267500\n",
      "0479517000.tif TOTAL WAGES PAID 7667558\n",
      "0661666000.tif TOTAL WAGES PAID 15702500\n",
      "0946204000.tif TOTAL WAGES PAID 394490\n",
      "0955447000.tif TOTAL WAGES PAID 855000\n",
      "0257272000.tif TOTAL WAGES PAID 1096245\n",
      "0878579000.tif TOTAL WAGES PAID 8800\n",
      "0691690002.tif TOTAL WAGES PAID 382500\n",
      "0184364000.tif TOTAL WAGES PAID 12431315\n",
      "0319768000.tif TOTAL WAGES PAID 385196\n",
      "0922504000.tif TOTAL WAGES PAID 4139440\n",
      "0382085000.tif TOTAL WAGES PAID 186575\n",
      "0963660000.tif TOTAL WAGES PAID 677246\n",
      "0944892000.tif TOTAL WAGES PAID 9418\n",
      "0954594000.tif TOTAL WAGES PAID 4127075\n",
      "0107753000.tif TOTAL WAGES PAID 3054455\n",
      "0619105000.tif TOTAL WAGES PAID 21132865\n",
      "0308610000.tif TOTAL WAGES PAID 5829000\n",
      "0550168000.tif TOTAL WAGES PAID 1938688\n",
      "0618105000.tif TOTAL WAGES PAID 2672716\n",
      "0724682000.tif TOTAL WAGES PAID 2452823\n",
      "0928685000.tif TOTAL WAGES PAID 1000000\n",
      "0655193000.tif TOTAL WAGES PAID nan\n",
      "0288014000.tif TOTAL WAGES PAID 9078103\n",
      "0750792000.tif TOTAL WAGES PAID 7559116\n",
      "0826908000.tif TOTAL WAGES PAID 100000\n",
      "0791303000.tif TOTAL WAGES PAID 3080\n",
      "0674115000.tif TOTAL WAGES PAID 750000\n",
      "0695282000.tif TOTAL WAGES PAID 2818347\n",
      "0613943000.tif TOTAL WAGES PAID 7170460\n",
      "0961211000.tif TOTAL WAGES PAID nan\n",
      "0222259000.tif TOTAL WAGES PAID 789494\n",
      "0482399000.tif TOTAL WAGES PAID 2640125\n",
      "0778944000.tif TOTAL WAGES PAID nan\n",
      "0939541000.tif TOTAL WAGES PAID 30910\n",
      "0932232000.tif TOTAL WAGES PAID 2543700\n",
      "0254933000.tif TOTAL WAGES PAID 6371529\n",
      "0912463000.tif TOTAL WAGES PAID 3888950\n",
      "0365088000.tif TOTAL WAGES PAID 1000\n",
      "0912131000.tif TOTAL WAGES PAID nan\n",
      "0769119000.tif TOTAL WAGES PAID 362283\n",
      "0774798000.tif TOTAL WAGES PAID 283\n",
      "0681971000.tif TOTAL WAGES PAID 128600\n",
      "0665692000.tif TOTAL WAGES PAID 1942633\n",
      "0771062000.tif TOTAL WAGES PAID 8762O01\n",
      "0736378000.tif TOTAL WAGES PAID 1200000\n",
      "0798560000.tif TOTAL WAGES PAID 420000\n",
      "0154722000.tif TOTAL WAGES PAID nan\n",
      "0917509000.tif TOTAL WAGES PAID 3102050\n",
      "0720565000.tif TOTAL WAGES PAID 1416700\n",
      "0667314000.tif TOTAL WAGES PAID 673076\n",
      "0120464000.tif TOTAL WAGES PAID 745000\n",
      "0109337000.tif TOTAL WAGES PAID 6047026\n",
      "0493679000.tif TOTAL WAGES PAID 11408000\n",
      "0593499000.tif TOTAL WAGES PAID 827027\n",
      "0601398000.tif TOTAL WAGES PAID 1017674\n",
      "0902033000.tif TOTAL WAGES PAID 2356507\n",
      "0916430000.tif TOTAL WAGES PAID 13676411\n",
      "0897083000.tif TOTAL WAGES PAID 356979\n",
      "0834353000.tif TOTAL WAGES PAID 17411598\n",
      "0123845000.tif TOTAL WAGES PAID 3000000\n",
      "0865071000.tif TOTAL WAGES PAID 5254789\n",
      "0606499000.tif TOTAL WAGES PAID 744047\n",
      "0136726000.tif TOTAL WAGES PAID 14113379\n",
      "0809963000.tif TOTAL WAGES PAID 3966315\n",
      "0883432000.tif TOTAL WAGES PAID 4873920\n",
      "0744472000.tif TOTAL WAGES PAID 5335148\n",
      "0214267000.tif TOTAL WAGES PAID 24173139\n",
      "0624750000.tif TOTAL WAGES PAID Jo4875\n",
      "0264945000.tif TOTAL WAGES PAID 8979818\n",
      "0316327000.tif TOTAL WAGES PAID 20800\n",
      "0939393000.tif TOTAL WAGES PAID 266334\n",
      "0105343000.tif TOTAL WAGES PAID 32748078\n",
      "0706757000.tif TOTAL WAGES PAID 2115000\n",
      "0933130000.tif TOTAL WAGES PAID 1504100\n",
      "0932102000.tif TOTAL WAGES PAID 000000\n",
      "0763217001.tif TOTAL WAGES PAID 19890C\n",
      "0670973000.tif TOTAL WAGES PAID 252322\n",
      "0186259000.tif TOTAL WAGES PAID 36150\n",
      "0855474000.tif TOTAL WAGES PAID 887400\n",
      "0698303000.tif TOTAL WAGES PAID 3666058\n",
      "0779546000.tif TOTAL WAGES PAID 3636300\n",
      "0912299000.tif TOTAL WAGES PAID 499200\n",
      "0922812000.tif TOTAL WAGES PAID 353461\n",
      "0270405000.tif TOTAL WAGES PAID 1695500\n",
      "0150651000.tif TOTAL WAGES PAID 10878672\n",
      "0632871000.tif TOTAL WAGES PAID 7926648\n",
      "0120982000.tif TOTAL WAGES PAID 1493770\n",
      "0347457000.tif TOTAL WAGES PAID nan\n",
      "0102170000.tif TOTAL WAGES PAID 24688730\n",
      "0878765000.tif TOTAL WAGES PAID 1079117\n",
      "0450933000.tif TOTAL WAGES PAID 7938622\n",
      "0709418000.tif TOTAL WAGES PAID 299000\n",
      "0657500000.tif TOTAL WAGES PAID 1653000\n",
      "0870857000.tif TOTAL WAGES PAID 17904181\n",
      "0647434000.tif TOTAL WAGES PAID 3902602\n",
      "0790464000.tif TOTAL WAGES PAID 1810450\n",
      "0876784000.tif TOTAL WAGES PAID 5101360\n",
      "0938444000.tif TOTAL WAGES PAID nan\n",
      "0443723000.tif TOTAL WAGES PAID 2118250\n",
      "0300168000.tif TOTAL WAGES PAID nan\n",
      "0402093000.tif TOTAL WAGES PAID 215806\n",
      "0571285000.tif TOTAL WAGES PAID 544500\n",
      "0950006000.tif TOTAL WAGES PAID 547050\n",
      "0599895000.tif TOTAL WAGES PAID 88022\n",
      "0233749000.tif TOTAL WAGES PAID 17001336\n",
      "0296028000.tif TOTAL WAGES PAID 780000\n",
      "0887424001.tif TOTAL WAGES PAID 429825\n",
      "0933304000.tif TOTAL WAGES PAID 282425\n",
      "0867706000.tif TOTAL WAGES PAID 1916877\n",
      "0882142000.tif TOTAL WAGES PAID 8080101\n",
      "0219814000.tif TOTAL WAGES PAID 6302080\n",
      "0621230000.tif TOTAL WAGES PAID 353340\n",
      "0632598000.tif TOTAL WAGES PAID 86336\n",
      "0553891000.tif TOTAL WAGES PAID 020000\n",
      "0274139000.tif TOTAL WAGES PAID 900000\n",
      "0462378000.tif TOTAL WAGES PAID 6333830\n",
      "0416255000.tif TOTAL WAGES PAID 810000\n",
      "0350868000.tif TOTAL WAGES PAID 4096842\n",
      "0873647000.tif TOTAL WAGES PAID 7978446\n",
      "0729435000.tif TOTAL WAGES PAID 3953066\n",
      "0313471000.tif TOTAL WAGES PAID 1466625\n",
      "0802155000.tif TOTAL WAGES PAID 317313\n",
      "0670547000.tif TOTAL WAGES PAID 16085850\n",
      "0843072000.tif TOTAL WAGES PAID 1636213\n",
      "0343925000.tif TOTAL WAGES PAID 4233\n",
      "0917783000.tif TOTAL WAGES PAID 340066\n",
      "0380534000.tif TOTAL WAGES PAID 4779545\n",
      "0434451000.tif TOTAL WAGES PAID 7521744\n",
      "0496117000.tif TOTAL WAGES PAID 334691\n",
      "0434951000.tif TOTAL WAGES PAID 2457501\n",
      "0888396000.tif TOTAL WAGES PAID 328365\n",
      "0134407000.tif TOTAL WAGES PAID 8694753\n",
      "0263612000.tif TOTAL WAGES PAID SOT42\n",
      "0367816000.tif TOTAL WAGES PAID 2620000\n",
      "0960321000.tif TOTAL WAGES PAID 1461831\n",
      "0950474000.tif TOTAL WAGES PAID 324000\n",
      "0603333000.tif TOTAL WAGES PAID 6673734\n",
      "0645812000.tif TOTAL WAGES PAID 4088991\n",
      "0928097001.tif TOTAL WAGES PAID ect\n",
      "0475796000.tif TOTAL WAGES PAID 256419\n",
      "0727920000.tif TOTAL WAGES PAID Aod\n",
      "0754579000.tif TOTAL WAGES PAID 1520800\n",
      "0906603000.tif TOTAL WAGES PAID 162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0816899000.tif TOTAL WAGES PAID 4629\n",
      "0857612000.tif TOTAL WAGES PAID 6416926\n",
      "0603643000.tif TOTAL WAGES PAID 2507305\n",
      "0792638000.tif TOTAL WAGES PAID 1032000\n",
      "0414134001.tif TOTAL WAGES PAID 419100\n",
      "0173923000.tif TOTAL WAGES PAID 2970849\n",
      "0746730000.tif TOTAL WAGES PAID 21532143\n",
      "0798409000.tif TOTAL WAGES PAID 864316\n",
      "0941240000.tif TOTAL WAGES PAID 2927500\n",
      "0745433000.tif TOTAL WAGES PAID 5255322\n",
      "0889626000.tif TOTAL WAGES PAID 1249998\n",
      "0922941001.tif TOTAL WAGES PAID 209894\n",
      "0557316000.tif TOTAL WAGES PAID 600\n",
      "0868133001.tif TOTAL WAGES PAID 334946\n",
      "0849127000.tif TOTAL WAGES PAID 12497088\n",
      "0716321001.tif TOTAL WAGES PAID 338675\n",
      "0954438000.tif TOTAL WAGES PAID 3556047\n",
      "0423173000.tif TOTAL WAGES PAID 4963118\n",
      "0137136000.tif TOTAL WAGES PAID 7299257\n",
      "0865388000.tif TOTAL WAGES PAID 00500\n",
      "0892831000.tif TOTAL WAGES PAID 3908800\n",
      "0830415000.tif TOTAL WAGES PAID 44799\n",
      "0598048000.tif TOTAL WAGES PAID 3970751\n",
      "0560522000.tif TOTAL WAGES PAID 28359226\n",
      "0872485000.tif TOTAL WAGES PAID 8414515\n",
      "0484371000.tif TOTAL WAGES PAID 5631888\n",
      "0509710000.tif TOTAL WAGES PAID 420000\n",
      "0932919000.tif TOTAL WAGES PAID 2375208\n",
      "0944759000.tif TOTAL WAGES PAID 384725\n",
      "0191294000.tif TOTAL WAGES PAID 4206600\n",
      "0183502000.tif TOTAL WAGES PAID 330632\n",
      "0469981000.tif TOTAL WAGES PAID WYP\n",
      "0233728000.tif TOTAL WAGES PAID nan\n",
      "0917801000.tif TOTAL WAGES PAID 317000\n",
      "0939537000.tif TOTAL WAGES PAID 38000\n",
      "0801812000.tif TOTAL WAGES PAID 35446765\n",
      "0830550000.tif TOTAL WAGES PAID 1386000\n",
      "0879393000.tif TOTAL WAGES PAID 750025\n",
      "0140272000.tif TOTAL WAGES PAID 2162640\n",
      "0509601000.tif TOTAL WAGES PAID 11838125\n",
      "0891470000.tif TOTAL WAGES PAID 1500000\n",
      "0139800000.tif TOTAL WAGES PAID 13294784\n",
      "0757710000.tif TOTAL WAGES PAID 11A234\n",
      "0531764000.tif TOTAL WAGES PAID 1284726\n",
      "0841493000.tif TOTAL WAGES PAID 1920000\n",
      "0866578000.tif TOTAL WAGES PAID 2638420\n",
      "0677602001.tif TOTAL WAGES PAID 4U9U15\n",
      "0871785000.tif TOTAL WAGES PAID 600000\n",
      "0294779000.tif TOTAL WAGES PAID 3321000\n",
      "0372767000.tif TOTAL WAGES PAID 791438\n",
      "0649776000.tif TOTAL WAGES PAID 648500\n",
      "0890275000.tif TOTAL WAGES PAID 235U\n",
      "0451720000.tif TOTAL WAGES PAID 130007\n",
      "0867978000.tif TOTAL WAGES PAID p37U\n",
      "0499887000.tif TOTAL WAGES PAID 2462625\n",
      "0798719000.tif TOTAL WAGES PAID 2448441\n",
      "0964434000.tif TOTAL WAGES PAID 2972900\n",
      "0820484000.tif TOTAL WAGES PAID 3425002\n",
      "0886541000.tif TOTAL WAGES PAID 2805624\n",
      "0384889000.tif TOTAL WAGES PAID 1587972\n",
      "0435512000.tif TOTAL WAGES PAID 6294280\n",
      "0868496000.tif TOTAL WAGES PAID 254792\n",
      "0541702000.tif TOTAL WAGES PAID 858624\n",
      "0609965000.tif TOTAL WAGES PAID 2111266\n",
      "0327919000.tif TOTAL WAGES PAID 372500\n",
      "0928307000.tif TOTAL WAGES PAID 4961791\n",
      "0142101000.tif TOTAL WAGES PAID 9115338\n",
      "0497648000.tif TOTAL WAGES PAID 7270600\n",
      "0772161000.tif TOTAL WAGES PAID 740250\n",
      "0956300000.tif TOTAL WAGES PAID 301500\n",
      "0737994000.tif TOTAL WAGES PAID 6956137\n",
      "0577163000.tif TOTAL WAGES PAID 634266\n",
      "0799610000.tif TOTAL WAGES PAID 1050000\n",
      "0829992000.tif TOTAL WAGES PAID 747252\n",
      "0748505000.tif TOTAL WAGES PAID 2140350\n",
      "0917802000.tif TOTAL WAGES PAID 305500\n",
      "0711625000.tif TOTAL WAGES PAID 4944C\n",
      "0258461000.tif TOTAL WAGES PAID 5589677\n",
      "0805989000.tif TOTAL WAGES PAID 250000\n",
      "0391179000.tif TOTAL WAGES PAID 200000\n",
      "0226408000.tif TOTAL WAGES PAID 32929570\n",
      "0108511000.tif TOTAL WAGES PAID 2031239\n",
      "0116003000.tif TOTAL WAGES PAID 9803792\n",
      "0249097000.tif TOTAL WAGES PAID sim\\n\\n38400\n",
      "0748579000.tif TOTAL WAGES PAID 3313800\n",
      "0115784000.tif TOTAL WAGES PAID 19295043\n",
      "0668763000.tif TOTAL WAGES PAID 200000\n",
      "0702384000.tif TOTAL WAGES PAID 4750\n",
      "0338940000.tif TOTAL WAGES PAID 286000\n",
      "0550133000.tif TOTAL WAGES PAID 5624000\n",
      "0648044000.tif TOTAL WAGES PAID 2468313\n",
      "0518750001.tif TOTAL WAGES PAID 390225\n",
      "0495704000.tif TOTAL WAGES PAID 1894000\n",
      "0462298000.tif TOTAL WAGES PAID 339404\n",
      "0879850000.tif TOTAL WAGES PAID 275321\n",
      "0501180000.tif TOTAL WAGES PAID 7942538\n",
      "0890855000.tif TOTAL WAGES PAID 8541900\n",
      "0961967000.tif TOTAL WAGES PAID nan\n",
      "0500146002.tif TOTAL WAGES PAID 410300\n",
      "0457776000.tif TOTAL WAGES PAID 10122985\n",
      "0923203000.tif TOTAL WAGES PAID 17419479\n",
      "0814009000.tif TOTAL WAGES PAID 367731\n",
      "0229049000.tif TOTAL WAGES PAID 1609396\n",
      "0481483000.tif TOTAL WAGES PAID 7787912\n",
      "0662160000.tif TOTAL WAGES PAID 10577112\n",
      "0791770000.tif TOTAL WAGES PAID 219742\n",
      "0715619000.tif TOTAL WAGES PAID nan\n",
      "0666610000.tif TOTAL WAGES PAID 5485565\n",
      "0742352000.tif TOTAL WAGES PAID 9751333\n",
      "0590489000.tif TOTAL WAGES PAID 5965508\n",
      "0710189000.tif TOTAL WAGES PAID 233893\n",
      "0419295000.tif TOTAL WAGES PAID 00000\n",
      "0311030000.tif TOTAL WAGES PAID 4401666\n",
      "0917213000.tif TOTAL WAGES PAID 386925\n",
      "0649282000.tif TOTAL WAGES PAID 3222700\n",
      "0301211000.tif TOTAL WAGES PAID 4120360\n",
      "0762946000.tif TOTAL WAGES PAID 1500000\n",
      "0749946000.tif TOTAL WAGES PAID 2206996\n",
      "0753838000.tif TOTAL WAGES PAID 45923803\n",
      "0502696000.tif TOTAL WAGES PAID nan\n",
      "0344977000.tif TOTAL WAGES PAID 5503070\n",
      "0938877000.tif TOTAL WAGES PAID 085788\n",
      "0860458000.tif TOTAL WAGES PAID 900000\n",
      "0905808000.tif TOTAL WAGES PAID 980213\n",
      "0736346000.tif TOTAL WAGES PAID 3750000\n",
      "0358542000.tif TOTAL WAGES PAID 4166759\n",
      "0929280000.tif TOTAL WAGES PAID 5090818\n",
      "0175195000.tif TOTAL WAGES PAID 16603095\n",
      "0730803000.tif TOTAL WAGES PAID 30878275\n",
      "0589080000.tif TOTAL WAGES PAID 7869064\n",
      "0877495000.tif TOTAL WAGES PAID 49000\n",
      "0928403000.tif TOTAL WAGES PAID 1580000\n",
      "0573626000.tif TOTAL WAGES PAID nan\n",
      "0314814000.tif TOTAL WAGES PAID 2451\n",
      "0356369000.tif TOTAL WAGES PAID 4193025\n",
      "0420062000.tif TOTAL WAGES PAID 94000\n",
      "0961895000.tif TOTAL WAGES PAID 166100\n",
      "0900699002.tif TOTAL WAGES PAID 353\n",
      "0328878000.tif TOTAL WAGES PAID 1004499\n",
      "0781045000.tif TOTAL WAGES PAID 344361\n",
      "0928096000.tif TOTAL WAGES PAID 373000\n",
      "0912375000.tif TOTAL WAGES PAID nan\n",
      "0120321000.tif TOTAL WAGES PAID 10041882\n",
      "0424476000.tif TOTAL WAGES PAID 4316767\n",
      "0891942000.tif TOTAL WAGES PAID 347986\n",
      "0477625000.tif TOTAL WAGES PAID 339215\n",
      "0885006000.tif TOTAL WAGES PAID 585950\n",
      "0893067001.tif TOTAL WAGES PAID 794000\n",
      "0876648000.tif TOTAL WAGES PAID 2624550\n",
      "0612066000.tif TOTAL WAGES PAID nan\n",
      "0882568000.tif TOTAL WAGES PAID 389001\n",
      "0916062000.tif TOTAL WAGES PAID 2000000\n",
      "0890200000.tif TOTAL WAGES PAID 34250\n",
      "0689089000.tif TOTAL WAGES PAID 393123\n",
      "0607227000.tif TOTAL WAGES PAID 12627\n",
      "0885313000.tif TOTAL WAGES PAID nan\n",
      "0278379000.tif TOTAL WAGES PAID 2831992\n",
      "0950478000.tif TOTAL WAGES PAID 326800\n",
      "0955593000.tif TOTAL WAGES PAID 2997510\n",
      "0791862000.tif TOTAL WAGES PAID 3499469\n",
      "0598452000.tif TOTAL WAGES PAID 51652\n",
      "0666501000.tif TOTAL WAGES PAID 34600\n",
      "0489279000.tif TOTAL WAGES PAID 096814\n",
      "0641445001.tif TOTAL WAGES PAID 385000\n",
      "0372748000.tif TOTAL WAGES PAID 23911592\n",
      "0447623000.tif TOTAL WAGES PAID 932000\n",
      "0622550000.tif TOTAL WAGES PAID F00006\n",
      "0518979000.tif TOTAL WAGES PAID 411450\n",
      "0377389000.tif TOTAL WAGES PAID 442500\n",
      "0711520000.tif TOTAL WAGES PAID 3512177\n",
      "0914255001.tif TOTAL WAGES PAID 416075\n",
      "0896443000.tif TOTAL WAGES PAID 1177700\n",
      "0912296000.tif TOTAL WAGES PAID 405000\n",
      "0939303000.tif TOTAL WAGES PAID 1024803\n",
      "0412027000.tif TOTAL WAGES PAID nan\n",
      "0891827000.tif TOTAL WAGES PAID 309537\n",
      "0349890000.tif TOTAL WAGES PAID 7276401\n",
      "0270552000.tif TOTAL WAGES PAID 10741644\n",
      "0339544000.tif TOTAL WAGES PAID 4967663\n",
      "0854946000.tif TOTAL WAGES PAID 372733\n",
      "0667394003.tif TOTAL WAGES PAID 45390C\n",
      "0902476000.tif TOTAL WAGES PAID 11790266\n",
      "0323744000.tif TOTAL WAGES PAID 25981331\n",
      "0130202000.tif TOTAL WAGES PAID 3Sela\n",
      "0144206000.tif TOTAL WAGES PAID 23510AS\n",
      "0624479000.tif TOTAL WAGES PAID 2531600\n",
      "0110864000.tif TOTAL WAGES PAID 4782560\n",
      "0905223000.tif TOTAL WAGES PAID 128855\n",
      "0880398001.tif TOTAL WAGES PAID 5544\n",
      "0582403000.tif TOTAL WAGES PAID 2400000\n",
      "0388172000.tif TOTAL WAGES PAID 5958378\n",
      "0917915000.tif TOTAL WAGES PAID 2442400\n",
      "0547555000.tif TOTAL WAGES PAID 852000\n",
      "0404543000.tif TOTAL WAGES PAID 1718653\n",
      "0455876000.tif TOTAL WAGES PAID 3984000\n",
      "0643814000.tif TOTAL WAGES PAID 195000\n",
      "0610172002.tif TOTAL WAGES PAID piss\n",
      "0688952000.tif TOTAL WAGES PAID 007570\n",
      "0662677000.tif TOTAL WAGES PAID 3309590\n",
      "0872245000.tif TOTAL WAGES PAID 1500000\n",
      "0564406000.tif TOTAL WAGES PAID 039490\n",
      "0571522000.tif TOTAL WAGES PAID 2730000\n",
      "0486405000.tif TOTAL WAGES PAID 790000\n",
      "0959929000.tif TOTAL WAGES PAID 600000\n",
      "0197054000.tif TOTAL WAGES PAID 2160000\n",
      "0573498002.tif TOTAL WAGES PAID 325429\n",
      "0784707000.tif TOTAL WAGES PAID 835882\n",
      "0882564000.tif TOTAL WAGES PAID 341219\n",
      "0330764000.tif TOTAL WAGES PAID 4868916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0450140000.tif TOTAL WAGES PAID 446670\n",
      "0737250000.tif TOTAL WAGES PAID 14818243\n",
      "0621386000.tif TOTAL WAGES PAID 2053848\n",
      "0118105000.tif TOTAL WAGES PAID 4672925\n",
      "0450154000.tif TOTAL WAGES PAID 86S494\n",
      "0852526000.tif TOTAL WAGES PAID 940652\n",
      "0633979000.tif TOTAL WAGES PAID 3595576\n",
      "0381002000.tif TOTAL WAGES PAID 627100\n",
      "0904175000.tif TOTAL WAGES PAID 289680\n",
      "0305040000.tif TOTAL WAGES PAID 6050\n",
      "0693359000.tif TOTAL WAGES PAID 6907166\n",
      "0286199000.tif TOTAL WAGES PAID 785268\n",
      "0535100000.tif TOTAL WAGES PAID 2145000\n",
      "0623205000.tif TOTAL WAGES PAID 164310\n",
      "0576298000.tif TOTAL WAGES PAID 239855\n",
      "0906485000.tif TOTAL WAGES PAID 3685580\n",
      "0681766000.tif TOTAL WAGES PAID 3229618\n",
      "0885263000.tif TOTAL WAGES PAID 201025\n",
      "0296923000.tif TOTAL WAGES PAID 79486\n",
      "0734805000.tif TOTAL WAGES PAID 1001455\n",
      "0801417000.tif TOTAL WAGES PAID 1138197\n",
      "0587994000.tif TOTAL WAGES PAID 839504\n",
      "0906474000.tif TOTAL WAGES PAID nan\n",
      "0598493000.tif TOTAL WAGES PAID 5598650\n",
      "0950476000.tif TOTAL WAGES PAID 327000\n",
      "0365338000.tif TOTAL WAGES PAID 3379562\n",
      "0581672000.tif TOTAL WAGES PAID 14000O1\n",
      "0622711000.tif TOTAL WAGES PAID 368769\n",
      "0912421000.tif TOTAL WAGES PAID 4073998\n",
      "0667917000.tif TOTAL WAGES PAID 1260963\n",
      "0961795000.tif TOTAL WAGES PAID 771972\n",
      "0265290000.tif TOTAL WAGES PAID 1178093\n",
      "0390097000.tif TOTAL WAGES PAID 7819628\n",
      "0950475000.tif TOTAL WAGES PAID 324000\n",
      "0580290000.tif TOTAL WAGES PAID 7737116\n",
      "0397034000.tif TOTAL WAGES PAID 11700\n",
      "0304347000.tif TOTAL WAGES PAID 1810394\n",
      "0835953000.tif TOTAL WAGES PAID 6351342\n",
      "0719339000.tif TOTAL WAGES PAID 87000\n",
      "0393102000.tif TOTAL WAGES PAID 5285630\n",
      "0591194000.tif TOTAL WAGES PAID 62984340\n",
      "0617250000.tif TOTAL WAGES PAID 12250603\n",
      "0919151000.tif TOTAL WAGES PAID 807500\n",
      "0692253000.tif TOTAL WAGES PAID IAIS450\n",
      "0558226000.tif TOTAL WAGES PAID 600000\n",
      "0877101000.tif TOTAL WAGES PAID 14955519\n",
      "0458883000.tif TOTAL WAGES PAID 1844384\n",
      "0911520000.tif TOTAL WAGES PAID 3954989\n",
      "0958394000.tif TOTAL WAGES PAID 2353628\n",
      "0530846002.tif TOTAL WAGES PAID 118S60\n",
      "0499769000.tif TOTAL WAGES PAID 249600\n"
     ]
    }
   ],
   "source": [
    "def twgp()    \n",
    "    import matplotlib.image as mpimg\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    from fuzzywuzzy import fuzz\n",
    "    from fuzzywuzzy import process\n",
    "    import cv2\n",
    "    import os\n",
    "    import math\n",
    "    import sys\n",
    "    import numpy as np\n",
    "    import pytesseract\n",
    "    import io \n",
    "    import csv\n",
    "    import pandas as pd\n",
    "    import shutil, os\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    #file_name = '0100477000.jpeg'\n",
    "\n",
    "    path = '/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input'\n",
    "    for file_name in os.listdir(path):\n",
    "        #print(file_name)\n",
    "        shutil.copytree('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/sample', \n",
    "            os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                     os.path.splitext(file_name)[0]))\n",
    "\n",
    "        img = mpimg.imread(os.path.join\n",
    "                           ('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input',\n",
    "                            file_name))\n",
    "        width = img.shape[1]\n",
    "        height = img.shape[0]\n",
    "        wi = width * 0.95\n",
    "        he = height * 0.3\n",
    "        w = int(wi)\n",
    "        h = int(he)\n",
    "        y = 0\n",
    "        x1 = w * 0.45\n",
    "        x = int(x1)\n",
    "        crop = img[y:y+h, x:x+w]\n",
    "        #plt.imshow(crop)\n",
    "        im = Image.fromarray(crop)\n",
    "        b = os.path.splitext(file_name)[0]+'_crop.jpeg'\n",
    "        im.save(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                               os.path.splitext(file_name)[0],'crop',b))\n",
    "        def extract_cell_images_from_table(image):\n",
    "            BLUR_KERNEL_SIZE = (17, 17)\n",
    "            STD_DEV_X_DIRECTION = 0\n",
    "            STD_DEV_Y_DIRECTION = 0\n",
    "            blurred = cv2.GaussianBlur(image, BLUR_KERNEL_SIZE, STD_DEV_X_DIRECTION, STD_DEV_Y_DIRECTION)\n",
    "            MAX_COLOR_VAL = 255\n",
    "            BLOCK_SIZE = 15\n",
    "            SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "            img_bin = cv2.adaptiveThreshold(\n",
    "                ~blurred,\n",
    "                MAX_COLOR_VAL,\n",
    "                cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                cv2.THRESH_BINARY,\n",
    "                BLOCK_SIZE,\n",
    "                SUBTRACT_FROM_MEAN,\n",
    "            )\n",
    "            vertical = horizontal = img_bin.copy()\n",
    "            SCALE = 5\n",
    "            image_width, image_height = horizontal.shape\n",
    "            horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(image_width / SCALE), 1))\n",
    "            horizontally_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "            vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(image_height / SCALE)))\n",
    "            vertically_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "\n",
    "            horizontally_dilated = cv2.dilate(horizontally_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1)))\n",
    "            vertically_dilated = cv2.dilate(vertically_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (1, 60)))\n",
    "\n",
    "            mask = horizontally_dilated + vertically_dilated\n",
    "            contours, heirarchy = cv2.findContours(\n",
    "                mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE,\n",
    "            )\n",
    "\n",
    "            perimeter_lengths = [cv2.arcLength(c, True) for c in contours]\n",
    "            epsilons = [0.05 * p for p in perimeter_lengths]\n",
    "            approx_polys = [cv2.approxPolyDP(c, e, True) for c, e in zip(contours, epsilons)]\n",
    "\n",
    "            # Filter out contours that aren't rectangular. Those that aren't rectangular\n",
    "            # are probably noise.\n",
    "            approx_rects = [p for p in approx_polys if len(p) == 4]\n",
    "            bounding_rects = [cv2.boundingRect(a) for a in approx_polys]\n",
    "\n",
    "            # Filter out rectangles that are too narrow or too short.\n",
    "            MIN_RECT_WIDTH = 40\n",
    "            MIN_RECT_HEIGHT = 10\n",
    "            bounding_rects = [\n",
    "                r for r in bounding_rects if MIN_RECT_WIDTH < r[2] and MIN_RECT_HEIGHT < r[3]\n",
    "            ]\n",
    "\n",
    "            # The largest bounding rectangle is assumed to be the entire table.\n",
    "            # Remove it from the list. We don't want to accidentally try to OCR\n",
    "            # the entire table.\n",
    "            largest_rect = max(bounding_rects, key=lambda r: r[2] * r[3])\n",
    "            bounding_rects = [b for b in bounding_rects if b is not largest_rect]\n",
    "\n",
    "            cells = [c for c in bounding_rects]\n",
    "            def cell_in_same_row(c1, c2):\n",
    "                c1_center = c1[1] + c1[3] - c1[3] / 2\n",
    "                c2_bottom = c2[1] + c2[3]\n",
    "                c2_top = c2[1]\n",
    "                return c2_top < c1_center < c2_bottom\n",
    "\n",
    "            orig_cells = [c for c in cells]\n",
    "            rows = []\n",
    "            while cells:\n",
    "                first = cells[0]\n",
    "                rest = cells[1:]\n",
    "                cells_in_same_row = sorted(\n",
    "                    [\n",
    "                        c for c in rest\n",
    "                        if cell_in_same_row(c, first)\n",
    "                    ],\n",
    "                    key=lambda c: c[0]\n",
    "                )\n",
    "\n",
    "                row_cells = sorted([first] + cells_in_same_row, key=lambda c: c[0])\n",
    "                rows.append(row_cells)\n",
    "                cells = [\n",
    "                    c for c in rest\n",
    "                    if not cell_in_same_row(c, first)\n",
    "                ]\n",
    "\n",
    "            # Sort rows by average height of their center.\n",
    "            def avg_height_of_center(row):\n",
    "                centers = [y + h - h / 2 for x, y, w, h in row]\n",
    "                return sum(centers) / len(centers)\n",
    "\n",
    "            rows.sort(key=avg_height_of_center)\n",
    "            cell_images_rows = []\n",
    "            for row in rows:\n",
    "                cell_images_row = []\n",
    "                for x, y, w, h in row:\n",
    "                    cell_images_row.append(image[y:y+h, x:x+w])\n",
    "                cell_images_rows.append(cell_images_row)\n",
    "            return cell_images_rows\n",
    "\n",
    "        def main(f):\n",
    "            results = []\n",
    "            directory, filename = os.path.split(f)\n",
    "            table = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "            rows = extract_cell_images_from_table(table)\n",
    "            #cell_img_dir = os.path.join(directory, \"cells\")\n",
    "            #os.makedirs(cell_img_dir, exist_ok=True)\n",
    "            out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                    os.path.splitext(file_name)[0],'cells')\n",
    "            paths = []\n",
    "            for i, row in enumerate(rows):\n",
    "                for j, cell in enumerate(row):\n",
    "                    cell_filename = \"{:03d}-{:03d}.png\".format(i, j)\n",
    "                    path = os.path.join(out_path, cell_filename)\n",
    "                    cv2.imwrite(path, cell)\n",
    "                    paths.append(path)\n",
    "            return paths\n",
    "\n",
    "        f = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                               os.path.splitext(file_name)[0],'crop',b)\n",
    "        main(f)\n",
    "\n",
    "        def main(image_file, tess_args):\n",
    "            \"\"\"\n",
    "            OCR the image and output the text to a file with an extension that is ready\n",
    "            to be used in Tesseract training (.gt.txt).\n",
    "            Tries to crop the image so that only the relevant text gets passed to Tesseract.\n",
    "            Returns the name of the text file that contains the text.\n",
    "            \"\"\"\n",
    "            #file_path = '/home/vimal/Documents/table_detect_samples/structured images/input/011364700/cells'\n",
    "            #image_file = os.listdir(file_path)\n",
    "\n",
    "            for f in image_file:\n",
    "                #print(f)\n",
    "                directory, filename = os.path.split(f)\n",
    "                filename_sans_ext, ext = os.path.splitext(filename)\n",
    "                image = cv2.imread(os.path.join(file_path,f), cv2.IMREAD_GRAYSCALE)\n",
    "                cropped = crop_to_text(image)\n",
    "                #ocr_data_dir = os.path.join(directory, \"ocr_data\")\n",
    "                #os.makedirs(ocr_data_dir, exist_ok=True)\n",
    "                #out_imagepath = os.path.join(ocr_data_dir, filename)\n",
    "                out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                    os.path.splitext(file_name)[0],'text')\n",
    "                out_txtpath = os.path.join(out_path, \"{}.txt\".format(filename_sans_ext))\n",
    "                #cv2.imwrite(out_imagepath, cropped)\n",
    "                if not tess_args:\n",
    "                    d = os.path.dirname(sys.modules[\"table_ocr\"].__file__)\n",
    "                    tessdata_dir = os.path.join(d, \"tessdata\")\n",
    "                    tess_args = [\"--psm\", \"7\", \"-l\", \"table-ocr\", \"--tessdata-dir\", tessdata_dir]\n",
    "                txt = ocr_image(cropped, \" \".join(tess_args))\n",
    "                with open(out_txtpath, \"w\") as txt_file:\n",
    "                    txt_file.write(txt)\n",
    "                #return out_txtpath\n",
    "        def crop_to_text(image):\n",
    "            MAX_COLOR_VAL = 255\n",
    "            BLOCK_SIZE = 15\n",
    "            SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "            img_bin = cv2.adaptiveThreshold(\n",
    "                ~image,\n",
    "                MAX_COLOR_VAL,\n",
    "                cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                cv2.THRESH_BINARY,\n",
    "                BLOCK_SIZE,\n",
    "                SUBTRACT_FROM_MEAN,\n",
    "            )\n",
    "\n",
    "            img_h, img_w = image.shape\n",
    "            horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(img_w * 0.5), 1))\n",
    "            vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(img_h * 0.7)))\n",
    "            horizontal_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "            vertical_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "            both = horizontal_lines + vertical_lines\n",
    "            cleaned = img_bin - both\n",
    "\n",
    "            # Get rid of little noise.\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "            opened = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)\n",
    "            opened = cv2.dilate(opened, kernel)\n",
    "\n",
    "            contours, hierarchy = cv2.findContours(opened, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            bounding_rects = [cv2.boundingRect(c) for c in contours]\n",
    "            NUM_PX_COMMA = 6\n",
    "            MIN_CHAR_AREA = 5 * 9\n",
    "            char_sized_bounding_rects = [(x, y, w, h) for x, y, w, h in bounding_rects if w * h > MIN_CHAR_AREA]\n",
    "            if char_sized_bounding_rects:\n",
    "                minx, miny, maxx, maxy = math.inf, math.inf, 0, 0\n",
    "                for x, y, w, h in char_sized_bounding_rects:\n",
    "                    minx = min(minx, x)\n",
    "                    miny = min(miny, y)\n",
    "                    maxx = max(maxx, x + w)\n",
    "                    maxy = max(maxy, y + h)\n",
    "                x, y, w, h = minx, miny, maxx - minx, maxy - miny\n",
    "                cropped = image[y:min(img_h, y+h+NUM_PX_COMMA), x:min(img_w, x+w)]\n",
    "            else:\n",
    "                # If we morphed out all of the text, assume an empty image.\n",
    "                cropped = MAX_COLOR_VAL * np.ones(shape=(20, 100), dtype=np.uint8)\n",
    "            bordered = cv2.copyMakeBorder(cropped, 5, 5, 5, 5, cv2.BORDER_CONSTANT, None, 255)\n",
    "            return bordered\n",
    "        def ocr_image(image, config):\n",
    "            return pytesseract.image_to_string(\n",
    "                image,\n",
    "                lang='eng', config='--psm 11'\n",
    "            )\n",
    "\n",
    "        file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                    os.path.splitext(file_name)[0],'cells')\n",
    "        image_file = os.listdir(file_path)\n",
    "        tess_args = os.listdir(file_path)\n",
    "\n",
    "        main(image_file, tess_args)\n",
    "\n",
    "        def text_files_to_csv(files):\n",
    "            \"\"\"Files must be sorted lexicographically\n",
    "            Filenames must be <row>-<colum>.txt.\n",
    "            000-000.txt\n",
    "            000-001.txt\n",
    "            001-000.txt\n",
    "            etc...\n",
    "            \"\"\"\n",
    "            rows = []\n",
    "            for f in files:\n",
    "                directory, filename = os.path.split(f)\n",
    "                with open(os.path.join(file_path,f)) as of:\n",
    "                    txt = of.read().strip()\n",
    "                row, column = map(int, filename.split(\".\")[0].split(\"-\"))\n",
    "                if row == len(rows):\n",
    "                    rows.append([])\n",
    "                rows[row].append(txt)\n",
    "\n",
    "            csv_file = io.StringIO()\n",
    "            writer = csv.writer(csv_file)\n",
    "            writer.writerows(rows)\n",
    "            return csv_file.getvalue()\n",
    "\n",
    "        def main(files):\n",
    "            return text_files_to_csv(files)\n",
    "\n",
    "\n",
    "        file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                    os.path.splitext(file_name)[0],'text')\n",
    "        file = os.listdir(file_path)\n",
    "        files = sorted(file)\n",
    "\n",
    "        a = main(files)\n",
    "        #print(a)\n",
    "\n",
    "        c = os.path.splitext(file_name)[0]+'_text.txt'\n",
    "        t = os.path.splitext(file_name)[0]+'_f-text.txt'\n",
    "\n",
    "        #cs = os.path.splitext(file_name)[0]+'_xl.csv'\n",
    "\n",
    "        text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                    os.path.splitext(file_name)[0],'txt',c), \"wt\")\n",
    "        n = text_file.write(a)\n",
    "        text_file.close()\n",
    "\n",
    "        df = pd.read_csv(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                    os.path.splitext(file_name)[0],'txt',c),\n",
    "            header=None,delimiter=',',names=list(range(10)))\n",
    "        df[1] = df[1].astype(str)\n",
    "        #print(df)\n",
    "\n",
    "        df1 = df.dropna(axis = 0,how = 'all')\n",
    "        #print(df1)\n",
    "\n",
    "        word = 'TOTAL WAGES PAID'\n",
    "\n",
    "\n",
    "\n",
    "        if df1[0].dtypes != 'object':\n",
    "            print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',0)\n",
    "\n",
    "        else:\n",
    "\n",
    "            for i in df1[0]:\n",
    "                if fuzz.ratio(word,str(i)) > 80:\n",
    "                    #print(i)\n",
    "                    dff = df1[df1[0] == i]\n",
    "                    dff = dff.dropna(axis = 1,how = 'all')\n",
    "                    output = dff[1]\n",
    "                    output = output.str.replace(r'[^\\w\\s]+', '')\n",
    "                    output = output.str.replace(\" \",\"\")\n",
    "                    #print(output)\n",
    "\n",
    "                    if len(output) == 0:\n",
    "                        print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',0)\n",
    "                    else:\n",
    "                        with open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                                os.path.splitext(file_name)[0],'final_text',t), 'a') as f:\n",
    "                            f.write(output.to_string(header = False, index = False))\n",
    "\n",
    "                        text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                                os.path.splitext(file_name)[0],'final_text',t), 'r+')\n",
    "\n",
    "                        print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',text_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b8b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twp(file_name):\n",
    "    import matplotlib.image as mpimg\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    from fuzzywuzzy import fuzz\n",
    "    from fuzzywuzzy import process\n",
    "    import cv2\n",
    "    import os\n",
    "    import math\n",
    "    import sys\n",
    "    import numpy as np\n",
    "    import pytesseract\n",
    "    import io \n",
    "    import csv\n",
    "    import pandas as pd\n",
    "    import shutil, os\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    #file_name = '0100477000.jpeg'\n",
    "\n",
    "    #path = '/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input'\n",
    "    #for file_name in os.listdir(path):\n",
    "        #print(file_name)\n",
    "    shutil.copytree('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/sample', \n",
    "        os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                     os.path.splitext(file_name)[0]))\n",
    "\n",
    "    img = mpimg.imread(os.path.join\n",
    "                           ('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input/input',\n",
    "                            file_name))\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "    wi = width * 0.95\n",
    "    he = height * 0.3\n",
    "    w = int(wi)\n",
    "    h = int(he)\n",
    "    y = 0\n",
    "    x1 = w * 0.45\n",
    "    x = int(x1)\n",
    "    crop = img[y:y+h, x:x+w]\n",
    "    #plt.imshow(crop)\n",
    "    im = Image.fromarray(crop)\n",
    "    b = os.path.splitext(file_name)[0]+'_crop.jpeg'\n",
    "    im.save(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                               os.path.splitext(file_name)[0],'crop',b))\n",
    "    def extract_cell_images_from_table(image):\n",
    "        BLUR_KERNEL_SIZE = (17, 17)\n",
    "        STD_DEV_X_DIRECTION = 0\n",
    "        STD_DEV_Y_DIRECTION = 0\n",
    "        blurred = cv2.GaussianBlur(image, BLUR_KERNEL_SIZE, STD_DEV_X_DIRECTION, STD_DEV_Y_DIRECTION)\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~blurred,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "        vertical = horizontal = img_bin.copy()\n",
    "        SCALE = 5\n",
    "        image_width, image_height = horizontal.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(image_width / SCALE), 1))\n",
    "        horizontally_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(image_height / SCALE)))\n",
    "        vertically_opened = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "\n",
    "        horizontally_dilated = cv2.dilate(horizontally_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1)))\n",
    "        vertically_dilated = cv2.dilate(vertically_opened, cv2.getStructuringElement(cv2.MORPH_RECT, (1, 60)))\n",
    "\n",
    "        mask = horizontally_dilated + vertically_dilated\n",
    "        contours, heirarchy = cv2.findContours(\n",
    "            mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE,\n",
    "        )\n",
    "\n",
    "        perimeter_lengths = [cv2.arcLength(c, True) for c in contours]\n",
    "        epsilons = [0.05 * p for p in perimeter_lengths]\n",
    "        approx_polys = [cv2.approxPolyDP(c, e, True) for c, e in zip(contours, epsilons)]\n",
    "\n",
    "        # Filter out contours that aren't rectangular. Those that aren't rectangular\n",
    "        # are probably noise.\n",
    "        approx_rects = [p for p in approx_polys if len(p) == 4]\n",
    "        bounding_rects = [cv2.boundingRect(a) for a in approx_polys]\n",
    "\n",
    "        # Filter out rectangles that are too narrow or too short.\n",
    "        MIN_RECT_WIDTH = 40\n",
    "        MIN_RECT_HEIGHT = 10\n",
    "        bounding_rects = [\n",
    "            r for r in bounding_rects if MIN_RECT_WIDTH < r[2] and MIN_RECT_HEIGHT < r[3]\n",
    "        ]\n",
    "\n",
    "        # The largest bounding rectangle is assumed to be the entire table.\n",
    "        # Remove it from the list. We don't want to accidentally try to OCR\n",
    "        # the entire table.\n",
    "        largest_rect = max(bounding_rects, key=lambda r: r[2] * r[3])\n",
    "        bounding_rects = [b for b in bounding_rects if b is not largest_rect]\n",
    "\n",
    "        cells = [c for c in bounding_rects]\n",
    "        def cell_in_same_row(c1, c2):\n",
    "            c1_center = c1[1] + c1[3] - c1[3] / 2\n",
    "            c2_bottom = c2[1] + c2[3]\n",
    "            c2_top = c2[1]\n",
    "            return c2_top < c1_center < c2_bottom\n",
    "\n",
    "        orig_cells = [c for c in cells]\n",
    "        rows = []\n",
    "        while cells:\n",
    "            first = cells[0]\n",
    "            rest = cells[1:]\n",
    "            cells_in_same_row = sorted(\n",
    "                [\n",
    "                    c for c in rest\n",
    "                    if cell_in_same_row(c, first)\n",
    "                ],\n",
    "                key=lambda c: c[0]\n",
    "            )\n",
    "\n",
    "            row_cells = sorted([first] + cells_in_same_row, key=lambda c: c[0])\n",
    "            rows.append(row_cells)\n",
    "            cells = [\n",
    "                c for c in rest\n",
    "                if not cell_in_same_row(c, first)\n",
    "            ]\n",
    "\n",
    "        # Sort rows by average height of their center.\n",
    "        def avg_height_of_center(row):\n",
    "            centers = [y + h - h / 2 for x, y, w, h in row]\n",
    "            return sum(centers) / len(centers)\n",
    "\n",
    "        rows.sort(key=avg_height_of_center)\n",
    "        cell_images_rows = []\n",
    "        for row in rows:\n",
    "            cell_images_row = []\n",
    "            for x, y, w, h in row:\n",
    "                cell_images_row.append(image[y:y+h, x:x+w])\n",
    "            cell_images_rows.append(cell_images_row)\n",
    "        return cell_images_rows\n",
    "\n",
    "    def main(f):\n",
    "        results = []\n",
    "        directory, filename = os.path.split(f)\n",
    "        table = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
    "        rows = extract_cell_images_from_table(table)\n",
    "        #cell_img_dir = os.path.join(directory, \"cells\")\n",
    "        #os.makedirs(cell_img_dir, exist_ok=True)\n",
    "        out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                    os.path.splitext(file_name)[0],'cells')\n",
    "        paths = []\n",
    "        for i, row in enumerate(rows):\n",
    "            for j, cell in enumerate(row):\n",
    "                cell_filename = \"{:03d}-{:03d}.png\".format(i, j)\n",
    "                path = os.path.join(out_path, cell_filename)\n",
    "                cv2.imwrite(path, cell)\n",
    "                paths.append(path)\n",
    "        return paths\n",
    "\n",
    "    f = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                               os.path.splitext(file_name)[0],'crop',b)\n",
    "    main(f)\n",
    "\n",
    "    def main(image_file, tess_args):\n",
    "        \"\"\"\n",
    "        OCR the image and output the text to a file with an extension that is ready\n",
    "        to be used in Tesseract training (.gt.txt).\n",
    "        Tries to crop the image so that only the relevant text gets passed to Tesseract.\n",
    "        Returns the name of the text file that contains the text.\n",
    "        \"\"\"\n",
    "        #file_path = '/home/vimal/Documents/table_detect_samples/structured images/input/011364700/cells'\n",
    "        #image_file = os.listdir(file_path)\n",
    "\n",
    "        for f in image_file:\n",
    "            #print(f)\n",
    "            directory, filename = os.path.split(f)\n",
    "            filename_sans_ext, ext = os.path.splitext(filename)\n",
    "            image = cv2.imread(os.path.join(file_path,f), cv2.IMREAD_GRAYSCALE)\n",
    "            cropped = crop_to_text(image)\n",
    "            #ocr_data_dir = os.path.join(directory, \"ocr_data\")\n",
    "            #os.makedirs(ocr_data_dir, exist_ok=True)\n",
    "            #out_imagepath = os.path.join(ocr_data_dir, filename)\n",
    "            out_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                    os.path.splitext(file_name)[0],'text')\n",
    "            out_txtpath = os.path.join(out_path, \"{}.txt\".format(filename_sans_ext))\n",
    "            #cv2.imwrite(out_imagepath, cropped)\n",
    "            if not tess_args:\n",
    "                d = os.path.dirname(sys.modules[\"table_ocr\"].__file__)\n",
    "                tessdata_dir = os.path.join(d, \"tessdata\")\n",
    "                tess_args = [\"--psm\", \"11\", \"-l\", \"table-ocr\", \"--tessdata-dir\", tessdata_dir]\n",
    "            txt = ocr_image(cropped, \" \".join(tess_args))\n",
    "            with open(out_txtpath, \"w\") as txt_file:\n",
    "                txt_file.write(txt)\n",
    "            #return out_txtpath\n",
    "    def crop_to_text(image):\n",
    "        MAX_COLOR_VAL = 255\n",
    "        BLOCK_SIZE = 15\n",
    "        SUBTRACT_FROM_MEAN = -2\n",
    "\n",
    "        img_bin = cv2.adaptiveThreshold(\n",
    "            ~image,\n",
    "            MAX_COLOR_VAL,\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,\n",
    "            BLOCK_SIZE,\n",
    "            SUBTRACT_FROM_MEAN,\n",
    "        )\n",
    "\n",
    "        img_h, img_w = image.shape\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (int(img_w * 0.5), 1))\n",
    "        vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, int(img_h * 0.7)))\n",
    "        horizontal_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        vertical_lines = cv2.morphologyEx(img_bin, cv2.MORPH_OPEN, vertical_kernel)\n",
    "        both = horizontal_lines + vertical_lines\n",
    "        cleaned = img_bin - both\n",
    "\n",
    "        # Get rid of little noise.\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        opened = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)\n",
    "        opened = cv2.dilate(opened, kernel)\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(opened, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        bounding_rects = [cv2.boundingRect(c) for c in contours]\n",
    "        NUM_PX_COMMA = 6\n",
    "        MIN_CHAR_AREA = 5 * 9\n",
    "        char_sized_bounding_rects = [(x, y, w, h) for x, y, w, h in bounding_rects if w * h > MIN_CHAR_AREA]\n",
    "        if char_sized_bounding_rects:\n",
    "            minx, miny, maxx, maxy = math.inf, math.inf, 0, 0\n",
    "            for x, y, w, h in char_sized_bounding_rects:\n",
    "                minx = min(minx, x)\n",
    "                miny = min(miny, y)\n",
    "                maxx = max(maxx, x + w)\n",
    "                maxy = max(maxy, y + h)\n",
    "            x, y, w, h = minx, miny, maxx - minx, maxy - miny\n",
    "            cropped = image[y:min(img_h, y+h+NUM_PX_COMMA), x:min(img_w, x+w)]\n",
    "        else:\n",
    "            # If we morphed out all of the text, assume an empty image.\n",
    "            cropped = MAX_COLOR_VAL * np.ones(shape=(20, 100), dtype=np.uint8)\n",
    "        bordered = cv2.copyMakeBorder(cropped, 5, 5, 5, 5, cv2.BORDER_CONSTANT, None, 255)\n",
    "        return bordered\n",
    "    def ocr_image(image, config):\n",
    "        return pytesseract.image_to_string(\n",
    "            image,\n",
    "            lang='eng', config='psm--11'\n",
    "        )\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                    os.path.splitext(file_name)[0],'cells')\n",
    "    image_file = os.listdir(file_path)\n",
    "    tess_args = os.listdir(file_path)\n",
    "\n",
    "    main(image_file, tess_args)\n",
    "\n",
    "    def text_files_to_csv(files):\n",
    "        \"\"\"Files must be sorted lexicographically\n",
    "        Filenames must be <row>-<colum>.txt.\n",
    "        000-000.txt\n",
    "        000-001.txt\n",
    "        001-000.txt\n",
    "        etc...\n",
    "        \"\"\"\n",
    "        rows = []\n",
    "        for f in files:\n",
    "            directory, filename = os.path.split(f)\n",
    "            with open(os.path.join(file_path,f)) as of:\n",
    "                txt = of.read().strip()\n",
    "            row, column = map(int, filename.split(\".\")[0].split(\"-\"))\n",
    "            if row == len(rows):\n",
    "                rows.append([])\n",
    "            rows[row].append(txt)\n",
    "\n",
    "        csv_file = io.StringIO()\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerows(rows)\n",
    "        return csv_file.getvalue()\n",
    "\n",
    "    def main(files):\n",
    "        return text_files_to_csv(files)\n",
    "\n",
    "\n",
    "    file_path = os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                    os.path.splitext(file_name)[0],'text')\n",
    "    file = os.listdir(file_path)\n",
    "    files = sorted(file)\n",
    "\n",
    "    a = main(files)\n",
    "    #print(a)\n",
    "\n",
    "    c = os.path.splitext(file_name)[0]+'_text.txt'\n",
    "    t = os.path.splitext(file_name)[0]+'_f-text.txt'\n",
    "\n",
    "    #cs = os.path.splitext(file_name)[0]+'_xl.csv'\n",
    "\n",
    "    text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                    os.path.splitext(file_name)[0],'txt',c), \"wt\")\n",
    "    n = text_file.write(a)\n",
    "    text_file.close()\n",
    "\n",
    "    df = pd.read_csv(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                    os.path.splitext(file_name)[0],'txt',c),\n",
    "            header=None,delimiter=',',names=list(range(5)))\n",
    "    df[1] = df[1].astype(str)\n",
    "    #print(df)\n",
    "\n",
    "    df1 = df.dropna(axis = 0,how = 'all')\n",
    "    #print(df1)\n",
    "\n",
    "    word = 'TOTAL WAGES PAID'\n",
    "\n",
    "\n",
    "\n",
    "    if df1[0].dtypes != 'object':\n",
    "        print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',0)\n",
    "\n",
    "    else:\n",
    "\n",
    "        for i in df1[0]:\n",
    "            if fuzz.ratio(word,str(i)) > 80:\n",
    "                #print(i)\n",
    "                dff = df1[df1[0] == i]\n",
    "                dff = dff.dropna(axis = 1,how = 'all')\n",
    "                output = dff[1]\n",
    "                output = output.str.replace(r'[^\\w\\s]+', '')\n",
    "                output = output.str.replace(\" \",\"\")\n",
    "                #print(output)\n",
    "\n",
    "                if len(output) == 0:\n",
    "                    print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',0)\n",
    "                else:\n",
    "                    with open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                                os.path.splitext(file_name)[0],'final_text',t), 'a') as f:\n",
    "                        f.write(output.to_string(header = False, index = False))\n",
    "\n",
    "                    text_file = open(os.path.join('/home/vimalkumar.s/Documents/extraction/header/total wages paid/table-ocr_input',\n",
    "                                                os.path.splitext(file_name)[0],'final_text',t), 'r+')\n",
    "\n",
    "                    print(os.path.splitext(file_name)[0]+'.tif','TOTAL WAGES PAID',text_file.read())\n",
    "        \n",
    "                \n",
    "                \n",
    "    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3478d06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vimalkumar.s/Documents/python_new/cde_venv/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0423173000.tif TOTAL WAGES PAID 4963118\n"
     ]
    }
   ],
   "source": [
    "file_name = '0423173000.jpeg'\n",
    "twp(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c98b8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0319768000.tif TOTAL WAGES PAID 385196\n"
     ]
    }
   ],
   "source": [
    "file_name = '0319768000.jpeg'\n",
    "twp(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5094ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
